---
  title: "Predicting child maltreatment risk in Richmond, VA:<br>An open source framework"
author: <span style="font-size:20px">Ken Steif, Ph.D,<br>Matthew D. Harris,<br>Sydney Goldstein, M.C.P.</span>
  date: <span style="font-size:18px">November 21, 2018</span><br><br><span style="font-size:14px">[Urban Spatial](http://urbanspatialanalysis.com/)<br>[Predict Align Prevent](https://www.predict-align-prevent.org/)</span>
  output:
  html_document:
  includes:
  in_header: header.html
theme: united
toc: yes
toc_depth: 6
toc_float: yes
---
  
```{r setup, include=FALSE, warning=FALSE, messages=FALSE, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(include=FALSE, warning=FALSE, 
                      message=FALSE, echo=FALSE, cache=TRUE, fig.align="center")
```

```{r packages, message=FALSE, warning=FALSE, cache=FALSE, echo=FALSE}
library("sf")            # Spatial data objects and methods
library("mapview")       # Interactive Map Viewing
library("ggmap")         # ggplot2 addon for base maps
library("cowplot")
library("spatstat")      # KDE and other spatial functions
library("raster")        # cell-based spatial operations
library("tidyverse")     # data manipulation framework
library("Hmisc")         # using cut2() functions for ggplot legends
library("fitdistrplus")  # Distribution fitting functions
library("lubridate")     # Power tools for handling dates
library("tidycensus")
library("lwgeom")
library("Hmisc")
library("hrbrthemes")
library("gridExtra")
library("patchwork")
library("spdep")         # KNN functions
library("foreach")
library("doParallel")
library("corrplot")
library("ranger")        # randomforest implimentation      
library("glmnet")        # for Ridge and Lasso Regression
library("knitr")         # for kable table
library("kableExtra")
library("FNN")           # KNN for CPS vs. NN plots
library("groupdata2")
library("htmltools")
library("viridis")
library("viridisLite")
```

```{r logos, echo = FALSE, include = FALSE, cache = FALSE}
img <- htmltools::img(src = knitr::image_uri("C:/projects/PAP_Virginia/final_report/logosForMarkdown-01.png"), 
                      alt = 'logo', 
                      style = 'position:absolute; top:0px; right:0px; padding:10px; width:200px; height:150px')

htmlhead <- paste0('
<script>
document.write(\'<div class="logos">',img,'</div>\')
</script>
')

readr::write_lines(htmlhead, path = "header.html")
```

```{r themes}
mapTheme <- function() {
  theme(
    plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks = element_blank(),
    axis.line = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"),
    panel.border = element_blank()
  )
}

plotTheme <- function() {
  theme(
    plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0), 
    axis.title.x = element_text(size = 10, family = "sans", face = "plain", hjust = 1, vjust = -0.5),
    axis.title.y = element_text(size = 10, family = "sans", face = "plain", hjust = 1, vjust = 1),
    axis.text = element_text(size = 9, family = "sans", face = "plain"),
    panel.background = element_blank(),
    panel.grid.minor = element_line(colour = "gray"),
    panel.grid.major = element_line(colour = "gray"),
    axis.ticks = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"),
    axis.line = element_blank()
  )
}
```

```{r options}
mapviewOptions(basemaps = c("Stamen.TonerLite", "OpenStreetMap.DE"))
base_dir = "C:/projects/PAP_Virginia"
fishnet_grid_dim = 1000
k_direction = 8 # 4 = rook, 8 = queen
k_nearest_neighbors = 5
# Either k (e.g. 5 or 10) or "LOOCV"
n_folds = "LOOCV"
# threshold quntile for statArea grouping
stat_area_quantile = 0.60
# Number of simulations for CPS vs. NN
simulations = 1000
# Number of neighbors for CPS vs. NN
k = 5
# random seed
set.seed(717)
```

```{r SOURCE}
source('C:/projects/PAP_Virginia/source_files/FUNCTIONS_VAPAP.R', echo = TRUE, keep.source = TRUE)
source('C:/projects/PAP_Virginia/source_files/FEA_CREATE_VARIABLES.R', echo = TRUE, keep.source = TRUE)
```

```{r neighborhoods}
# Richmond Neighborhoods
nbr <- read_sf("https://data.richmondgov.com/resource/7juf-nwis.geojson")  %>%
  st_sf() %>%
  st_transform(102747)

nbr_diss <- nbr %>%
  mutate(dissolve = 1) %>%
  # get rid of slivers
  st_buffer(., dist = 0.1) %>%
  group_by(dissolve) %>%
  summarise()

nbr_rast_SP <- raster(as(nbr_diss, "Spatial"), nrows = 2000, ncol = 2000)
```

```{r basemap}
nbr <- read_sf("https://data.richmondgov.com/resource/7juf-nwis.geojson") %>%
  st_transform(crs = 102747)
cps_base_map   <- get_map(location = unname(st_bbox(ll(st_buffer(var_list[["CPS_Accepted"]],5000)))),
                          source = "stamen",
                          maptype = "toner")

### get CPS_Accepted values (add 1 column for dissolving)
cps_dissolve <- var_list[["CPS_Accepted"]] %>%
  mutate(value = 1) %>%
  dplyr::select(value)
```

```{r fishnet}
net <- st_make_grid(nbr, cellsize = fishnet_grid_dim) 
# count CPS incidents per net cell - really just to get net raster into sf polygon format
net_agg <- aggregate(cps_dissolve, net, sum) %>%
  tibble::rowid_to_column(.,"net_id")
# list of net cells IDs that intersect with Richmond
net_intersect <- st_intersects(nbr, net_agg) 
# extract Richmonds net cells based on intersect ID
net_Richmond <- net_agg[unique(unlist(net_intersect)),]
net_hood <- st_join(net_Richmond, nbr, largest = TRUE)
listw <- nb2listw(poly2nb(as(net_Richmond, "Spatial"), queen = TRUE))
```

```{r population_data}
vars10 <- c("P0010001") # total population (correct, I checked the web)
## get total 2010 census pop for blocks & calculate area
#richmond_block <- get_decennial(geography = "block", variables = vars10, year = 2010,
#summary_var = "P0010001", state = 51, county = 760, geometry = TRUE) %>%
#st_transform(crs = 102747)
# calc area
richmond_block <- st_read("richmond_block.shp")    #was having issues with above code when I knit so pulled in from the PAP project file

richmond_block <- richmond_block %>%
  mutate(acre = as.numeric(st_area(richmond_block)*2.29568e-5),
         # acre = units::set_units(acre, acre), 
         pop_acre_rate = value / acre) 
```

```{r t_intersection}
net_blocks_intersect <- st_intersection(richmond_block, net_Richmond)

# group by cell and calc block stats.
net_blocks_intersect <- net_blocks_intersect %>%
  mutate(intersect_area_acres = as.numeric(st_area(net_blocks_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = intersect_area_acres/acre,
         intersect_pop = value * pcnt_of_block) %>%
  arrange(net_id)
```

```{r, summarise_pop}
fishnet_pop <- net_blocks_intersect %>% # xcc
  group_by(net_id) %>%
  summarise(net_pop = sum(intersect_pop)) %>%
  filter(net_pop > 0)   # <-  zeros or no zeros!!!!

######### MAKE NET AND RATE FOR ALL CPS VARS
CPS_vars <- grep("CPS_",names(var_list), value = TRUE)
CPS_agg <- NULL
for(i in seq_along(CPS_vars)){
  var_name <- paste0("net_",CPS_vars[i])
  cat(var_name,"\n")
  
  CPS_dat <- var_list[[CPS_vars[i]]] %>%
    mutate(value = 1) %>%
    dplyr::select(value)
  fishnet_CPS_var <- aggregate(x = CPS_dat, by = fishnet_pop, FUN = sum) %>%
    st_drop_geometry() %>%
    mutate(Feature = var_name) %>%
    dplyr::select(Feature,value)
  
  CPS_agg <- rbind(CPS_agg, fishnet_CPS_var)
}
CPS_agg <- CPS_agg %>%
  mutate(id = rep(seq(1:nrow(fishnet_pop)),length(CPS_vars))) %>%
  spread(Feature, value) %>%
  dplyr::select(-id) %>%
  mutate(geometry = fishnet_pop$geometry) %>%
  st_as_sf()
#### Spatial join of fishnet_pop and fishnet_cps to then calculate rate for all CPS features
fishnet_pop_cps <- st_join(fishnet_pop, CPS_agg, join = st_equals) %>%
  mutate_at(vars(paste0("net_",CPS_vars)), funs(rate = ./(net_pop/100)))  %>% # cps per 100 person
  rename_at(vars( contains( "_rate")), funs(paste("rate", gsub("net_|_rate", "", .), sep = "_"))) %>% 
  replace(is.na(.), 0) # replace NA with zero

fishnet_coords <- fishnet_pop_cps %>%
  st_centroid() %>%
  st_coordinates() %>%
  as.matrix()
```

```{r CPS_COUNT_BY_FISHNET_plot}
fishnet_pop_cps_cut <- fishnet_pop_cps %>%
  mutate(net_CPS_Accepted = ifelse(is.na(net_CPS_Accepted), 0, net_CPS_Accepted)) %>% 
  make_cuts(., "net_CPS_Accepted", cuts = "breaks", n_breaks = 10)

CPS_COUNT_BY_FISHNET_PLOT <- ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_cut), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  labs(title = "CPS count per\nfishnet cell") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "CPS Count") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))
```

```{r CPS_RATE_BY_FISHNET_plot}
fishnet_pop_cps_rate_cut <- fishnet_pop_cps %>%
  mutate(rate_CPS_Accepted = ifelse(is.na(rate_CPS_Accepted), 0, rate_CPS_Accepted)) %>% 
  make_cuts(., "rate_CPS_Accepted", cuts = "breaks", n_breaks = 10)

CPS_RATE_BY_FISHNET_PLOT <- ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_rate_cut), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  labs(title = "Child Protective Service rate\nper 100 people") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "CPS Rate\nper 100") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))
```

```{r CPS_Count_Month_Year_table}
CPS_Counts_Year_table  <- table(lubridate::year(var_list[["CPS_Accepted"]]$RDate))
CPS_Counts_Month_table <- table(lubridate::month(var_list[["CPS_Accepted"]]$RDate))
```

```{r CPS_HIST_BY_DATE_plot}
CPS_by_year <- lubridate::year(var_list[["CPS_Accepted"]]$RDate) %>%
  data.frame(year = .)
CPS_HIST_BY_DATE <- ggplot(CPS_by_year, aes(x = year)) +
  geom_histogram() +
  plotTheme()
```

```{r CPS_POINT_BY_MONTH_plot}
months <- c("January", "February", "March", "April", 
            "May", "June", "July","August", 
            "September", "October", "November", "December")
cps <- var_list[["CPS_Accepted"]] %>%
  mutate(year  = lubridate::year(RDate),
         month = lubridate::month(RDate),
         month = months[month],
         month = fct_relevel(month, months))

CPS_POINT_BY_MONTH_plot <- ggmap(cps_base_map) +
  geom_point(data = data.frame(st_coordinates(ll(cps)), year = cps$year), 
             aes(x=X, y=Y, color = as.factor(year)), size=1.5, alpha = 0.8) +
  scale_color_viridis_d(name = "Year") +
  labs(title = "CPS Accepted in Richmond, Virginia by Year",
       caption = "source: **************") +
  facet_wrap(~year) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11),
    legend.position = c(0.85, 0.25) # or "none
  )
```

```{r CPS_KDE_BY_YEAR_plot}
variable = "year"
values <- unique(cps[[variable]])
year_dat <- list()
brks <- 9
window_cps <- get_window(cps, buff_dist = 10000)
for(i in seq_along(values)){
  dat <- filter(cps, !!as.name(variable) == values[i])
  points.ppp <- as.ppp(st_coordinates(ll(dat)),window_cps)
  densityRaster <- raster(density(points.ppp, scalekernel=TRUE, sigma = 0.005))
  dens_data <- gplot_data(densityRaster, maxpixels = 2500) %>%
    mutate(!!as.name(variable) := values[i])
  year_dat[[i]] <- dens_data
}
year_dat <- do.call(rbind, year_dat)

CPS_KDE_BY_YEAR_plot <- ggmap(cps_base_map) +
  geom_tile(data = year_dat, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = !!as.name(variable)), alpha=0.8) +
  scale_fill_viridis_d(name = variable) +
  labs(title = "CPS accepted in Richmond, VA by year",
       caption = "Figure 5.2") +
  facet_wrap(vars(!!as.name(variable))) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11, hjust = 0),
    strip.background = element_rect(fill = "white"),
    legend.position = "none"
  )
```

```{r CPS_TREND_BY_MONTH_YEAR_plot}
CPS_by_year_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate(month = lubridate::month(RDate),
         year  = lubridate::year(RDate))%>%
  dplyr::select(month, year) %>%
  group_by(month, year) %>%
  mutate(m_count = n()) %>%
  distinct() %>%
  ungroup()

CPS_TREND_BY_MONTH_YEAR_plot <- ggplot(CPS_by_year_month, aes(x = year, y = m_count)) +
  geom_point() +
  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) +
  labs(y="Incidents per month") +
  plotTheme()
```

```{r CPS_LINE_AGG_BY_MOTNH_plot}
CPS_agg_by_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate(month = lubridate::month(RDate),
         year  = lubridate::year(RDate))%>%
  group_by(month) %>%
  summarise(count = n())

CPS_LINE_AGG_BY_MOTNH_plot <- ggplot(CPS_agg_by_month, aes(x = month, y = count)) +
  scale_x_continuous(breaks = seq(1,12), labels = seq(1,12)) +
  geom_line() +
  plotTheme()
```

```{r CPS_LINE_NORMALIZED_plot}
CPS_normalized_by_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate(month = lubridate::month(RDate),
         year  = lubridate::year(RDate)) %>%
  group_by(year, month) %>%
  summarise(m_total = n()) %>%
  arrange(month, year) %>%
  dplyr::select(month, year, m_total) %>%
  ungroup() %>%
  group_by(month) %>%
  mutate(m_mean = mean(m_total),
         m_sd   = sd(m_total),
         m_z    = (m_total - m_mean) / m_sd)

CPS_LINE_NORMALIZED_plot <- ggplot(CPS_normalized_by_month, aes(x = as.factor(month), 
                                                                y = m_z, group = year, 
                                                                color = as.factor(year))) +
  geom_line() +
  geom_hline(yintercept = 0, color = "gray20", linetype = "dashed") +
  scale_color_viridis_d(name = "year") +
  labs(x = "month") +
  scale_y_continuous(limits = c(-2,2)) +
  plotTheme()
```

```{r CPS_CALENDAR_plot}
CPS_agg_cal <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
  mutate() %>%
  mutate(day = factor(weekdays(RDate,T),
                      levels = rev(c("Mon", "Tue", "Wed", "Thu","Fri", "Sat", "Sun"))),
         week = week(RDate),
         month = month(RDate),
         year  = year(RDate)) %>%
  dplyr::select(day, week, month, year) %>%
  group_by(day, week, month, year) %>%
  summarise(day_cnt = n()) %>%
  complete(day, week, month, year) 

CPS_CALENDAR_plot <- ggplot(CPS_agg_cal, aes(x = week, y = day, fill = day_cnt)) +
  viridis::scale_fill_viridis(name="Incidents",
                              option = 'C',
                              direction = 1,
                              na.value = "gray90") +
  geom_tile(color = 'white', size = 0.1) +
  facet_wrap('year', ncol = 1) +
  scale_x_continuous(
    expand = c(0, 0),
    breaks = seq(1, 52, length = 12),
    labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
               "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")) +
  theme_ipsum_rc()
```

```{r CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot}
grid_seq <- c(500,1000,1500)
p_loc_l  <- vector(mode = "list", length = length(grid_seq))
p_hist_l <- vector(mode = "list", length = length(grid_seq))
for(i in seq_along(grid_seq)){
  cat(grid_seq[i], "\n")
  net_i <- st_make_grid(nbr, cellsize = grid_seq[i])
  net_agg_i <- aggregate(cps_dissolve, net_i, sum) %>% 
    mutate(value = ifelse(is.na(value),0,value))
  
  net_intersect_i <- st_intersects(nbr, net_agg_i) 
  # extract Richmonds net cells based on intersect ID
  net_Richmond_i <- net_agg_i[unique(unlist(net_intersect_i)),]
  
  net_Richmond_i$class <- Hmisc::cut2(net_Richmond_i$value, g = 9)
  p_loc <- ggmap(cps_base_map) +
    geom_sf(data = ll(net_Richmond_i), aes(fill = class), 
            color = NA, inherit.aes = FALSE, size = 0.5, alpha = 0.8) +
    scale_fill_viridis_d(na.value=NA,
                         name   = paste0("Values","\n[quantiles]"),
                         breaks = levels(net_agg_i$class),
                         labels = levels(net_agg_i$class)) +
    mapTheme()
  
  p_loc_l[[i]] <- p_loc
  
  p_hist <- ggplot(net_Richmond_i, aes(x=value)) +
    geom_histogram(bins = 30) +
    # scale_x_continuous(limits = c(-1,100)) +
    # scale_y_continuous(limits = c(0,15)) +
    labs(title = paste0("Cell Dimensions =\n",grid_seq[i]," ft sq")) +
    plotTheme()
  
  p_hist_l[[i]] <- p_hist
}

CPS_COMPARE_FISHNET_GRID_SIZE_3x2_plot <- grid.arrange(p_hist_l[[1]], p_hist_l[[2]], p_hist_l[[3]], p_loc_l[[1]], p_loc_l[[2]], p_loc_l[[3]], ncol = 3)
```

```{r fitdistr_gof}
number <- as.numeric(na.omit(fishnet_pop_cps$net_CPS_Accepted))
fitp <- fitdist(number,"pois", discrete = TRUE)
fitnb <- fitdist(number,"nbinom", discrete = TRUE)
cdfcomp(list(fitp,fitnb)) # plot
gof <- gofstat(list(fitp,fitnb))
```

```{r AIC_LINE_FITDISTR_plot}
net_cell_dims <- seq(500,5000,50)
aic_results <- matrix(nrow=length(net_cell_dims), ncol = 3)
colnames(aic_results) <- c("cell_dim","pois","nbinom")
for(i in seq_along(net_cell_dims)){
  net <- st_make_grid(nbr,cellsize=net_cell_dims[i])
  
  cps_cnt <- aggregate(cps_dissolve, net, sum)
  
  number <- as.numeric(na.omit(cps_cnt$value))
  fitp <- fitdist(number,"pois", discrete = TRUE)
  fitnb <- fitdist(number,"nbinom", discrete = TRUE)
  gof <- gofstat(list(fitp,fitnb))
  aic_results[i,1] <- net_cell_dims[i]
  aic_results[i,2] <- as.numeric(gof$bic[1])
  aic_results[i,3] <- as.numeric(gof$bic[2])
}

AIC_LINE_FITDISTR_plot <- data.frame(aic_results) %>%
  gather(dist, aic, -cell_dim) %>%
  rename("Distribution" = dist) %>% 
  mutate(Distribution = case_when(
    Distribution == "nbinom" ~ "Negative Binomial",
    Distribution == "pois"   ~ "Poisson"
  )) %>% 
  ggplot(., aes(x = cell_dim, y = aic, group = Distribution, color = Distribution)) +
  geom_line() +
  labs(y = "AIC - goodness of fit",
       x = "Fishnet Cell Dimension (feet)") +
  plotTheme()
```

```{r risk_protective_var_list}
protective_names <- c("CommunityCenters",
                      "FireStations",
                      "HomelessShelters",
                      "Libraries",
                      "Parks",
                      "PointsOfInterest",
                      "PoliceStations",
                      "PublicSchools",
                      "ResourceOASIS",
                      "SNAP_WIC",
                      "VotingStations",
                      "Pharmacies",
                      "BUSI_Grocery.Store",
                      "Child.Care.Providers",
                      "Places.of.Worship")

risk_names <- c("BusStops",
                "DRUG.NARCOTIC",
                "SIMPLE.ASSAULT..DOMESTIC",
                "RUNAWAY",
                "AGGRAVATED.ASSAULT.DOMESTIC",
                "Unsafe.Structure",
                "Unfit.Structure",
                "Laundromats",
                "Pawnbrokers",
                "Car.Wash",
                "ABC.Stores",
                "Payday.Loan",
                "Motels",
                "Nail.and.Hair")

risk_var_list <- var_list[grep(paste(risk_names,collapse="|"), names(var_list), value = TRUE)]
protective_var_list <- var_list[grep(paste(protective_names,collapse="|"), names(var_list), value = TRUE)]

```

```{r risk_points_KDE_compute}
risk_plot_dat <- list()
brks <- 9
window_cps <- get_window(cps, buff_dist = 10000)
for(i in seq_along(risk_var_list)){
  var_dat <- risk_var_list[[i]]
  points.ppp <- as.ppp(st_coordinates(ll(var_dat)),window_cps)
  densityRaster <- raster(density(points.ppp, scalekernel=TRUE, sigma = 0.005))
  dens_data <- gplot_data(densityRaster, maxpixels = 2500) %>%
    mutate(variable = names(risk_var_list)[i])
  risk_plot_dat[[i]] <- dens_data
}
risk_plot_dat <- do.call(rbind, risk_plot_dat)

# one-liner to extract all 'geometry' cols from list and rbind
risk_compile <- sf::st_as_sf(data.table::rbindlist(lapply(risk_var_list, '[', "geometry")))
risk.points.ppp <- as.ppp(st_coordinates(ll(risk_compile)),window_cps)
risk_densityRaster <- raster(density(risk.points.ppp, scalekernel=TRUE, sigma = 0.005))
risk_aggregate_plot_data <- gplot_data(risk_densityRaster, maxpixels = 2500) %>%
  mutate(variable = "Risk")
```

```{r RISK_KDE_FACET_PLOT}
RISK_KDE_FACET_PLOT <- ggmap(cps_base_map) +
  geom_tile(data = risk_plot_dat, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.8) +
  scale_fill_viridis_d(name = variable) +
  facet_wrap(~variable) +
  labs(title = "Spatial density of risk factors",
       caption = "Figure 5.4") +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11, hjust = 0),
    legend.position = "none",
    strip.background = element_rect(fill = "white")
  )

RISK_KDE_PLOT <- ggmap(cps_base_map) +
  geom_tile(data = risk_aggregate_plot_data, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.6) +
  scale_fill_viridis_d(name = variable) +
  #facet_wrap(~variable) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11),
    legend.position = "none"
  )
```

```{r protective_points_KDE_compute}
protective_plot_dat <- list()
window_cps <- get_window(cps, buff_dist = 10000)
for(i in seq_along(protective_var_list)){
  var_dat <- protective_var_list[[i]]
  points.ppp <- as.ppp(st_coordinates(ll(var_dat)),window_cps)
  densityRaster <- raster(density(points.ppp, scalekernel=TRUE, sigma = 0.005))
  dens_data <- gplot_data(densityRaster, maxpixels = 2500) %>%
    mutate(variable = names(protective_var_list)[i])
  protective_plot_dat[[i]] <- dens_data
}
protective_plot_dat <- do.call(rbind, protective_plot_dat)

# one-liner to extract all 'geometry' cols from list and rbind
protective_compile <- sf::st_as_sf(data.table::rbindlist(lapply(protective_var_list, '[', "geometry")))
protective.points.ppp <- as.ppp(st_coordinates(ll(protective_compile)),window_cps)
protective_densityRaster <- raster(density(protective.points.ppp, scalekernel=TRUE, sigma = 0.005))
protective_aggregate_plot_data <- gplot_data(protective_densityRaster, maxpixels = 2500) %>%
  mutate(variable = "Protective")
```

```{r PROTECTIVE_KDE_FACET_PLOT}
PROTECTIVE_KDE_FACET_PLOT <- ggmap(cps_base_map) +
  # geom_point(data = data.frame(st_coordinates(ll(cps)),
  #                              month = cps[[variable]]),
  #            aes(x=X, y=Y), size = 1, color = "gray30", alpha = 0.75) +
  geom_tile(data = protective_plot_dat, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.8) +
  scale_fill_viridis_d(name = variable) +
  facet_wrap(~variable) +
  labs(title = "Spatial density of protective factors",
       caption = "Figure 5.3") +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11, hjust = 0),
    legend.position = "none",
    strip.background = element_rect(fill = "white")
  )

PROTECTIVE_KDE_PLOT <- ggmap(cps_base_map) +
  geom_tile(data = protective_aggregate_plot_data, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.6) +
  scale_fill_viridis_d(name = variable) +
  #facet_wrap(~variable) +
  mapTheme() +
  theme(
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "plain", size = 11),
    legend.position = "none"
  )
```

```{r spatial_weights_lattice}
fishnet_knn <- knn2nb(knearneigh(fishnet_coords, k_direction))
fishnet_Weights <- nb2listw(fishnet_knn, style="W")
localMorans  <- as.data.frame(localmoran(fishnet_pop_cps$net_CPS_Accepted, fishnet_Weights))
globalMorans <- moran.mc(fishnet_pop_cps$net_CPS_Accepted, fishnet_Weights, nsim=999)
```

```{r GLOBAL_MORANS_PERMUTATION_plot}
GLOBAL_MORANS_PERMUTATION_plot <- ggplot(data.frame(res = globalMorans$res)[1:999,,0], aes(res)) + 
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = globalMorans$statistic), colour = "red",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I", 
       x = "Simulated Moran's I Value") +
  plotTheme()
```

```{r Morans_i_p_join}
fishnet_pop_cps_morans <- fishnet_pop_cps
fishnet_pop_cps_morans$Ii <- localMorans$Ii
fishnet_pop_cps_morans$pvalue <- localMorans$`Pr(z > 0)`
fishnet_pop_cps_morans <- cbind(fishnet_coords, fishnet_pop_cps_morans)
```

```{r MORANS_I_P_plot}
fishnet_pop_cps_morans_cut <- make_cuts(fishnet_pop_cps_morans, "net_CPS_Accepted",
                                        cuts = "breaks", n_breaks = 10)

plot_cps <- ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_morans_cut), aes(fill = cut_val),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "Maltreatment\nEvents") +
  labs(title = "Panel 1",
       subtitle = "CPS count by fishnet") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))

Ii_cut <- fishnet_pop_cps_morans %>%
  mutate(Ii_cut_val = as.character(Hmisc::cut2(.$Ii, 
                                               cuts = as.numeric(quantile(round(fishnet_pop_cps_morans$Ii,2), 
                                                                          na.rm=T, p = seq(0,1,0.25))))))
plot_Ii <- ggmap(cps_base_map) +
  geom_sf(data = ll(Ii_cut), aes(fill = Ii_cut_val),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "I value", option = "D") +
  labs(title = "Panel 2",
       subtitle = "Local Moran's I value") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))

p_cut <- fishnet_pop_cps_morans %>%
  mutate(pval_cut = ifelse(pvalue > 0.05, "Not\nSignificant", "Significant"))

plot_p <- ggmap(cps_base_map) +
  geom_sf(data = ll(p_cut), aes(fill = pval_cut),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "p-value", option = "D") +
  labs(title = "Panel 3",
       subtitle = "Stastically significant\nmaltreatment clusters",
       caption = "Figure 5.5") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
        plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
        plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
        axis.line = element_blank(),
        legend.title = element_text(size = 10, family = "sans"),
        legend.text = element_text(size = 9, family = "sans"))

MORANS_I_P_plot <- cowplot::plot_grid(plot_cps, plot_Ii, plot_p, ncol =1, align = "hv", axis = "lrbt")
#cowplot::plot_grid(plot_cps, plot_Ii, plot_p,rel_widths = c(0.9,0.9,0.9),ncol = 1, align = "v")
```

```{r start_parallel_backend}
cl <- makePSOCKcluster(24)
registerDoParallel(cl)
```

```{r aggregate_count_features}
agg_results <- Aggregate_points_Features(var_list, net_Richmond)
```

```{r euclidean_distance_features}
ED_results <- Euclidean_point_features(var_list, nbr_rast_SP, nbr_diss, net_Richmond)
```

```{r nearest_neighbor_features}
NN_results <- NN_point_features(var_list, net_Richmond, k_nearest_neighbors)
```

```{r stop_parallel_backend}
stopCluster(cl)
```

```{r sf1_features_download}
vars_sf1 <- c("P0010001",  # Total Population,
              "H00010001", # housing units
              "H0030003",  # vacant housing,
              "H0040002",  # owned and mortgaged,
              "H0040004",  # renter occupied
              "H0060001",  # occupied housing units
              "H0130001",  # Houshold size
              "P0360001",  # Population in families
              "P0360002",  # Population under 18yo
              "P0120003",  # Male under 5yo
              "P0120004",  # Male under 5-9yo
              "P0120005",  # Male under 10-14yo
              "P0120006",  # Male under 15-17yo
              "P0120027",  # Female under 5yo
              "P0120028",  # Female under 5-9yo
              "P0120029",  # Female under 10-14yo
              "P0120030"   # Female under 15-17yo
)
vars_sf1_desc <- c("Total Pop",
                   "Housing units",
                   "Housing, vacant",
                   "Housing, owned",
                   "Housing, rented",
                   "Housing, occupied units",
                   "Houshold size",
                   "Families Pop",
                   "Pop, under 18y",
                   "Male under 5y",
                   "Male under 5-9y",
                   "Male under 10-14y",
                   "Male under 15-17y",
                   "Female under 5y",
                   "Female under 5-9y",
                   "Female under 10-14y",
                   "Female under 15-17y")
vars_names <- data.frame(variable = vars_sf1, var_name = vars_sf1_desc, stringsAsFactors = FALSE)
#richmond_block_sf1 <- get_decennial(geography = "block", variables = vars_sf1, year = 2010,
#summary_var = "P0010001", state = 51, county = 760, geometry = TRUE) %>%
#st_transform(crs = 102747)
richmond_block_sf1 <- st_read("richmond_block_sf1.shp") %>% 
  rename(variable = variabl,
         summary_var = smmry_v)
sf1 <- richmond_block_sf1 %>%
  spread(., variable, value)
```

```{r sf1_features_create}
sf1_block <- sf1 %>%
  mutate(acre = as.numeric(st_area(sf1)*2.29568e-5))

net_blocks_intersect <- st_intersection(sf1_block, net_Richmond) 

# group by cell and calc block stats.
net_blocks_intersect2 <- net_blocks_intersect %>%
  mutate(intersect_area_acres = as.numeric(st_area(net_blocks_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = intersect_area_acres/acre) %>%
  # intersect_pop = value * pcnt_of_block) %>%
  arrange(net_id) %>%
  mutate_at(vars(matches("^P|^H")), funs(.* pcnt_of_block))

### summarise intersect pops to each net cell and create pop rates for some
fishnet_sf1 <- net_blocks_intersect2 %>% # xcc
  group_by(net_id) %>%
  summarise_at(vars(matches("^P|^H")), funs(sum)) %>%
  dplyr::select(-pcnt_of_block) %>%
  rename_at(vars(vars_sf1), function(x) vars_sf1_desc) %>%
  mutate(`Pop, under 5y`     = rowSums(st_drop_geometry(.[grep("5y$", names(.))])),
         `Pop, under 5-9y`   = rowSums(st_drop_geometry(.[grep("5-9y$", names(.))])),
         `Pop, under 10-14y` = rowSums(st_drop_geometry(.[grep("10-14y$", names(.))])),
         `Pop, under 15-17y` = rowSums(st_drop_geometry(.[grep("15-17y$", names(.))])),
         `Pop, under 10y`    = `Pop, under 5y` + `Pop, under 5-9y`,
         `Pop, 10-17y`       = `Pop, under 10-14y` + `Pop, under 15-17y`) %>%
  mutate_at(vars(matches("^Male|^Female|^Pop")), 
            funs(rate = divide_by(.,`Total Pop`/100)))

## cast data frame to list of variables
sf1_results <- fishnet_sf1 %>%
  gather(variable, value, -net_id, -geometry) %>%
  mutate(feature_name = paste0("SF1_",variable)) %>%
  group_by(variable) %>%
  nest() %>%
  pull(data)
names(sf1_results) <- paste0("SF1_",setdiff(colnames(fishnet_sf1), c("net_id","geometry")))
```

```{r fishnet_pop_crs_net}
fishnet_pop_cps_net <- fishnet_pop_cps %>%
  dplyr::select(net_id, net_pop, rate_CPS_Accepted, net_CPS_Accepted) %>%
  rename(cps_rate = rate_CPS_Accepted,
         cps_net  = net_CPS_Accepted)
```

```{r nearest_neighbor_feature_combine}
features <- data.frame(net_id = NN_results[[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(NN_results)){
  feat_i <- NN_results[[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value) %>%
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
NN_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id") 
```

```{r euclidean_distance_feature_combine}
features <- data.frame(net_id = ED_results[[1]][[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(ED_results[[1]])){
  feat_i <- ED_results[[1]][[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value = mean_dist ) %>% ### mean_dist  !!!
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
ED_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id")
```

```{r agg_feature_combine}
features <- data.frame(net_id = agg_results[[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(ED_results[[1]])){
  feat_i <- agg_results[[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value) %>%
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
agg_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id")
```

```{r sf1_feature_combine}
features <- data.frame(net_id = sf1_results[[1]]$net_id, stringsAsFactors = FALSE)
for(i in  seq_along(sf1_results)){
  feat_i <- sf1_results[[i]] %>%
    st_drop_geometry() %>%
    dplyr::select(net_id, feature_name, value) %>%
    spread(feature_name, value)
  features <- left_join(features, feat_i, by = "net_id")
}
# join features to our target of cps_rate
sf1_features <- features %>%
  left_join(., st_drop_geometry(fishnet_pop_cps_net), by = "net_id")
```

```{r corr_feature_remove_NA}
cor_NN_features <- NN_features %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>%
  dplyr::select(-net_id)

cor_agg_features <- agg_features %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>%
  dplyr::select(-net_id)

cor_ED_features <- ED_features %>%
  mutate(cps_rate = ifelse(is.na(cps_rate),0,cps_rate),
         net_pop = ifelse(is.na(net_pop),0,net_pop)) %>%
  na.omit() %>%
  dplyr::select(-net_id)

cor_sf1_features <- sf1_features %>%
  mutate(cps_rate = ifelse(is.na(cps_rate),0,cps_rate),
         net_pop = ifelse(is.na(net_pop),0,net_pop)) %>%
  na.omit() %>%
  dplyr::select(-net_id)
```

```{r combine_ALL_FEATURES}
ALL_FEATURES <- full_join(NN_features, agg_features, by = "net_id") %>%
  full_join(.,ED_features, by = "net_id") %>%
  full_join(.,sf1_features, by = "net_id")
all.equal(ALL_FEATURES$cps_rate.x, ALL_FEATURES$cps_rate.y, 
          ALL_FEATURES$cps_rate.x.x, ALL_FEATURES$cps_rate.y.y)

NN_CPS_Accepted <- ALL_FEATURES$NN_CPS_Accepted

ALL_FEATURES <- ALL_FEATURES %>%
  dplyr::select(-cps_rate.y, -cps_rate.x.x, -cps_rate.y.y, 
                -cps_net.y, -cps_net.x.x, -cps_net.y.y,
                -net_pop.y, -net_pop.x.x, -net_pop.y.y) %>%
  dplyr::select(-contains("_CPS_")) %>%
  dplyr::rename(cps_net  = cps_net.x,
                cps_rate = cps_rate.x,
                net_pop  = net_pop.x) %>%
  mutate_all(funs(replace(., is.na(.), 0)))  %>%
  dplyr::rename_all(funs(make.names(.)))
## add NN_CPS_Accepted back in to ALL_FEATURES
ALL_FEATURES$NN_CPS_Accepted <- NN_CPS_Accepted
```

```{r corr_line_feature_data}
cps_cor_ALL <- cor(ALL_FEATURES)
All_cors <- cps_cor_ALL[,"cps_net"]

p.mat_ALL <- cor.mtest(ALL_FEATURES)$p
p.mat_ALL <- p.mat_ALL[,which(colnames(cps_cor_ALL)=="cps_net")]

cor_ALL_plot <- data.frame(feature = names(All_cors), 
                           cor = as.numeric(All_cors),
                           p_value   = p.mat_ALL) %>%
  filter(!(feature %in% c("cps_rate","cps_net","net_pop","net_cps","net_id"))) %>%
  filter(!(feature %in% grep("CPS", names(All_cors),value=T))) %>%
  arrange(desc(cor)) %>% 
  mutate(p_value = ifelse(p_value >= 0.1, "Not Significant", "Significant"))

cor_ALL_plot$feature <- factor(cor_ALL_plot$feature,
                               levels=cor_ALL_plot[order(cor_ALL_plot$cor,
                                                         decreasing=F),]$feature)
```

```{r CORR_LINE_POSITIVE_FEATURE_plot}
CORR_LINE_POSITIVE_FEATURE_plot <- ggplot(dplyr::filter(cor_ALL_plot,cor >= 0), 
                                          aes(x = feature, y = cor, color = factor(p_value))) +
  geom_segment(aes(x = feature, y = 0, xend = feature, yend = cor), color = "grey50") +
  geom_point() +
  coord_flip() +
  scale_color_discrete(name = "p-value") +
  theme_bw()
```

```{r CORR_LINE_NEGATIVE_FEATURE_plot}
CORR_LINE_NEGATIVE_FEATURE_plot <- ggplot(dplyr::filter(cor_ALL_plot,cor <= 0), 
                                          aes(x = feature, y = cor, color = factor(p_value))) +
  geom_segment(aes(x = feature, y = 0, xend = feature, yend = cor), color = "grey50") +
  geom_point() +
  coord_flip() +
  scale_color_discrete(name = "p-value") +
  theme_bw()
```

```{r corr_features_strong}
features_cor <- cor_ALL_plot %>%
  mutate(feature = as.character(feature)) %>%
  arrange(desc(cor)) %>%
  pull(feature)
top_n <- head(features_cor,10)
bottom_n <- tail(features_cor,10)

features_strong_cor <- ALL_FEATURES %>%
  dplyr::select(top_n, bottom_n, cps_net, cps_rate, net_pop, net_id) %>%
  base::identity()
```

```{r features_protective_all}
features_protective_all <- ALL_FEATURES %>%
  dplyr::select(contains("CommunityCenters"),
                contains("FireStations"),
                contains("HomelessShelters"),
                contains("Libraries"),
                contains("Parks"),
                contains("PointsOfInterest"),
                contains("PoliceStations"),
                contains("PublicSchools"),
                contains("ResourceOASIS"),
                contains("SNAP_WIC"),
                contains("VotingStations"),
                contains("Pharmacies"),
                contains("BUSI_Grocery.Store"),
                contains("Child.Care.Providers"),
                contains("Places.of.Worship"),
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id)

```

```{r features_protective_strong}
features_strong_protective_names <- cor_ALL_plot %>% 
  filter(feature %in% names(features_protective_all)) %>%
  mutate(prefix = str_extract(feature, "^[^_]+(?=_)"),
         suffix = str_extract(feature, "(?<=_)[^_].*"),
         feature = as.character(feature)) %>%
  group_by(suffix) %>%
  slice(which.max(abs(cor)))

features_protective_strong <- features_protective_all %>%
  dplyr::select(features_strong_protective_names$feature,
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id) %>%
  base::identity()
```

```{r features_risk_all}
features_risk_all <- ALL_FEATURES %>%
  dplyr::select(contains("BusStops"),
                contains("DRUG.NARCOTIC"),
                contains("SIMPLE.ASSAULT..DOMESTIC"),
                contains("RUNAWAY"),
                contains("AGGRAVATED.ASSAULT.DOMESTIC"),
                contains("Unsafe.Structure"),
                contains("Unfit.Structure"),
                contains("Laundromats"),
                contains("Pawnbrokers"),
                contains("Car.Wash"),
                contains("ABC.Stores"),
                contains("Payday.Loan"),
                contains("Motels"),
                contains("Nail.and.Hair"),
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id)
```

```{r features_risk_strong}
features_risk_strong_names <- cor_ALL_plot %>%
  filter(feature %in% names(features_risk_all)) %>%
  mutate(prefix = str_extract(feature, "^[^_]+(?=_)"),
         suffix = str_extract(feature, "(?<=_)[^_].*"),
         feature = as.character(feature)) %>%
  group_by(suffix) %>%
  slice(which.max(abs(cor)))

features_risk_strong <- features_risk_all %>%
  dplyr::select(features_risk_strong_names$feature,
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id) %>%
  base::identity()
```

```{r features_census_select}
features_census_select <- ALL_FEATURES %>%
  dplyr::select(SF1_Pop..under.18y,
                SF1_Families.Pop,
                SF1_Housing..rented,
                SF1_Houshold.size,
                SF1_Housing..vacant,
                cps_net, cps_rate, net_pop, net_id)
```

```{r CORR_RISK_FEATURES_plot, cache = FALSE}
features_risk_strong_plot <- features_risk_strong %>%
  dplyr::select(-net_id)
CORR_RISK_FEATURES_plot <- feature_corrplot(features_risk_strong_plot, "Correlation of Risk Features")
```

```{r CORR_PROTECTIVE_FEATURES_plot, cache = FALSE}
features_protective_strong_plot <- features_protective_strong %>%
  dplyr::select(-net_id)
CORR_PROTECTIVE_FEATURES_plot <- feature_corrplot(features_protective_strong_plot, "Correlation of Protective Features")
```

```{r protective_feature_CPS_vs_NN}
BUSI_protective_name <- var_list[["BusinessProject"]] %>%
  filter(Classification == "PROTECTIVE") %>%
  mutate(BUSTYP = paste0("BUSI_",BUSTYP)) %>%
  pull(BUSTYP) %>%
  unique()

protective_class <- c("CommunityCenters","FireStations",
                      "HomelessShelters","Libraries","Parks","PointsOfInterest",
                      "PoliceStations","PublicSchools","ResourceOASIS","SNAP_WIC",
                      "VotingStations")

BUSI_protective <- var_list[BUSI_protective_name[BUSI_protective_name %in% names(var_list)]]
resource_protective <- var_list[protective_class[protective_class %in% names(var_list)]]

protective_list <- do.call(c, list(resource_protective, BUSI_protective))


cl <- makePSOCKcluster(detectCores()-1)
registerDoParallel(cl)


rnd_protective_p_results_total <- NULL
rnd_protective_vec_total <- NULL
protective_mean_NN <- NULL
for(j in seq_along(protective_list)){
  protective_desc <- protective_list[[j]]
  cat(names(protective_list)[j], "\n")
  # need below b/c PoliceStation feature only has 5 featuresO
  k_nearest_neighbors_i <- ifelse(nrow(protective_desc) <= k_nearest_neighbors,
                                  nrow(protective_desc)-1, k_nearest_neighbors)
  protective_cps_NN <- nn_function(st_coordinates(protective_desc),
                                   st_coordinates(cps_dissolve), k_nearest_neighbors_i)
  protective_cps_NN <- mean(protective_cps_NN$value)
  
  
  rnd_protective_results <- foreach(i = seq_len(simulations),
                                    .packages = c('sf', 'dplyr', 'FNN', 'tibble', 'tidyr'),
                                    .combine  = c) %dopar% {
                                      # cat(i,"\n")
                                      if(nrow(protective_desc) > k_nearest_neighbors_i){
                                        ## b/c low count (e.g. police station) can return zero samples
                                        protective_cps_NN_rnd <- NULL
                                        while(length(protective_cps_NN_rnd) == 0){
                                          protective_cps_NN_rnd <- sf::st_sample(nbr_diss, nrow(protective_desc))
                                        }
                                        protective_cps_NN_rnd <- protective_cps_NN_rnd %>% 
                                          st_coordinates(.) %>%
                                          nn_function(., st_coordinates(cps_dissolve), k_nearest_neighbors_i)
                                      } else {
                                        protective_cps_NN_rnd <- NA
                                      }
                                    }
  rnd_protective_p_results <- data.frame(p = map_dbl(rnd_protective_results,
                                                     function(x) 1-ecdf(x)(protective_cps_NN)),
                                         Feature = names(protective_list)[j])
  rnd_protective_p_results_total <- rbind(rnd_protective_p_results_total, rnd_protective_p_results)
  
  rnd_protective_vec <- data.frame(dist = as.numeric(map_dbl(rnd_protective_results, mean)),
                                   Feature = names(protective_list)[j])
  rnd_protective_vec_total <- rbind(rnd_protective_vec_total, rnd_protective_vec)
  
  protective_mean_NN <- rbind(protective_mean_NN, data.frame(mean = protective_cps_NN,
                                                             Feature = names(protective_list)[j]))
}

stopCluster(cl)

```

```{r PROTECTIVE_CPS_VS_NN_plot}
rnd_protective_vec_total$Feature <- factor(rnd_protective_vec_total$Feature ,
                                           levels = as.character(arrange(protective_mean_NN, mean)$Feature))
PROTECTIVE_CPS_VS_NN_plot <- ggplot(data = rnd_protective_vec_total, aes(x = dist, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) +
  geom_vline(data = protective_mean_NN, aes(xintercept = mean), size = 2) +
  #scale_x_continuous(breaks=seq(400,4500,200), labels = seq(400,4500,200)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = paste0("Mean NN Distance (k = ",k_nearest_neighbors,")"),
       title = "Protective factors closeness test",
       caption = "Figure 5.8") +
  scale_fill_viridis_d() +
  plotTheme() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 11, family = "sans", face = "plain", hjust = 0),
    strip.background = element_rect(fill = "white")
  )
```

```{r PROTECTIVE_CPS_VS_NN_PVALUE_plot}
rnd_protective_p_results_total$Feature <- factor(rnd_protective_p_results_total$Feature ,
                                                 levels = as.character(arrange(protective_mean_NN, mean)$Feature))
PROTECTIVE_CPS_VS_NN_PVALUE_plot <- ggplot(rnd_protective_p_results_total, aes(x = p, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0.5) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1), limits = c(0,1)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = "Probability of True Mean NN Distance Being Less Than Simulated Distance Value") +
  scale_fill_viridis_d() +
  theme_bw() +
  theme(
    legend.position = "none"
  )

```

```{r risk_feature_CPS_vs_NN}
BUSI_risk_name <- var_list[["BusinessProject"]] %>%
  filter(Classification == "RISK") %>% 
  mutate(BUSTYP = paste0("BUSI_",BUSTYP)) %>% 
  pull(BUSTYP) %>% 
  unique()

CrimeData_risk_name <- var_list[["CrimeData"]] %>%
  filter(OFFENSE %in% c('DRUG/NARCOTIC VIOLATION','SIMPLE ASSAULT, DOMESTIC',
                        'Runaway','AGGRAVATED ASSAULT DOMESTIC')) %>% 
  mutate(OFFENSE = paste0("CRIME_",OFFENSE)) %>% 
  pull(OFFENSE) %>% 
  unique()

VIO_risk_name <- var_list[["Violations_III_ks"]] %>%
  filter(CodeDsrp %in% c('General Violations','Unsafe Structure',
                         'Unfit Structure'))  %>% 
  mutate(CodeNbr = paste0("VIO_", CodeNbr)) %>% 
  count(CodeNbr) %>% 
  filter(n > 50) %>% 
  pull(CodeNbr) %>% 
  unique()

BUSI_risk <- var_list[BUSI_risk_name[BUSI_risk_name %in% names(var_list)]]
CRIME_risk <- var_list[CrimeData_risk_name[CrimeData_risk_name %in% names(var_list)]]
BusStops_risk <- var_list["BusStops"]
VIO_risk <- var_list[VIO_risk_name[VIO_risk_name %in% names(var_list)]]

risk_list <- do.call(c, list(BUSI_risk, CRIME_risk, BusStops_risk, VIO_risk))

cl <- makePSOCKcluster(detectCores()-1)
registerDoParallel(cl)

rnd_risk_p_results_total <- NULL
rnd_risk_vec_total <- NULL
risk_mean_NN <- NULL
for(j in seq_along(risk_list)){
  risk_desc <- risk_list[[j]]
  cat(names(risk_list)[j], "\n")
  risk_cps_NN <- nn_function(st_coordinates(risk_desc),
                             st_coordinates(cps_dissolve), k_nearest_neighbors)
  risk_cps_NN <- mean(risk_cps_NN$value)
  
  
  rnd_risk_results <- foreach(i = seq_len(simulations),
                              .packages = c('sf', 'dplyr', 'FNN', 'tibble', 'tidyr'),
                              .combine  = c) %dopar% { 
                                cat(i,"\n")
                                if(nrow(risk_desc) >= k_nearest_neighbors){
                                  risk_cps_NN_rnd <- sf::st_sample(nbr_diss, nrow(risk_desc)) %>%
                                    st_coordinates(.) %>%
                                    nn_function(., st_coordinates(cps_dissolve), k_nearest_neighbors)
                                } else {
                                  risk_cps_NN_rnd <- NA                    
                                }
                              }
  rnd_risk_p_results <- data.frame(p = map_dbl(rnd_risk_results, 
                                               function(x) 1-ecdf(x)(risk_cps_NN)), 
                                   Feature = names(risk_list)[j])
  rnd_risk_p_results_total <- rbind(rnd_risk_p_results_total, rnd_risk_p_results)
  
  rnd_risk_vec <- data.frame(dist = as.numeric(map_dbl(rnd_risk_results, mean)),
                             Feature = names(risk_list)[j])
  rnd_risk_vec_total <- rbind(rnd_risk_vec_total, rnd_risk_vec)
  
  risk_mean_NN <- rbind(risk_mean_NN, data.frame(mean = risk_cps_NN, 
                                                 Feature = names(risk_list)[j]))
}

stopCluster(cl)
```

```{r RISK_CPS_VS_NN_plot}
rnd_risk_vec_total$Feature <- factor(rnd_risk_vec_total$Feature , 
                                     levels = as.character(arrange(risk_mean_NN, mean)$Feature))
RISK_CPS_VS_NN_plot <- ggplot(data = rnd_risk_vec_total, aes(x = dist, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) +
  geom_vline(data = risk_mean_NN, aes(xintercept = mean), size = 2) +
  scale_x_continuous(breaks=seq(400,4500,200), labels = seq(400,4500,200)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = paste0("Mean NN Distance (k = ",k_nearest_neighbors,")")) +
  scale_fill_viridis_d(option = "A") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```

```{r RISK_CPS_VS_NN_PVALUE_plot}
rnd_risk_p_results_total$Feature <- factor(rnd_risk_p_results_total$Feature , 
                                           levels = as.character(arrange(risk_mean_NN, mean)$Feature))
RISK_CPS_VS_NN_PVALUE_plot <- ggplot(rnd_risk_p_results_total, aes(x = p, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) + 
  geom_vline(xintercept = 0.5) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1), limits = c(0,1)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = "Probability of True Mean NN Distance Being Less Than Simulated Distance Value") +
  scale_fill_viridis_d(option = "A") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```

```{r violation_feature_CPS_vs_NN}
vio_vars <- var_list[grep("VIO_",names(var_list), value = TRUE)]

#################################
cl <- makePSOCKcluster(32)
registerDoParallel(cl)
#################################
rnd_vio_p_results_total <- NULL
rnd_vio_vec_total <- NULL
vio_mean_NN <- NULL
for(j in seq_along(vio_vars)){
  vio_desc <- vio_vars[[j]]
  cat(names(vio_vars)[j], "\n")
  vio_cps_NN <- nn_function(st_coordinates(vio_desc),
                            st_coordinates(cps_dissolve), k)
  vio_cps_NN <- mean(vio_cps_NN$value)
  
  
  rnd_vio_results <- foreach(i = seq_len(simulations),
                             .packages = c('sf', 'dplyr', 'FNN', 'tibble', 'tidyr'),
                             .combine  = c) %dopar% { 
                               cat(i,"\n")
                               if(nrow(vio_desc) >= k){
                                 vio_cps_NN_rnd <- sf::st_sample(nbr_diss, nrow(vio_desc)) %>%
                                   st_coordinates(.) %>%
                                   nn_function(., st_coordinates(cps_dissolve), k_nearest_neighbors)
                               } else {
                                 vio_cps_NN_rnd <- NA                    
                               }
                             }
  rnd_vio_p_results <- data.frame(p = map_dbl(rnd_vio_results, 
                                              function(x) 1-ecdf(x)(vio_cps_NN)), 
                                  Feature = names(vio_vars)[j])
  rnd_vio_p_results_total <- rbind(rnd_vio_p_results_total, rnd_vio_p_results)
  
  rnd_vio_vec <- data.frame(dist = as.numeric(map_dbl(rnd_vio_results, mean)),
                            Feature = names(vio_vars)[j])
  rnd_vio_vec_total <- rbind(rnd_vio_vec_total, rnd_vio_vec)
  
  vio_mean_NN <- rbind(vio_mean_NN, data.frame(mean = vio_cps_NN, 
                                               Feature = names(vio_vars)[j]))
}

#################################
stopCluster(cl)
#################################
```

```{r VIOLATION_CPS_VS_NN_plot}
rnd_vio_vec_total$Feature <- factor(rnd_vio_vec_total$Feature , 
                                    levels = as.character(arrange(vio_mean_NN, mean)$Feature))
VIOLATION_CPS_VS_NN_plot <- ggplot(data = rnd_vio_vec_total, aes(x = dist, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) +
  geom_vline(data = vio_mean_NN, aes(xintercept = mean), size = 2) +
  scale_x_continuous(breaks=seq(400,4500,200), labels = seq(400,4500,200)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = paste0("Mean NN Distance (k = ",k_nearest_neighbors,")"),
       title = "Violation-related risk factors closeness test",
       caption = "Figure 5.7") +
  scale_fill_viridis_d() +
  plotTheme() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 11, family = "sans", face = "plain", hjust = 0),
    strip.background = element_rect(fill = "white")
  )
```

```{r VIOLATION_CPS_VS_NN_PVALUE_plot}
rnd_vio_p_results_total$Feature <- factor(rnd_vio_p_results_total$Feature , 
                                          levels = as.character(arrange(vio_mean_NN, mean)$Feature))
VIOLATION_CPS_VS_NN_PVALUE_plot <- ggplot(rnd_vio_p_results_total, aes(x = p, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) + 
  geom_vline(xintercept = 0.5) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1), limits = c(0,1)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = "Probability of True Mean NN Distance Being Less Than Simulated Distance Value") +
  scale_fill_viridis_d(option = "A") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```

```{r crime_feature_CPS_vs_NN}
crime_vars <- var_list[grep("CRIME_",names(var_list), value = TRUE)]

#################################
cl <- makePSOCKcluster(32)
registerDoParallel(cl)
#################################
rnd_crime_p_results_total <- NULL
rnd_crime_vec_total <- NULL
crime_mean_NN <- NULL
for(j in seq_along(crime_vars)){
  crime_desc <- crime_vars[[j]]
  cat(names(crime_vars)[j], "\n")
  crime_cps_NN <- nn_function(st_coordinates(crime_desc),
                              st_coordinates(cps_dissolve), k)
  crime_cps_NN <- mean(crime_cps_NN$value)
  
  
  rnd_crime_results <- foreach(i = seq_len(simulations),
                               .packages = c('sf', 'dplyr', 'FNN', 'tibble', 'tidyr'),
                               .combine  = c) %dopar% { 
                                 cat(i,"\n")
                                 if(nrow(crime_desc) >= k){
                                   crime_cps_NN_rnd <- sf::st_sample(nbr_diss, nrow(crime_desc)) %>%
                                     st_coordinates(.) %>%
                                     nn_function(., st_coordinates(cps_dissolve), k_nearest_neighbors)
                                 } else {
                                   crime_cps_NN_rnd <- NA                    
                                 }
                               }
  rnd_crime_p_results <- data.frame(p = map_dbl(rnd_crime_results, 
                                                function(x) 1-ecdf(x)(crime_cps_NN)), 
                                    Feature = names(crime_vars)[j])
  rnd_crime_p_results_total <- rbind(rnd_crime_p_results_total, rnd_crime_p_results)
  
  rnd_crime_vec <- data.frame(dist = as.numeric(map_dbl(rnd_crime_results, mean)),
                              Feature = names(crime_vars)[j])
  rnd_crime_vec_total <- rbind(rnd_crime_vec_total, rnd_crime_vec)
  
  crime_mean_NN <- rbind(crime_mean_NN, data.frame(mean = crime_cps_NN, 
                                                   Feature = names(crime_vars)[j]))
}

#################################
stopCluster(cl)
#################################
```

```{r CRIME_CPS_VS_NN_plot}
rnd_crime_vec_total$Feature <- factor(rnd_crime_vec_total$Feature , 
                                      levels = as.character(arrange(crime_mean_NN, mean)$Feature))
CRIME_CPS_VS_NN_plot <- ggplot(data = rnd_crime_vec_total, aes(x = dist, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) +
  geom_vline(data = crime_mean_NN, aes(xintercept = mean), size = 2) +
  scale_x_continuous(breaks=seq(400,4500,200), labels = seq(400,4500,200)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = paste0("Mean NN Distance (k = ",k_nearest_neighbors,")"),
       title = "Crime-related risk factors closeness test",
       caption = "Figure 5.6") +
  scale_fill_viridis_d() +
  plotTheme() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 11, family = "sans", face = "plain", hjust = 0),
    strip.background = element_rect(fill = "white")
  )
```

```{r CRIME_CPS_VS_NN_PVALUE_plot}
rnd_crime_p_results_total$Feature <- factor(rnd_crime_p_results_total$Feature , 
                                            levels = as.character(arrange(crime_mean_NN, mean)$Feature))
CRIME_CPS_VS_NN_PVALUE_plot <- ggplot(rnd_crime_p_results_total, aes(x = p, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) + 
  geom_vline(xintercept = 0.5) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1), limits = c(0,1)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = "Probability of True Mean NN Distance Being Less Than Simulated Distance Value") +
  scale_fill_viridis_d(option = "A") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```

```{r busifeature_CPS_vs_NN}
busi_vars <- var_list[grep("BUSI_",names(var_list), value = TRUE)]

#################################
cl <- makePSOCKcluster(32)
registerDoParallel(cl)
#################################
rnd_busi_p_results_total <- NULL
rnd_busi_vec_total <- NULL
busi_mean_NN <- NULL
for(j in seq_along(busi_vars)){
  busi_desc <- busi_vars[[j]]
  cat(names(busi_vars)[j], "\n")
  busi_cps_NN <- nn_function(st_coordinates(busi_desc),
                             st_coordinates(cps_dissolve), k)
  busi_cps_NN <- mean(busi_cps_NN$value)
  
  
  rnd_busi_results <- foreach(i = seq_len(simulations),
                              .packages = c('sf', 'dplyr', 'FNN', 'tibble', 'tidyr'),
                              .combine  = c) %dopar% { 
                                cat(i,"\n")
                                if(nrow(busi_desc) >= k){
                                  busi_cps_NN_rnd <- sf::st_sample(nbr_diss, nrow(busi_desc)) %>%
                                    st_coordinates(.) %>%
                                    nn_function(., st_coordinates(cps_dissolve), k_nearest_neighbors)
                                } else {
                                  busi_cps_NN_rnd <- NA                    
                                }
                              }
  rnd_busi_p_results <- data.frame(p = map_dbl(rnd_busi_results, 
                                               function(x) 1-ecdf(x)(busi_cps_NN)), 
                                   Feature = names(busi_vars)[j])
  rnd_busi_p_results_total <- rbind(rnd_busi_p_results_total, rnd_busi_p_results)
  
  rnd_busi_vec <- data.frame(dist = as.numeric(map_dbl(rnd_busi_results, mean)),
                             Feature = names(busi_vars)[j])
  rnd_busi_vec_total <- rbind(rnd_busi_vec_total, rnd_busi_vec)
  
  busi_mean_NN <- rbind(busi_mean_NN, data.frame(mean = busi_cps_NN, 
                                                 Feature = names(busi_vars)[j]))
}

#################################
stopCluster(cl)
#################################
```

```{r BUSINESS_CPS_VS_NN_plot}
rnd_busi_vec_total$Feature <- factor(rnd_busi_vec_total$Feature , 
                                     levels = as.character(arrange(busi_mean_NN, mean)$Feature))
BUSINESS_CPS_VS_NN_plot <- ggplot(data = rnd_busi_vec_total, aes(x = dist, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) +
  geom_vline(data = busi_mean_NN, aes(xintercept = mean), size = 2) +
  #scale_x_continuous(breaks=seq(400,4500,200), labels = seq(400,4500,200)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = paste0("Mean NN Distance (k = ",k_nearest_neighbors,")"),
       title = "Business-related features closeness test",
       caption = "Figure 5.8") +
  scale_fill_viridis_d() +
  plotTheme() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 11, family = "sans", face = "plain", hjust = 0),
    strip.background = element_rect(fill = "white")
  )
```

```{r BUSINESS_CPS_VS_NN_PVALUE_plot}
rnd_busi_p_results_total$Feature <- factor(rnd_busi_p_results_total$Feature , 
                                           levels = as.character(arrange(busi_mean_NN, mean)$Feature))
BUSINESS_CPS_VS_NN_PVALUE_plot <- ggplot(rnd_busi_p_results_total, aes(x = p, group = Feature, fill = Feature)) +
  geom_histogram(bins = 50) + 
  geom_vline(xintercept = 0.5) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1), limits = c(0,1)) +
  facet_wrap(~Feature, ncol = 1, scales = "free_y") +
  labs(x = "Probability of True Mean NN Distance Being Less Than Simulated Distance Value") +
  scale_fill_viridis_d(option = "A") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```

```{r features_prep}
target_var <- "cps_net"
features_protective_strong2 <- dplyr::select(features_protective_strong, -cps_rate, -net_pop)
features_risk_strong2 <- dplyr::select(features_risk_strong, -cps_rate, -net_pop)
features_census_select2     <- dplyr::select(features_census_select, -cps_rate, -net_pop)
```

```{r model_data_prep}
og_dat <- full_join(features_risk_strong, features_census_select, by = "net_id") %>%
  full_join(., features_protective_strong, by = "net_id") %>% 
  dplyr::select(-net_pop.y, -cps_net.y, -cps_rate.y,
                -net_pop.x, -cps_net.x, -cps_rate.x,
                -NN_CPS_Accepted.y) %>% 
  rename("NN_CPS_Accepted" = NN_CPS_Accepted.x)

dat    <- og_dat %>% dplyr::select(-cps_rate, -net_pop, -net_id) %>%
  mutate_at(vars(-cps_net), scale_this) %>%
  identity() # line ender (does nothing)

net_hood <- st_join(net_Richmond, nbr, largest = TRUE)
all.equal(net_hood$net_id, og_dat$net_id)
og_dat$.block_id <- net_hood$name
```

```{r neighborhood_fixed_effects}
hood_matrix <- model.matrix(cps_net~.block_id,og_dat)
hood_model <- lm(sqrt(og_dat$cps_net) ~ hood_matrix)
dat$hood_fixed <- predict(hood_model, type = "response")^2
og_dat$hood_fixed <- predict(hood_model, type = "response")^2
```

```{r create_cv_fold_tibble}
all_hoods <- length(unique(net_hood$name))
n_folds = ifelse(n_folds == "LOOCV", all_hoods, n_folds)
folds_index <- groupdata2::fold(og_dat, k = n_folds, id_col = '.block_id')$.folds

cv_tbl <- tibble(folds = seq_len(n_folds),
                 train = NA, train_y = NA, train_index = NA, train_net_id = NA,
                 test  = NA, test_y  = NA, test_index  = NA, test_net_id  = NA)
for(k in seq_len(n_folds)){
  fold_i  <- which(folds_index == k)
  cv_tbl[k,]$train         <- list(dat[-fold_i,])
  cv_tbl[k,]$test          <- list(dat[ fold_i,])
  cv_tbl[k,]$train_y       <- list(og_dat[-fold_i,target_var])
  cv_tbl[k,]$test_y        <- list(og_dat[ fold_i,target_var])
  cv_tbl[k,]$train_index   <- list(setdiff(seq(1:nrow(dat)),fold_i))
  cv_tbl[k,]$test_index    <- list(fold_i)
  cv_tbl[k,]$train_net_id  <- list(og_dat[-fold_i,"net_id"])
  cv_tbl[k,]$test_net_id   <- list(og_dat[ fold_i,"net_id"])
}
```

```{r NEIGHBORHOOD_FOLDS_plot}
cv_sf <- left_join(og_dat, net_Richmond, by = "net_id") %>%
  st_as_sf() %>%
  dplyr::select(.block_id)
NEIGHBORHOOD_FOLDS_plot <- plot(cv_sf)
```

```{r Poisson_regression}
po_cv_tbl <- cv_tbl %>%
  mutate(fit   = map(train, glm_fit, 
                     formula =  paste("cps_net ~ ."), 
                     family = "poisson"),
         pred  = map2(fit, test, lm_predict, sqrt = FALSE),
         mdl_nam = "GLM - Poisson") %>% 
  score_model()
cat("Test Set MAE:",mean(po_cv_tbl$MAE),"\n")
cat("Test Set logdev:",mean(po_cv_tbl$logdev, na.rm=TRUE),"\n")
```

```{r POISSON_REGRESSION_FIT_plot}
POISSON_REGRESSION_FIT_plot <- plot_fold_pred(po_cv_tbl$pred, po_cv_tbl$test_y, type = "fit")
```

```{r Random_Forest_regression}
rf_cv_tbl <- cv_tbl %>%
  mutate(fit   = map(train, rf_fit, formula = "cps_net ~ .", mtry_add = 2, importance = "impurity"),
         pred  = map2(fit, test, lm_predict),
         mdl_nam = "Random Forest") %>% 
  score_model()
cat("Test Set MAE:",mean(rf_cv_tbl$MAE),"\n")
cat("Test Set logdev:",mean(rf_cv_tbl$logdev, na.rm=TRUE),"\n")
```

```{r Radom_Forest_variable_importance_PLOT}
varimp_dat <- data.frame(importance = rf_cv_tbl$fit[[1]]$variable.importance) %>% 
  rownames_to_column("variable")

RF_VARIMP_PLOT <- ggplot(varimp_dat, aes(x=reorder(variable,importance), y=importance, fill=importance))+ 
  geom_bar(stat="identity", position="dodge")+ coord_flip()+
  labs(y = "Variable Importance",
       x = " ", 
       title = "Feature importance",
       subtitle = "Random Forest sub-model",
       caption = "Figure 6.4") +
  guides(fill=F)+
  scale_fill_viridis_c() +
  plotTheme()

```

```{r RANDOM_FOREST_FIT_plot}
RANDOM_FOREST_FIT_plot <- plot_fold_pred(rf_cv_tbl$pred, rf_cv_tbl$test_y, type = "fit")
```

```{r spatial_error_regression}
spat_durbin <- errorsarlm(sqrt(cps_net) ~ ., data = dat, listw, etype ="emixed")
spat_durbin_tbl <- tibble(
  fit   = list(spat_durbin),
  pred  = map(fit, sar_pred),
  test_y= list(dat$cps_net),
  test_net_id = list(og_dat$net_id),
  mdl_nam = "Spatial Durbin - sqrt") %>% 
  score_model()
cat("Test Set MAE:",mean(spat_durbin_tbl$MAE),"\n")
cat("Test Set logdev:",mean(spat_durbin_tbl$logdev, na.rm=TRUE),"\n")
```

```{r SPATIAL_ERROR_FIT_plot}
SPATIAL_ERROR_FIT_plot <- plot_fold_pred(spat_durbin_tbl$pred, dat$cps_net, type = "fit")
```

```{r gather_OOF_predictions}
po_pred_dat <- po_cv_tbl %>%
  unnest(pred) %>%
  mutate(test_y = po_cv_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = po_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id))

po_pred_geoplot <- model_pred_geoplot(po_pred_dat$pred,
                                      po_pred_dat$test_y,
                                      po_pred_dat$test_net_id,
                                      net_Richmond, cps_base_map, "po")

rf_pred_dat <- rf_cv_tbl %>%
  unnest(pred) %>%
  mutate(test_y = rf_cv_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = rf_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id))

rf_pred_geoplot <- model_pred_geoplot(rf_pred_dat$pred,
                                      rf_pred_dat$test_y,
                                      rf_pred_dat$test_net_id,
                                      net_Richmond, cps_base_map,
                                      "Random Forest")

sarlm_pred_dat <- spat_durbin_tbl %>%
  unnest(pred) %>%
  mutate(test_y = spat_durbin_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = spat_durbin_tbl %>% unnest(test_net_id) %>% pull(test_net_id))

sarlm_pred_geoplot <- model_pred_geoplot(sarlm_pred_dat$pred,
                                         sarlm_pred_dat$test_y,
                                         sarlm_pred_dat$test_net_id,
                                         net_Richmond, cps_base_map,
                                         "SARLM")
```

```{r join_model_predictions}
cps_preds <- og_dat %>% 
  dplyr::select(net_id, cps_net) %>% 
  left_join(., dplyr::select(po_pred_dat,
                             net_id = test_net_id,
                             pred_lm = pred), by = "net_id") %>%
  left_join(., dplyr::select(rf_pred_dat, 
                             net_id = test_net_id,
                             pred_rf = pred), by = "net_id") %>% 
  left_join(., dplyr::select(sarlm_pred_dat, 
                             net_id = test_net_id,
                             pred_sarlm = pred), by = "net_id") %>% 
  mutate_if(is.double, round, 2)
```

```{r meta_model_stacking}
if(all.equal(cps_preds$net_id, net_hood$net_id)){
  cat("Predictions and spatial data are in same order, GOOD to go!", "\n")
} else {
  cat("There is a PROBLEM with order of predictions and spatial data; Likely Errors!","\n")
}

cps_preds_cv_dat <- dplyr::select(cps_preds, -net_id)
ens_cv_tbl <- tibble(folds = seq_len(n_folds),
                     train = NA, train_y = NA, train_index = NA, train_net_id = NA,
                     test  = NA, test_y  = NA, test_index  = NA, test_net_id  = NA)
for(k in seq_len(n_folds)){
  fold_i  <- which(folds_index == k)
  ens_cv_tbl[k,]$train         <- list(cps_preds_cv_dat[-fold_i,])
  ens_cv_tbl[k,]$test          <- list(cps_preds_cv_dat[ fold_i,])
  ens_cv_tbl[k,]$train_y       <- list(cps_preds_cv_dat[-fold_i,target_var])
  ens_cv_tbl[k,]$test_y        <- list(cps_preds_cv_dat[ fold_i,target_var])
  ens_cv_tbl[k,]$train_index   <- list(setdiff(seq(1:nrow(cps_preds_cv_dat)),fold_i))
  ens_cv_tbl[k,]$test_index    <- list(fold_i)
  ens_cv_tbl[k,]$train_net_id  <- list(cps_preds[-fold_i,"net_id"])
  ens_cv_tbl[k,]$test_net_id   <- list(cps_preds[ fold_i,"net_id"])
}

ens_cv_tbl <- ens_cv_tbl %>%
  mutate(fit   = map(train, rf_fit, formula = "cps_net ~ pred_rf + pred_sarlm"),
         pred  = map2(fit, test, lm_predict),
         # pred  = map(pred, round),
         mdl_nam = "Meta-Model") %>% 
  score_model()

cat("Test Set MAE:",mean(ens_cv_tbl$MAE),"\n")
cat("Test Set logdev:",mean(ens_cv_tbl$logdev),"\n")
```

```{r META_MODEL_FIT_plot}
META_MODEL_FIT_plot <- plot_fold_pred(ens_cv_tbl$pred, ens_cv_tbl$test_y, type = "fit") +
  labs(x = "Observed Maltreatment Counts",
       y = "Predicted Maltreatment Counts",
       title = "Predicted vs. observed maltreatment counts",
       caption = "Figure 1.7") +
  plotTheme() +
  theme(panel.border = element_blank())
```

```{r join_meta_model_predictions}
ens_pred_dat <- ens_cv_tbl %>% 
  unnest(pred) %>% 
  mutate(test_y = ens_cv_tbl %>% unnest(test_y) %>% pull(test_y),
         test_net_id = ens_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id)) 

ens_pred_geoplot <- model_pred_geoplot(ens_pred_dat$pred, 
                                       ens_pred_dat$test_y, 
                                       ens_pred_dat$test_net_id,
                                       net_Richmond, cps_base_map, 
                                       "Meta-Model")
cps_preds2 <- cps_preds %>% 
  left_join(., dplyr::select(ens_pred_dat, 
                             net_id = test_net_id,
                             pred_ens = pred) %>% 
              mutate(pred_ens = round(pred_ens,2)), by = "net_id") 
```

```{r PREDICTION_MAP_plots}
POISSON_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(po_pred_geoplot[[2]] + 
                                                          labs(title = "Poisson Regression",
                                                               subtitle = "Predicted Maltreatment Count") +
                                                          mapTheme() + 
                                                          theme(panel.border = element_blank()), 
                                                        po_pred_geoplot[[1]] + 
                                                          labs(subtitle = "MAE") +
                                                          scale_fill_viridis_d(name = "MAE") +
                                                          mapTheme() +
                                                          theme(panel.border = element_blank()), 
                                                        align = "h")
RF_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(rf_pred_geoplot[[2]] + 
                                                     labs(title = "Random Forest",
                                                          subtitle = "Predicted Maltreatment Count") +
                                                     mapTheme() + 
                                                     theme(panel.border = element_blank()), 
                                                   rf_pred_geoplot[[1]] + 
                                                     labs(subtitle = "MAE") +
                                                     scale_fill_viridis_d(name = "MAE") +
                                                     mapTheme() + 
                                                     theme(panel.border = element_blank()), 
                                                   align = "h")
SARLM_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(sarlm_pred_geoplot[[2]] + 
                                                        labs(title = "Spatial Durbin Model",
                                                             subtitle = "Predicted Maltreatment Count") +
                                                        mapTheme() + 
                                                        theme(panel.border = element_blank()), 
                                                      sarlm_pred_geoplot[[1]] + 
                                                        labs(subtitle = "MAE") +
                                                        scale_fill_viridis_d(name = "MAE") +
                                                        mapTheme() + 
                                                        theme(panel.border = element_blank()), 
                                                      align = "h")
META_MODEL_PREDICTION_MAP_plot <- cowplot::plot_grid(ens_pred_geoplot[[2]] + 
                                                       labs(title = "Meta-Model",
                                                            subtitle = "Predicted Maltreatment Count",
                                                            caption = "Figure 6.2") +
                                                       mapTheme() + 
                                                       theme(panel.border = element_blank()), 
                                                     ens_pred_geoplot[[1]] + 
                                                       labs(subtitle = "MAE") +
                                                       scale_fill_viridis_d(name = "MAE") +
                                                       mapTheme() + 
                                                       theme(panel.border = element_blank()), 
                                                     align = "h")
```

```{r model_error_by_decile}
models <- bind_rows(rf_cv_tbl, spat_durbin_tbl, ens_cv_tbl, po_cv_tbl)

CV_preds_long <- models %>%
  group_by(mdl_nam) %>%
  unnest(pred, test_y) 

## map over all quantiles to get error metrics
quantile_errors <- CV_preds_long %>%
  nest(-mdl_nam) %>%
  mutate(q      = list(seq(0,1,0.01)),
         pred   = map(data, "pred"),
         test_y = map(data, "test_y")) %>%
  dplyr::select(-data) %>%
  unnest(q, .preserve = c(pred, test_y)) %>%
  filter(q != 0) %>% 
  mutate(q_dat  = pmap(list(pred, test_y, q), quantile_error),
         q_pred = map(q_dat, "pred"),
         q_obs  = map(q_dat, "obs"),
         q_RMSE = map2_dbl(q_pred, q_obs, rmse),
         q_MAE  = map2_dbl(q_pred, q_obs, mae),
         q_logdev  = map2_dbl(q_pred, q_obs, logdev_p),
         y_max  = quantile(seq(0,max(dat$cps_net)), q),
         q_cnt  = nrow(og_dat) - map_int(q_dat, nrow))

q_error_plotdat <- quantile_errors %>%
  dplyr::select(mdl_nam, q, q_RMSE, q_MAE, q_logdev)
q_cnt_plotdat <- quantile_errors %>% 
  dplyr::select(mdl_nam, q, y_max, q_cnt) %>% 
  filter(q != 0) %>%
  mutate(q_pcnt = (q_cnt / nrow(og_dat)))
q_error_mean <- q_error_plotdat %>%
  group_by(mdl_nam) %>%
  summarise(mean_RMSE = mean(q_RMSE, na.rm = TRUE),
            mean_MAE  = mean(q_MAE, na.rm = TRUE),
            mean_logdev  = mean(q_logdev, na.rm = TRUE)) %>%
  arrange(desc(mean_logdev))
print(q_error_mean)
```

```{r ERROR_DECILE_plots}
LOGDEV_MODEL_ERROR_BY_DECILE_plot <- ggplot(data = q_error_plotdat, aes(x=q, y=q_logdev, group = mdl_nam, color = factor(mdl_nam))) +
  geom_line(size = 1) +
  scale_color_viridis_d(name = "Model") +
  scale_y_continuous(limits=c(0,1)) +
  labs(y = "Logarithmic Score",
       caption = "Figure 6.2 - Goodness of fit by decile") +
  plotTheme() +
  theme(legend.position = "none")

MAE_MODEL_ERROR_BY_DECILE_plot <- ggplot(data = q_error_plotdat, aes(x=q, y=q_MAE, group = mdl_nam, color = factor(mdl_nam))) +
  geom_line(size = 1) +
  scale_color_viridis_d(name = "Model") +
  labs(y = "MAE") +
  plotTheme()  +
  theme(legend.position = "none")

COUNT_BY_DECILE_plot <- ggplot(data = q_cnt_plotdat, 
                               aes(x=q, y=q_cnt, group = mdl_nam, color = factor(mdl_nam))) +
  geom_line(size = 1) +
  scale_x_continuous(breaks=seq(0,1,0.1), labels = seq(0,1,0.1)) +
  scale_color_viridis_d(name = "Model") +
  labs(y = "Number of Predictions in Each Decile",
       x = "Decile") +
  plotTheme()  +
  theme(legend.position = "none")


legend <- get_legend(LOGDEV_MODEL_ERROR_BY_DECILE_plot + plotTheme() + theme(legend.position = "right"))
```

```{r Model_Error_Results_table}
model_results <- models %>%
  dplyr::select("Model Name" = mdl_nam, R2, RMSE, MAE, logdev) %>%
  group_by(`Model Name`) %>%
  arrange(`Model Name`) %>%
  summarise(R2_mean      = mean(R2, na.rm=TRUE),
            R2_sd        = sd(R2, na.rm=TRUE),
            MAE_mean     = mean(MAE, na.rm=TRUE),
            MAE_sd       = sd(MAE, na.rm=TRUE),
            RMSE_mean    = mean(RMSE, na.rm=TRUE),
            RMSE_sd      = sd(RMSE, na.rm=TRUE),
            logdev_mean  = mean(logdev, na.rm=TRUE),
            logdev_sd    = sd(logdev, na.rm=TRUE)) 
Model_Error_Results_table <- model_results %>%
  kable(., format = "html", digits = 3) %>%
  kable_styling()

meta_log_mean <- model_results[which(model_results$`Model Name` == "Meta-Model"),"logdev_mean",drop=TRUE]
meta_log_sd <- model_results[which(model_results$`Model Name` == "Meta-Model"),"logdev_sd",drop=TRUE]
meta_log_error <- qnorm(0.975)*meta_log_sd/sqrt(nrow(ens_cv_tbl))
meta_log_error_lower <- round(meta_log_mean - meta_log_error,3)
meta_log_error_upper <- round(meta_log_mean + meta_log_error,3)

meta_MAE_mean <- model_results[which(model_results$`Model Name` == "Meta-Model"),"MAE_mean",drop=TRUE]
meta_MAE_sd <- model_results[which(model_results$`Model Name` == "Meta-Model"),"MAE_sd",drop=TRUE]
meta_MAE_error <- qnorm(0.975)*meta_MAE_sd/sqrt(nrow(ens_cv_tbl))
meta_MAE_error_lower <- round(meta_MAE_mean - meta_MAE_error,3)
meta_MAE_error_upper <- round(meta_MAE_mean + meta_MAE_error,3)
```

```{r aggregate_model_errors_to_neighborhood}
error_geoplot <-  net_Richmond %>%
  left_join(., ens_pred_dat, by = c("net_id" = "test_net_id"),
            feature_name = paste0("Meta-Model", "dev")) %>%
  score_model() %>%
  mutate(dev_p_inv = 1 - logdev) %>% 
  make_cuts(., "logdev", cuts = "breaks", n_breaks = 5)

# error metrics to points
error_points <- st_centroid(error_geoplot) %>%
  dplyr::select(logdev, MAE, test_y)

# aggreate mean errors to neighborhoods
neighborhood_metric_logdev <- error_points %>%
  aggregate(., nbr, mean) %>%
  dplyr::select(logdev) %>% 
  make_cuts(., "logdev")

neighborhood_metric_MAE<- error_points %>%
  aggregate(., nbr, mean) %>%
  dplyr::select(MAE) %>% 
  mutate(MAE = round(MAE,2)) %>% 
  make_cuts(., "MAE")
```

```{r MODEL_ERROR_BY_NEIGHBORHOOD_plots}
LOGDEV_BY_NEIGHBORHOOD_plot <- make_fishnet_dist_plot(neighborhood_metric_logdev, cps_base_map, legend = "right", 
                                                      direction = 1, var_name = "Deviance", 
                                                      title = "Out-of-Fold error by neighborhood") + 
  labs(caption = "Figure 6.3",
       subtitle = "Logarithmic score") +
  mapTheme()

MAE_BY_NEIGHBORHOOD_plot <- make_fishnet_dist_plot(neighborhood_metric_MAE, cps_base_map, legend = "right", 
                                                   direction = 1, var_name = "MAE") +
  labs(subtitle = "MAE") +
  mapTheme()
```

```{r statistical_area_download}
#Below we calculate poverty and nonWhite rates by neighborhood by converting tracts to centroids and spatial joining with 
#neighbothoods statistical areas. 

#get statarea
nbr_statAreas <- read_sf("https://data.richmondgov.com/resource/8kyq-v9j2.geojson") %>%
  st_transform(crs = 102747) %>% 
  mutate(stat_area_id = id)
```

```{r ACS_data_download}
#download poverty and population data
tract10 <- get_acs(geography = "tract", variables = c("B02001_001","B02001_002E","B17001_002"), 
                   year = 2010, state=51, county=760, geometry=T)
```

```{r ACS_Rates}
tract10 <- tract10 %>%
  dplyr::select(variable,estimate) %>%
  as.data.frame() %>%
  spread(variable,estimate) %>%
  rename(TotalPop=B02001_001,
         NumberWhites=B02001_002,
         TotalPoverty=B17001_002) %>%
  mutate(percentNonWhite = ifelse(TotalPop > 0, ((TotalPop - NumberWhites) / TotalPop),0),
         percentPoverty  = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
         tract_id        = row_number()) %>%
  st_sf() %>%
  st_transform(102747) 
tract10$tract_area <- st_area(tract10)
```

```{r census_statistical_area_spatial_intersection}
#do the spatial join, create poverty and non whites rates by district. Create a dummy for rates >= stat_area_quantile percentile
# create intersection of tract10 and statareas
nbr_statAreas.intersect <- st_intersection(tract10, nbr_statAreas)
# get % tract in statares and mulitply by pop totals from each tract
# result is the total tract pops distributed to the statarea by % of tract in statare
nbr_statAreas.spJoin <- nbr_statAreas.intersect %>% 
  mutate(intersect_area = st_area(nbr_statAreas.intersect)) %>% 
  # get % of tract and multiply totals by percent area of tract in statarea
  group_by(tract_id) %>% 
  mutate(intersect_pcnt_of_tract = as.numeric(intersect_area) / as.numeric(tract_area),
         intersect_TotalPop = round(TotalPop * intersect_pcnt_of_tract, 1),
         intersect_NumberWhites = round(NumberWhites * intersect_pcnt_of_tract, 1),
         intersect_TotalPoverty = round(TotalPoverty * intersect_pcnt_of_tract, 1)) %>%
  ungroup() %>% 
  # sum the fraction of pop totals up to statarea
  group_by(stat_area_id) %>%
  summarise(statarea_TotalPop = sum(intersect_TotalPop),
            statarea_NumberWhites = sum(intersect_NumberWhites),
            statarea_TotalPoverty = sum(intersect_TotalPoverty)) %>% 
  # make quantites of interest
  mutate(percentNonWhite = ifelse(statarea_TotalPop > 0, 
                                  ((statarea_TotalPop - statarea_NumberWhites) / statarea_TotalPop),0),
         percentPoverty = ifelse(statarea_TotalPop > 0, 
                                 statarea_TotalPoverty / statarea_TotalPop, 0))

# classify by quantile and make dummy variable
nbr_statAreas.spJoin <- nbr_statAreas.spJoin %>% 
  mutate(poverty.percentile = ifelse(percentPoverty >=
                                       quantile(nbr_statAreas.spJoin$percentPoverty, 
                                                p = stat_area_quantile, na.rm=T),"1",0),
         nonWhite.percentile = ifelse(percentNonWhite >=
                                        quantile(nbr_statAreas.spJoin$percentNonWhite, 
                                                 p = stat_area_quantile, na.rm=T),1,0))
```

```{r STAT_AREA_CATEGORY_plot}
STAT_AREA_CATEGORY_plot <- nbr_statAreas.spJoin %>%
  dplyr::select(poverty.percentile,nonWhite.percentile) %>%
  gather(var,val,-geometry) %>%
  ggplot() +
  geom_sf(aes(fill=factor(val))) +
  facet_wrap(~var) +
  theme_bw()
```

```{r aggregate_model_area_to_statistical_area}
# aggreate mean errors to statareas
stat_area_metric_logdev <- error_points %>%
  aggregate(., nbr_statAreas.spJoin, mean) %>%
  dplyr::select(logdev) %>% 
  mutate(logdev = round(logdev, 3)) %>% 
  make_cuts(., "logdev")
stat_area_metric_MAE<- error_points %>%
  aggregate(., nbr_statAreas.spJoin, mean) %>%
  dplyr::select(MAE) %>% 
  mutate(MAE = round(MAE, 3)) %>% 
  make_cuts(., "MAE")

# aggregate sum of CPS incidents to statarea
stat_area_cps <- error_points %>%
  aggregate(., nbr_statAreas.spJoin, sum) %>%
  dplyr::select(test_y)
stat_area_errors <- stat_area_metric_logdev %>% 
  st_join(., stat_area_metric_MAE, join = st_equals) %>% 
  st_join(., stat_area_cps, join = st_equals) %>% 
  st_join(., nbr_statAreas.spJoin, join = st_equals)

# group by poverty and get median of statarea aggregate errors
poverty_aggregate <- stat_area_errors %>% 
  group_by(poverty.percentile) %>% 
  summarise(med_dev = round(median(logdev),3),
            med_MAE = round(median(MAE),3),
            med_CPS = sum(test_y)) %>% 
  st_drop_geometry() %>% 
  dplyr::select(poverty.percentile, med_dev, med_MAE, med_CPS)

# group by nonwhite and get median of statarea aggregate errors
nonwhite_aggregate <- stat_area_errors %>% 
  group_by(nonWhite.percentile) %>% 
  summarise(med_dev = round(median(logdev),3),
            med_MAE = round(median(MAE),3),
            med_CPS = sum(test_y)) %>% 
  st_drop_geometry() %>% 
  dplyr::select(nonWhite.percentile, med_dev, med_MAE, med_CPS)

print(poverty_aggregate)
print(nonwhite_aggregate)
```

```{r STATISTICAL_AREA_MODEL_ERROR_plot}
logdev_stat_area_plot <- make_fishnet_dist_plot(stat_area_metric_logdev, cps_base_map, 
                                                legend = "right", 
                                                direction = -1, var_name = "Deviance",
                                                title = "Out-of-Fold-Error by Statistical Area")

MAE_stat_area_plot <- make_fishnet_dist_plot(stat_area_metric_MAE, cps_base_map, 
                                             legend = "right", 
                                             direction = 1, var_name = "MAE",
                                             title = "Out-of-Fold-Error by Statistical Area")
STATISTICAL_AREA_MODEL_ERROR_plot <- cowplot::plot_grid(logdev_stat_area_plot , MAE_stat_area_plot, 
                                                        align = "h", labels = "Out-of-Fold Error by Statistical Area")
```

```{r prediction_to_bin_class}
error_geoplot$pred_bin_class <- bin_class(error_geoplot, "pred")

p.summ <- error_geoplot %>%
  group_by(pred_bin_class) %>%
  dplyr::summarize(obs.total = sum(test_y),
                   obs.cnt = n()) %>% 
  rename(sens_group = pred_bin_class) %>%
  filter(!is.na(sens_group)) %>%
  identity()
```

```{r compute_KDE}
cps_ppp <- as.ppp(st_coordinates(cps_dissolve), W = st_bbox(net_Richmond))
cps_KDE <- spatstat::density.ppp(cps_ppp)

cps_KDE_tbl <- as.data.frame(cps_KDE) %>%
  st_as_sf(coords = c("x", "y"), crs = 102747) %>%
  aggregate(., net_Richmond, mean) %>%
  mutate(net_id = net_Richmond$net_id)
```

```{r KDE_to_bin_class}
if(all.equal(error_geoplot$net_id, cps_KDE_tbl$net_id)){
  cat("Good to go!")
} else {
  cat("Join will be an error, Net_id index does not match")
}

error_geoplot$kde_bin_class  <- bin_class(cps_KDE_tbl, "value")

kde.summ <- error_geoplot %>%
  group_by(kde_bin_class) %>%
  dplyr::summarize(kde.total = sum(test_y),
                   kde.cnt = n()) %>% 
  rename(sens_group = kde_bin_class) %>%
  filter(!is.na(sens_group)) %>%
  identity()
```

```{r REALTIVE_SENSITIVITY_plot}
REALTIVE_SENSITIVITY_KDE <- ggmap(cps_base_map) +
  geom_sf(data = ll(kde.summ), aes(fill = factor(sens_group)), 
          color = NA, alpha = 0.85, inherit.aes = FALSE) +
  geom_sf(data = ll(cps_dissolve), inherit.aes = FALSE, size = 1) +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1,
                       name = "Risk\nCategory") +
  labs(title = "Risk categories from KDE",
       caption = "Figure 6.4") +
  mapTheme()

REALTIVE_SENSITIVITY_PREDICTIONS <- ggmap(cps_base_map) +
  geom_sf(data = ll(p.summ), aes(fill = factor(sens_group)), 
          color = NA, alpha = 0.85, inherit.aes = FALSE) +
  geom_sf(data = ll(cps_dissolve), inherit.aes = FALSE, size = 1) +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1,
                       name = "Risk\nCategory") +
  labs(title = "Risk categories from meta-model",
       caption = "Figure 1.5") +
  mapTheme()
```

```{r REALTIVE_RISK_BARPLOT_COMPARE_plot}
countComparisons <- merge(st_drop_geometry(p.summ), st_drop_geometry(kde.summ)) %>%
  mutate_if(is.double, round, 3) %>% 
  mutate(Category = rev(c("90% - 100%", "70% - 89%", "50% - 69%", 
                          "30% - 49%", "1% - 29%"))) %>%
  dplyr::mutate(kernelPct = round(kde.total / sum(kde.total),4),
                fittedPct = round(obs.total / sum(obs.total), 4))

countComparisonsLong <- countComparisons %>% 
  gather(Variable, Value, kernelPct:fittedPct)

REALTIVE_RISK_BARPLOT_COMPARE_plot <- ggplot(data=countComparisonsLong, aes(Category,Value)) +
  geom_bar(aes(fill = Variable), position = "dodge", stat="identity", color = NA) +
  scale_fill_viridis_d(name = " ",
                       labels=c("Meta-model", "Kernel Density")) +
  labs(x= "Predicted Risk Levels",
       y="Percent of Test Set Cases",
       title= "Goodness of fit: Spatial risk model vs. Kernel Density",
       caption = "Figure 1.6") +
  plotTheme() +
  theme(axis.line = element_blank())
```

```{r alignPhase}
##In this section change "sensitivty class" to "risk category"

#the final prediction map
predMap <- 
  error_geoplot #%>%
#st_transform(102747)
#removals
removals <- 
  read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/removals.csv") %>%
  st_as_sf(coords = c("X", "Y"), crs = 102747, agr = "constant")
#service visits
visits <- 
  read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/healthFamilyServices.csv") %>%
  filter(!is.na(X)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
  st_transform(102747) %>%
  #some are outside of the the study area, so select by those that itersect
  .[st_union(predMap),]
#SCAN data - 'stop child abuse now' network centers. geocode. There are only 27 in the study area
scan <- read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/scanPreventionResources.csv") %>%
  mutate(Street.Address = as.character(Street.Address))  %>%
  mutate(Street.Address = paste(Street.Address, "Richmond, Va."))
scan <-
  scan %>%
  bind_cols(scan,geocode(scan$Street.Address, source="dsk")) %>%
  filter(!is.na(lon)) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
  st_transform(102747) %>%
  .[st_union(predMap),]

#7.1 - population per risk category
popID <- ALL_FEATURES %>% 
  dplyr::select(net_id, net_pop) %>% 
  as.data.frame()

binID <- error_geoplot %>% 
  dplyr::select(net_id, pred_bin_class) %>% 
  as.data.frame()

popBin <- left_join(popID, binID, by = "net_id") %>% 
  group_by(pred_bin_class) %>% 
  summarise(sumPop = sum(net_pop)) %>%
  mutate(pctPop = sumPop/sum(sumPop),
         Category = rev(c("90% - 100%", "70% - 89%", "50% - 69%", 
                          "30% - 49%", "1% - 29%")))

popPerRiskPlot <- ggplot(data=popBin, aes(Category, sumPop)) +
  geom_bar(position = "dodge", stat="identity") +
  labs(x= "Predicted Risk Levels",
       y= "Number of People",
       title = "Population per risk category",
       caption = "Figure 2.1") +
  plotTheme()

#7.2 - poverty rate correlation with predicted maltreatment count
#take the net id and geometry for the fishnet 
geom_fishnet <- error_geoplot %>% 
  dplyr::select(net_id, geometry)

#get population and poverty info at tract level
poverty_tract <- tract10 %>% 
  dplyr::select(TotalPoverty, tract_id, geometry) %>% 
  mutate(tract_acre = as.numeric(st_area(.)*2.29568e-5),
         pov_acre_rate = TotalPoverty/tract_acre)

population_tract <- tract10 %>% 
  dplyr::select(TotalPop, tract_id, geometry) %>% 
  mutate(tract_acre = as.numeric(st_area(.)*2.29568e-5),
         pop_acre_rate = TotalPop/tract_acre)

#intersect tract poverty and fishnet
pov_tracts_intersect <- st_intersection(poverty_tract, geom_fishnet)

pov_tracts_intersect <- pov_tracts_intersect %>%
  mutate(int_area_acres = as.numeric(st_area(pov_tracts_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = int_area_acres/tract_acre,
         int_pov =TotalPoverty * pcnt_of_block) %>%
  arrange(net_id)

fishnet_poverty <- pov_tracts_intersect %>% # xcc
  group_by(net_id) %>%
  summarise(net_pov = sum(int_pov)) %>% 
  as.data.frame()

#intersect tract population and fishnet
pop_tracts_intersect <- st_intersection(population_tract, geom_fishnet)

pop_tracts_intersect <- pop_tracts_intersect %>%
  mutate(int_area_acres = as.numeric(st_area(pop_tracts_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = int_area_acres/tract_acre,
         int_pop =TotalPop * pcnt_of_block) %>%
  arrange(net_id)

fishnet_population <- pop_tracts_intersect %>% # xcc
  group_by(net_id) %>%
  summarise(net_pop = sum(int_pop)) %>% 
  as.data.frame()

pov_pop_fishnet <- left_join(fishnet_poverty, fishnet_population, by = "net_id") %>% 
  mutate(povRate = net_pov/net_pop) %>% 
  dplyr::select(-geometry.x) %>% 
  rename(geometry = geometry.y) %>% 
  st_sf() %>% 
  st_transform(102747)

#map it:
povertyRateMap <- ggmap(cps_base_map) +
  geom_sf(data=ll(pov_pop_fishnet), aes(fill=factor(ntile(povRate, 5))), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  scale_fill_viridis_d(labels = as.character(round(quantile(pov_pop_fishnet$povRate,
                                                            c(.1,.2,.4,.6,.8),na.rm=T), 4)),
                       name="Poverty\nRate") +
  labs(title = "Weighted poverty rate",
       caption = "Figure 2.2") +
  mapTheme()

pov_pop_fishnet_pred <- left_join(pov_pop_fishnet, error_geoplot %>% 
                                    dplyr::select(net_id, pred) %>% 
                                    #mutate(pred = round(pred)) %>% 
                                    as.data.frame(), by = "net_id") %>% 
  filter(pred > 0)

povRatePredPlot <- ggplot(pov_pop_fishnet_pred, aes(x=povRate, y=pred)) + 
  geom_point() +
  labs(x = "Poverty Rate",
       y = "Predicted\nMaltreatment Counts",
       title = "Relationship between predicted maltreatment counts\nand poverty rate",
       caption = "Figure 2.3") +
  plotTheme()

#7.3 - map of risk categoeries with removals overlayed
removalsMap <-
  ggmap(cps_base_map) +
  geom_sf(data=ll(predMap), aes(fill=factor(pred_bin_class)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(removals),aes(colour="Removals"),colour="red", inherit.aes = FALSE, size = 1) +
  scale_fill_viridis_d(name = "Risk\nCategory") +
  labs(title="Predicted risk levels and removals",
       subtitle="Removals in red",
       caption = "Figure 2.4") +
  mapTheme()

#7.4 - count of removals by risk categoery
removalsPlot <-
  removals %>%
  mutate(counter=1) %>%
  aggregate(predMap,FUN=length) %>%
  dplyr::select(counter) %>%
  mutate(counter = ifelse(is.na(counter),0,counter)) %>%
  bind_cols(predMap) %>%
  mutate(Category = case_when(pred_bin_class == 1 ~ "1% - 29%",
                              pred_bin_class == 2 ~ "30% - 49%%",
                              pred_bin_class == 3 ~ "50% - 69%",
                              pred_bin_class == 4 ~ "70% - 89%",
                              pred_bin_class == 5 ~ "90% - 100%")) %>%
  group_by(Category) %>%
  dplyr::summarize(percentCount = sum(counter)/nrow(removals)) %>%
  ggplot(aes(Category,percentCount)) +
  geom_bar(position = "dodge", stat="identity") +
  labs(x= "Predicted Risk Levels",
       y="Percent of Removals",
       title= "Percent of removals by risk category",
       caption = "Figure 2.5") +
  plotTheme()

#7.4 - map of protective land uses by type
#add the data
protectiveAlign <- 
  read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/protective_align.csv") %>%
  st_as_sf(coords = c("x", "y"), crs = 102747, agr = "constant") %>%
  .[st_union(predMap),]

#map 
protectiveUsesByType <- ggmap(cps_base_map) +
  geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.6, color = NA) +
  geom_sf(data=ll(protectiveAlign), aes(colour=use), inherit.aes = FALSE) +
  scale_colour_viridis_d(name="Protective\nuses",
                         label = c("Church", "Community Center", "Fire Station", "Homeless Shelter",
                                   "Library", "Oasis", "Police Station", "School")) +
  labs(title="Protective land uses",
       caption = "Figure 2.7") +
  mapTheme()

#7.5 mea predictive count by quarter
protectiveAlign.buffers <-
  st_centroid(predMap) %>%
  aggregate(st_buffer(protectiveAlign,1320),FUN=mean) 

#map average predicted event by quarter mile buffer
quarterMileBuffer_protective <-
  ggmap(cps_base_map) +
  geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(protectiveAlign.buffers), aes(fill=pred), inherit.aes = FALSE) +
  scale_fill_viridis_c(name = "Mean\npredicted\ncount") +
  labs(title = "Mean predicted count by quarter mile buffer",
       subtitle = "Protective uses",
       caption = "Figure 2.8") +
  guides(fill = guide_colourbar(reverse = TRUE)) +
  mapTheme()

#table of top protective places
protectiveTable <- 
  protectiveAlign.buffers %>%
  bind_cols(protectiveAlign) %>%
  group_by(use) %>%
  top_n(n=3,wt=pred) %>%
  as.data.frame() %>%
  mutate(Mean_Predicted_Count = round(pred)) %>%
  dplyr::select(use,name,address,Mean_Predicted_Count) %>%
  arrange(use,-Mean_Predicted_Count) %>%
  kable() %>% 
  kable_styling()

#7.6 - visits as a function of risk levels
homeVisits <-
  ggmap(cps_base_map) +
  geom_sf(data=ll(predMap), aes(fill=factor(pred_bin_class)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(visits), inherit.aes = FALSE, colour="red") +
  scale_fill_viridis_d(name = "Risk\nCategory") +
  labs(title="Predicted risk levels and home visits",
       subtitle="Home visits in red",
       caption = "Figure 2.12") +
  mapTheme()

#7.7 visits by risk category
vistsCategory <-
  visits %>%
  mutate(counter=1) %>%
  aggregate(predMap,FUN=length) %>%
  dplyr::select(counter) %>%
  mutate(counter = ifelse(is.na(counter),0,counter)) %>%
  bind_cols(predMap) %>%
  mutate(Category = case_when(pred_bin_class == 1 ~ "1% - 29%",
                              pred_bin_class == 2 ~ "30% - 49%%",
                              pred_bin_class == 3 ~ "50% - 69%",
                              pred_bin_class == 4 ~ "70% - 89%",
                              pred_bin_class == 5 ~ "90% - 100%")) %>%
  group_by(Category) %>%
  dplyr::summarize(percentCount = sum(counter)/nrow(visits)) %>%
  ggplot(aes(Category,percentCount)) +
  geom_bar(position = "dodge", stat="identity") +
  labs(x= "Predicted Risk Levels",
       y="Percent of Visits",
       title= "Percent of visits by risk category") +
  plotTheme()

#7.8 scan centers
scanCenters <-
  ggmap(cps_base_map) +
  geom_sf(data=ll(predMap), aes(fill=factor(pred_bin_class)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(scan),inherit.aes = FALSE, colour="red") +
  scale_fill_viridis_d(name = "Risk\nCategory") +
  labs(title="Predicted risk levels and SCAN Centers",
       subtitle="SCAN Centers in red",
       caption = "Figure 2.13") +
  mapTheme()

#7.9 scan buffers and risk
scan.buffers <-
  st_centroid(predMap) %>%
  aggregate(st_buffer(scan,1320),FUN=mean) 

#map average predicted event by quarter mile buffer
scanMap <-
  ggmap(cps_base_map) +
  geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(scan.buffers), aes(fill=pred), inherit.aes = FALSE) +
  scale_fill_viridis_c(name = "Mean\npredicted\ncount") +
  labs(title = "Mean predicted count by quarter mile buffer",
       subtitle = "SCAN Centers",
       caption = "Figure 2.14") +
  guides(fill = guide_colourbar(reverse = TRUE)) +
  mapTheme()

#find top 3 Scan centers
scan.buffers %>%
  bind_cols(scan) %>%
  top_n(n=3,wt=pred) %>%
  as.data.frame() %>%
  mutate(Mean_Predicted_Count = round(pred)) %>%
  dplyr::select(SCAN.s.Trauma.Informed.Community.Network..TICN.,Street.Address,Mean_Predicted_Count) %>%
  arrange(-Mean_Predicted_Count) %>%
  kable()

#Gap
#get neighborhoods
nbr_statAreas <- read_sf("https://data.richmondgov.com/resource/8kyq-v9j2.geojson") %>%
  st_sf() %>%
  st_transform(102747) %>%
  #calculate area
  mutate(area.sq_miles = as.numeric(st_area(.) * 3.58701e-8))

#create a dummy variable field for where risk category == 5
predMap$is5th <- ifelse(predMap$pred_bin_class == 5,1,0)
#count 5th risk quintile per neighborhood
nbr_statAreas.demand <-
  st_centroid(predMap) %>%
  dplyr::select(is5th,geometry) %>%
  aggregate(nbr_statAreas,FUN=sum) %>%
  bind_cols(
    st_centroid(predMap) %>%
      mutate(counter=1) %>%
      dplyr::select(counter,geometry) %>%  
      aggregate(nbr_statAreas,FUN=sum)) %>%
  mutate(relativeRisk = ntile((is5th / counter), 100))

#calculate number of protective centers within 
nbr_statAreas.supply <-
  protectiveAlign %>%
  mutate(counter= 1) %>%
  dplyr::select(counter,geometry) %>%
  aggregate(nbr_statAreas,FUN=sum) %>%
  bind_cols(nbr_statAreas) %>%
  dplyr::select(counter,geometry,area.sq_miles) %>%
  mutate(relativeProtective = ntile((counter/area.sq_miles),100))

#put demand and supply together and look at difference
nbr_statAreas.gap <-
  bind_cols(nbr_statAreas.demand, nbr_statAreas.supply) %>%
  mutate(gap = relativeProtective - relativeRisk)

#map average predicted event by neighborhoods
bl <- colorRampPalette(c("green2","green3","green4"))(200)                      
re <- colorRampPalette(c("darkred", "red3","red1"))(200)

gapMap <-
  ggmap(cps_base_map) +
  geom_sf(data=ll(nbr_statAreas.gap), aes(fill=gap), inherit.aes = FALSE,alpha = 0.8) +
  scale_fill_gradientn(colours=c(re,"green2", bl),
                       limits = c(-100,100),
                       breaks = c(-100,100),
                       labels = c("More risk\nthan protection","More protection\nthan risk")) +
  labs(title = "Gap analysis:\nComparing relative risk to protective resources",
       subtitle = "By Neighborhood Statistical Area",
       caption = "Figure 1.8") +
  mapTheme() +
  theme(legend.position = 'bottom',
        legend.title=element_blank(),
        legend.text=element_text(size=10, face = "bold"),
        legend.justification = "center") +
  guides(fill= guide_colorbar(barwidth=15,barheight=2))
```

```{r childRiskAreas}
child_tract10 <- get_acs(geography = "tract", variables = c("B01001_003E", "B01001_004E", "B01001_005E", "B01001_006E",
                                                            "B01001_027E", "B01001_028E", "B01001_029E", "B01001_030E"), 
                         year = 2010, state=51, county=760, geometry=T) %>%
  dplyr::select(variable,estimate) %>%
  as.data.frame() %>%
  spread(variable,estimate) %>%
  rename(MU5=B01001_003,
         M5_9=B01001_004,
         M10_14=B01001_005,
         M15_17 = B01001_006,
         FU5=B01001_027,
         F5_9=B01001_028,
         F10_14=B01001_029,
         F15_17 = B01001_030) %>%
  mutate(sum_U18 = (MU5 + M5_9 + M10_14 + M15_17 + FU5 + F5_9 + F10_14 + F15_17),   #39600
         tract_id = row_number()) %>%
  st_sf() %>%
  st_transform(102747) 

child_tract10 <- child_tract10 %>% 
  mutate(area = st_area(child_tract10))

children_tract <- child_tract10 %>% 
  dplyr::select(sum_U18, tract_id, geometry) %>% 
  mutate(tract_acre = as.numeric(st_area(.)*2.29568e-5),
         pop_acre_rate = sum_U18/tract_acre)


#intersect with fishnet
child_tracts_intersect <- st_intersection(children_tract, geom_fishnet)

child_tracts_intersect <- child_tracts_intersect %>% 
  mutate(int_area_acres = as.numeric(st_area(child_tracts_intersect)*2.29568e-5)) %>%
  group_by(net_id) %>%
  mutate(cnt = n(),
         pcnt_of_block = int_area_acres/tract_acre,
         int_child = sum_U18 * pcnt_of_block) %>%
  arrange(net_id)

fishnet_children <- child_tracts_intersect  %>%
  group_by(net_id) %>%
  summarise(net_child = sum(int_child)) %>%    #39599.9
  as.data.frame()


childBin <- left_join(binID, fishnet_children, by = "net_id") %>% 
  filter(net_child != "NA") %>% 
  group_by(pred_bin_class) %>% 
  summarise(count = n(),
            sumChild = sum(net_child)) %>%     #39599.9
  mutate(pctChild = sumChild/sum(sumChild),
         Category = rev(c("90% - 100%", "70% - 89%", "50% - 69%", 
                          "30% - 49%", "1% - 29%")))
```

```{r CPSCOUNT_by_nbr}
nbr_CPSCount <- st_join(fishnet_pop_cps, nbr, largest = TRUE) %>% 
  dplyr::select(name, geometry, net_CPS_Accepted, net_id) %>% 
  group_by(name) %>% 
  summarise(count = sum(net_CPS_Accepted)) %>% 
  filter(name != "NA")

CPSCOUNT_by_nbr_plot <- ggmap(cps_base_map) +
  geom_sf(data = ll(nbr_CPSCount), aes(fill = factor(ntile(count, 5))), color = NA, alpha = 0.8, inherit.aes = FALSE) +
  scale_fill_viridis_d(labels = as.character(quantile(nbr_CPSCount$count,
                                                      c(.1,.2,.4,.6,.8),na.rm=T)),
                       direction = 1,
                       name="Count\nQuantile\nBreaks") +
  labs(title = "Number of Child Protective Service events\nby neighborhood",
       caption = "Figure 1.1") +
  mapTheme()
```

```{r GLOBAL_MORANS_TEST_MAE}
#matrix of coordinates
nbrCoords <- neighborhood_metric_MAE %>% 
  st_centroid() %>% 
  mutate(X = st_coordinates(.)[,1],
         Y = st_coordinates(.)[,2]) %>% 
  as.data.frame() %>% 
  dplyr::select(X, Y) %>% 
  as.matrix()


#make weights for test - neighborhood level
neighborNbrs <- knn2nb(knearneigh(nbrCoords, 5))
spatialWeights <- nb2listw(neighborNbrs, style="W")

moranTest_MAE <- moran.mc(neighborhood_metric_MAE$MAE, spatialWeights, nsim = 999)
```

```{r childFatality}
deaths <- 
  read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/deaths.csv") %>%
  st_as_sf(coords = c("X", "Y"), crs = 102747, agr = "constant") %>% 
  filter(ChildFatality == "Y")

fatalitiesMap <- ggmap(cps_base_map) +
  geom_sf(data=ll(predMap), aes(fill=factor(pred_bin_class)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(deaths),aes(colour="ChildFatality"),colour="red", inherit.aes = FALSE, size = 1.5) +
  scale_fill_viridis_d(name = "Risk\nCategory") +
  labs(title="Predicted risk levels and child fatalities",
       subtitle="Fatalities in red",
       caption = "Figure 2.6") +
  mapTheme()

fatalitiesPlot <- deaths %>%
  mutate(counter=1) %>%
  aggregate(predMap,FUN=length) %>%
  dplyr::select(counter) %>%
  mutate(counter = ifelse(is.na(counter),0,counter)) %>%
  bind_cols(predMap) %>%
  mutate(Category = case_when(pred_bin_class == 1 ~ "1% - 29%",
                              pred_bin_class == 2 ~ "30% - 49%%",
                              pred_bin_class == 3 ~ "50% - 69%",
                              pred_bin_class == 4 ~ "70% - 89%",
                              pred_bin_class == 5 ~ "90% - 100%")) %>%
  group_by(Category) %>%
  dplyr::summarize(percentCount = sum(counter)/nrow(deaths)) %>%
  ggplot(aes(Category,percentCount)) +
  geom_bar(position = "dodge", stat="identity") +
  labs(x= "Predicted Risk Levels",
       y="Percent of Child Fatalities",
       title= "Percent of child fatalities by risk category") +
  plotTheme()
```

```{r churchesBuffers}
churches <- read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/protective_align.csv") %>%
  st_as_sf(coords = c("x", "y"), crs = 102747, agr = "constant") %>% 
  filter(use == "Church") %>% 
  .[st_union(predMap),]

church.buffers <-
  st_centroid(predMap) %>%
  aggregate(st_buffer(churches,1320),FUN=mean)

#map average predicted event by quarter mile buffer
churchMap <- ggmap(cps_base_map) +
  geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(church.buffers), aes(fill=pred), inherit.aes = FALSE) +
  scale_fill_viridis_c(name = "Mean\npredicted\ncount",
                       labels = round) +
  labs(title = "Mean predicted count by quarter mile buffer",
       subtitle = "Churches and other faith organizations",
       caption = "Figure 2.9") +
  guides(fill = guide_colourbar(reverse = TRUE)) +
  mapTheme()

#find top 3 Scan centers
top_church <- church.buffers %>%
  bind_cols(churches) %>%
  top_n(n=10,wt=pred) %>%
  as.data.frame() %>%
  mutate(Mean_Predicted_Count = round(pred)) %>%
  dplyr::select(name,address,Mean_Predicted_Count) %>%
  arrange(-Mean_Predicted_Count) %>%
  kable() %>% 
  kable_styling()
```

```{r childcareBuffers}
childcare <- st_read("C:/projects/PAP_Virginia/data/z_alignPhase/Richmond_child_providers.shp") %>%
  dplyr::select(Loc_name, Match_addr, Type_Of_Ca, License_Ty) %>% 
  st_transform(102747) %>% 
  .[st_union(predMap),]

resourcehomes <- read.csv("C:/projects/PAP_Virginia/data/z_alignPhase/resourceHomes.csv") %>%
  filter(X != "#NUM!",
         Y != "#NUM!") %>% 
  mutate(X = as.double(as.character(X)),
         Y = as.double(as.character(Y)),
         Type = ifelse(Type%in% c("Emergency Foster Care Home", "FFC/Kinship/Relative", 
                                  "Kinship/Relative Non-Paid", "LCPA Homes", "LDSS Home"), 
                       "Individual", as.character(Type)),
         ResourceName = ifelse(Type == "Individual", "Individual", as.character(ResourceName)),
         Address = ifelse(Type == "Individual", "Redacted (HIPPA)", as.character(Address))) %>%
  st_as_sf(coords = c("X", "Y"), crs = 102747, agr = "constant") %>% 
  .[st_union(predMap),]

childcare.buffers <-
  st_centroid(predMap) %>%
  aggregate(st_buffer(childcare,1320),FUN=mean)

resourcehomes.buffers <-
  st_centroid(predMap) %>%
  aggregate(st_buffer(resourcehomes,1320),FUN=mean) 

#map average predicted event by quarter mile buffer
childcareMap <- ggmap(cps_base_map) +
  geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(childcare.buffers), aes(fill=pred), inherit.aes = FALSE) +
  scale_fill_viridis_c(name = "Mean\npredicted\ncount") +
  labs(title = "Mean predicted count by quarter mile buffer",
       subtitle = "Licensed child care providers",
       caption = "Figure 2.10") +
  guides(fill = guide_colourbar(reverse = TRUE)) +
  mapTheme()

resourcehomeMap <- ggmap(cps_base_map) +
  geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
  geom_sf(data=ll(resourcehomes.buffers), aes(fill=pred), inherit.aes = FALSE) +
  scale_fill_viridis_c(name = "Mean\npredicted\ncount",
                       labels = round) +
  labs(title = "Mean predicted count by quarter mile buffer",
       subtitle = "Locations certified to accept foster care children",
       caption = "Figure 2.11") +
  guides(fill = guide_colourbar(reverse = TRUE)) +
  mapTheme()

#find top 3 
top_childcare <- childcare.buffers %>% 
  bind_cols(childcare) %>%
  group_by(License_Ty) %>%
  top_n(n=3,wt=pred) %>%
  as.data.frame() %>%
  mutate(Mean_Predicted_Count = round(pred)) %>%
  dplyr::select(License_Ty, Match_addr,Mean_Predicted_Count) %>%
  rename(license_type = License_Ty,
         address = Match_addr) %>% 
  arrange(license_type,-Mean_Predicted_Count) %>%
  kable() %>% 
  kable_styling()

top_resourcehomes <- resourcehomes.buffers %>% 
  bind_cols(resourcehomes) %>%
  group_by(Type) %>%
  top_n(n=3,wt=pred) %>%
  as.data.frame() %>%
  mutate(Mean_Predicted_Count = round(pred)) %>%
  dplyr::select(ResourceName,Type,Address,Mean_Predicted_Count) %>%
  rename(type = Type,
         name = ResourceName) %>% 
  arrange(type,-Mean_Predicted_Count) %>%
  kable() %>% 
  kable_styling()
```


##1. Executive Summary

###Motivation

There are approximately 40,000 children in Richmond, VA, and between July 2013 and July 2017 there were 6,500 accepted cases of child maltreatment.[^1] Figure 1.1a shows the count of maltreatment events between 2013 and 2017 by neighborhood. Not all neighborhoods are affected by maltreatment in the same manner, as neighborhoods in the southwest and northeast of Richmond are experiencing much higher counts of Child Protective Service (CPS) events. Can we do a better job ensuring that our limited child welfare resources are properly deployed to the communities where they are needed most?
  
  To understand which communities have the greatest need, we must first determine where child maltreatment is likely to occur. While there are a host of individual, family, and household level factors associated with child maltreatment, research shows that community and social factors play an important role in understanding where maltreatment may occur.[^2] At high densities, externalities associated with these 'neighborhood effects' can influence peers in close proximity.[^3] 

These spillover effects appear as maltreatment event clusters, as visualized in Figure 1.1b, which maps the rate of child maltreatment events in Richmond, VA between 2013 and 2017.[^4] Recent work shows that variation in these spatial clusters can be predicted by environmental factors such as crime, blight, and nuisance land uses like bars and restaurants.[^5]

```{r cache = TRUE,echo=FALSE, warning=FALSE, include = TRUE, fig.width=11.5, fig.height=5}
cowplot::plot_grid(CPSCOUNT_by_nbr_plot, CPS_RATE_BY_FISHNET_PLOT, align = "hv", axis = "lrbt")
```

There are two goals of the work presented here. First, to create a comprehensive open source framework for developing child maltreatment predictive models that can estimate maltreatment risk across Richmond. 

Second, to document a strategic planning process for converting maltreatment risk predictions into actionable intelligence stakeholders can use to efficiently allocate limited child welfare resources. In this 'Align' phase of the framework, we assess the extent to which the current supply of child welfare services is properly distributed relative to the demand for these services.

The intuition for this study is to borrow the observed maltreatment 'experience' in Richmond and test whether those experiences are generalizable to places where maltreatment may occur but is not observed directly. If so, we can confidently forecast maltreatment risk across space using predictive modeling techniques.

###Modeling

The predictive model is based on this notion of spatial externalities, positing that maltreatment risk is a function of exposure to certain environmental factors like crime and blight. Point data describing these environmental phenomena are aggregated to a regular lattice grid and engineered into a set of spatial 'features' from which predictive relationships can be mined. Figure 1.2 provides an example of the feature engineering process, mapping community center locations and recoding these locations so that every grid cell citywide receives three complementary measures of geographic 'exposure'.

```{r message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, include=TRUE, fig.width = 9}
#pull out rec centers
rec_centers <- var_list$CommunityCenters
rec_centers_count_map <-
  ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 2, alphae = 0.9) +
  geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 1) +
  labs(title = "Community center locations") +
  #scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "Count") +
  mapTheme()


#grab and map count
rec_centers_agg <- ALL_FEATURES %>% 
  dplyr::select(agg_CommunityCenters, net_id) %>% 
  left_join(., net_Richmond, by = "net_id") %>% 
  mutate(value = ifelse(is.na(agg_CommunityCenters), 0, agg_CommunityCenters)) %>% 
  st_sf()
rec_centers_agg <- make_cuts(rec_centers_agg, "value", cuts = "breaks", n_breaks = 5)
rec_centers_agg_map <-
  ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers_agg), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  # geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 4) +  
  #geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 2) +
  labs(title = "Community center count\nby fishnet") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "Count") +
  mapTheme()

#grab and counteuclidean distance
rec_centers_ed <- ALL_FEATURES %>% 
  dplyr::select(ed_CommunityCenters, net_id) %>% 
  left_join(., net_Richmond, by = "net_id") %>% 
  mutate(value = ifelse(is.na(ed_CommunityCenters), 0, ed_CommunityCenters)) %>% 
  st_sf()
rec_centers_ed <- make_cuts(rec_centers_ed, "value",  "value", cuts = "breaks", n_breaks = 5)
rec_centers_ed_map <-
  ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers_ed), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 1, alpha = 0.9) +
  #geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 2) +
  labs(title = "Community center\neuclidean distance",
       caption = "Figure 1.2") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "NN Distance") +
  mapTheme()

#grab and map avg nn 
rec_centers_NN <- ALL_FEATURES %>% 
  dplyr::select(NN_CommunityCenters, net_id) %>% 
  left_join(., net_Richmond, by = "net_id") %>% 
  mutate(value = ifelse(is.na(NN_CommunityCenters), 0, NN_CommunityCenters)) %>% 
  st_sf()
rec_centers_NN <- make_cuts(rec_centers_NN, "value",  "value", cuts = "breaks", n_breaks = 5)
rec_centers_NN_map <-
  ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers_NN), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 1, alpha = 0.9) +
  #geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 2) +
  labs(title = "Community center average\nnearest neighbor distance") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "NN Distance") +
  mapTheme()

cowplot::plot_grid(rec_centers_count_map,rec_centers_agg_map,rec_centers_ed_map, rec_centers_NN_map, align="hv", axis = "rlbt", ncol=2)
```

Prior to building any models, maltreatment events in Richmond are explored using various methods. We begin by analyzing maltreatment clusters to better understand the relevant spatial process. Figure 1.3 illustrates the location of statistically significant maltreatment event clusters across Richmond. These are locations where maltreatment occurs in higher densities than we might expect due to random chance alone.

```{r cache = TRUE,echo=FALSE,warning=FALSE,include = TRUE,fig.align="center"}
ggmap(cps_base_map) +
  geom_sf(data = ll(p_cut), aes(fill = pval_cut),
          color = NA, inherit.aes = FALSE, alpha = 0.8) +
  scale_fill_viridis_d(na.value=NA, name = "p-value", option = "D") +
  labs(title = "Stastically significant maltreatment clusters",
       caption = "Figure 1.3") +
  mapTheme()
```

We also analyze the extent of colocation between maltreatment and measures of exposure to determine whether a given factor is 'closer' to a maltreatment event than what we might otherwise presume due to random chance alone. This is a useful, policy-centric approach for understanding how phenomena are associated with maltreatment across space. 

For example, Figure 1.4 ranks crime related factors by their average distance to maltreatment. We provide more statistical intuition for this test in [Section 6](#exploratory-analysis), however for now, it is interesting to point out that several domestic-oriented crimes occur in close proximity to maltreatment.
  
  ```{r message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, include=TRUE, fig.height=18}
  CRIME_CPS_VS_NN_plot
  ```
  
  Once we understand the patterns within the maltreatment data, several linear and non-linear machine learning algorithms are estimated. For each model, a set of 'goodness of fit' metrics are recorded that describe the tradeoff between model accuracy and generalizability across space. 
  
  At the heart of the analysis is the tradeoff between accuracy and generalizability. A model that is perfectly accurate will not reveal areas where children may be at risk despite a lack of reported maltreatment. A model that is perfectly generalizable may fail to provide targeted intelligence to identify areas at serious risk for maltreatment.
  
  Accuracy is defined as the model's ability to minimize the difference between the observed count of maltreatment events and the predicted count. These differences are referred to as 'errors' and significant attention is paid to their nuances in [Section 4](#methods) and [Section 6](#modeling-and-validation). Generalizability refers to the model's ability to make comparable predictions across neighborhoods regardless of differences in factors like income and race. Several of these 'cross-validation' metrics are calculated, visualized, and explained in Section 6.
  
  ###Results
  
  By focusing on the tradeoff between accuracy and generalizability, the final predictive model produces highly targeted spatial risk predictions. These risk predictions are split into five risk categories - 5 being the greatest risk. Figure 1.5 maps these categories and overlays a set of maltreatment events that were withheld from the model for the purposes of validation. The map suggests that our model predicts well, evidenced by the many holdout maltreatment events that fall in the highest predicted risk category.
  
  ```{r cache = TRUE,echo=FALSE,warning=FALSE, include = TRUE, fig.align = "center"}
  REALTIVE_SENSITIVITY_PREDICTIONS
  ```
  
  This visual relationship is further formalized by comparing the model predictions to those derived from a simple Kernel Density Estimation (KDE) - a common tool used to convert point data into hot spot maps. The ubiquity of KDE as a tool for spatial targeting makes it a useful baseline to which model predictions can be compared.
  
  Both the KDE and the risk predictions are split into five risk categories, and the proportion of holdout maltreatment events are calculated for each category. The plot below shows that for the highest risk category, the meta-model captures approximately 70% of the observed maltreatment events, whereas the KDE captures only about 35%. For context, approximately 8,200 children live in the high risk category which represents about 21% of total children in Richmond, but only about 10% of the total area of the city.
  
  ```{r cache = TRUE,echo=FALSE,warning=FALSE, include = TRUE, fig.width=8, fig.align="center"}
  REALTIVE_RISK_BARPLOT_COMPARE_plot
  ```
  
  Other useful metrics are created to evaluate model performance. Our most useful predictive model has an average (absolute value) error of 0.533 of one maltreatment event. We believe this outcome is representative of a highly accurate model that is capable of producing policy-relevant risk predictions. However, it is difficult to determine how the model performs in areas with a lot of maltreatment events with those communities with few maltreatment occurrences using only this metric.
  
  Rather, Figure 1.7 displays a simple evaluative measure for the final model - visualizing predicted maltreatment counts as a function of observed counts. The black line that intersects the point cloud represents a perfect prediction, while the blue line represents actual predictions. The model is accurate for most of the data (i.e. most of the city), but loses some fidelity in areas with very high maltreatment event counts.
  
  ```{r cache = TRUE,echo=FALSE,warning=FALSE, include = TRUE, fig.align="center"}
  META_MODEL_FIT_plot
  ```
  
  We also develop several metrics to describe generalizability across space. Despite the models ability to rightfully predict high maltreatment risk in areas with high occurrence rates, we do see relatively higher errors in these places. The variability of (absolute value) error across Richmond neighborhoods is 0.746 of one event.
  
  Another way of judging how well the model generalizes across space is to ask how well it performs in neighborhoods of varying typologies. We test the model looking for relative differences across high and low poverty rates and high and low minority rates, respectively. If the model generalizes well to these places, we should see similar accuracies across the varying typologies. 
  
  Results suggest that the model predicts equally well across neighborhoods of varying poverty levels. However, these metrics also indicate that the model predicts less accurately in certain minority neighborhoods, particularly those with disproportionately large maltreatment counts. The nature of this finding is discussed in detail in [Section 6](#modeling-and-validation), and additional approaches for adding more equity into the model are proposed.
    
    ###Align
    
    Using the knowledge from the predictive model, we develop a strategic planning framework, embedding the risk predictions into a larger analysis describing whether the supply of child welfare services is properly aligned with the demand for these services. Demand in an area is defined by the risk predictions. We define supply as the presence of protective land uses - places stakeholders could deploy education, treatment, and prevention resources.
    
    One way to characterize alignment is to scale these indicators of supply and demand and relate them to each other at the neighborhood level. Figure 1.8 displays the resulting relationship. Light red and light green neighborhoods are those where there is a strong alignment between the supply of and demand for child welfare services. Dark green places are those where there are more protective resources than risk, and dark red areas are places where maltreatment risk outweighs the availability of protective resources.
    
    ```{r cache = TRUE, echo=FALSE,warning=FALSE, include = TRUE, fig.height = 7, fig.width = 6.5, fig.align = "center"}
    gapMap
    ```
    
    This method can suggest that protective resources are not always in optimal locations. To get a clearer picture we examine Stop Child Abuse Now (SCAN) Centers (Figure 1.9). The SCAN [mission](http://grscan.com/) is to 'prevent and treat child abuse and neglect throughout the Greater Richmond area by protecting children, promoting positive parenting, strengthening families and creating a community that values and cares for its children'. While this organization provides an invaluable service, when mapped in the context of risk, it appears some of these centers could be better allocated to communities at greater risk for maltreatment.
    
    ```{r cache = TRUE, echo=FALSE,warning=FALSE, include = TRUE, fig.align="center"}
    ggmap(cps_base_map) +
      geom_sf(data=ll(st_union(predMap)), inherit.aes = FALSE, alpha = 0.8, color = NA) +
      geom_sf(data=ll(scan.buffers), aes(fill=pred), inherit.aes = FALSE) +
      scale_fill_viridis_c(name = "Mean predicted\ncount") +
      labs(title = "Mean predicted count by quarter mile buffer",
           subtitle = "SCAN Centers",
           caption = "Figure 1.9") +
      guides(fill = guide_colourbar(reverse = TRUE)) +
      mapTheme()
    ```
    
    The next section provides and discusses more of these Align analytics, which stakeholders can easily develop by bringing a digital map file of risk predictions into a standard desktop GIS system. We believe this framework can have important impacts on the child welfare strategic planning process in Richmond.
    
    In the sections to follow, we delve deeply into the spatial risk predictive model developed for this project. We provide some motivation, contrasting predictive modeling to traditional research, and present a very robust methods section situating our framework in the literature on spatial analysis and spatial prediction. Next, we discuss our exploratory analysis and finally, results are examined at length.
    
    
    ##2. Align
    
    This work extends beyond the creation of an algorithm for predicting maltreatment risk, toward a workflow for generating actionable intelligence. The purpose of this phase is to harness the predictions generated above in the context of strategic planning. 
    
    Specifically, the goal is to understand the extent to which the supply of child welfare services are properly aligned with the demand for child welfare services. To define supply, a host of administrative datasets that either proxy or directly relate to service delivery are employed. To define demand, maltreatment risk predictions are used.
    
    Aside from direct child welfare provisions like social services, other important service delivery types include community resources such as churches and recreation centers. The purpose of the Align phase in part, is to identify resources that are optimally located relative to maltreatment risk. It is at these locations, where stakeholders may wish to deploy education, outreach, and treatment programs.
    
    The reader should consider the analysis outlined below to be a framework that can be adopted and replicated by both public and non-profit stakeholders. All one needs is a digital map file (i.e. shapefile) of risk predictions and the various supply-side oriented datasets. 
    
    The subheadings below outline different approaches that we feel could be useful for the planning process. We report analytics that:
      
      1. Look at the number of people living in areas of high maltreatment risk.
    2. Explore the relationship between poverty rate and predicted maltreatment risk.
    3. Examine correlations between risk and important public health outcomes like asthma and obesity.
    4. Explore the spatial relationship between child removals and predicted maltreatment risk.
    5. Examine the spatial relationship between child fatalities and predicted maltreatment risk.
    6. Assign risk scores to protective land uses (churches, rec centers etc.) to get a better sense of existing resources in the community.
    7. Examine whether current social worker home visits are situated in a high risk places.
    8. Explore maltreatment risk around Stop Child Abuse Now (SCAN) network centers.
    9. Perform a gap analysis to understand where and to what extent the supply of child welfare services co-locate with the demand for those services.
    
    
    ###Risk category population totals
    
    The demand for child welfare services is related to the number of people living in high risk areas. Figure 2.1 shows that approximately 48,500 people live in the highest risk category, an area which comprises about 10% of the city. Another 30% of the population lives in the second highest risk category, indicating, in total, over 50% of the population live in areas of potentially high demand for child welfare services.
    
    ```{r include = TRUE, fig.width=8, fig.align="center"}
    popPerRiskPlot
    ```
    
    ###Is poverty related to predicted maltreatment events?
    
    Figure 2.2 maps the weighted poverty rate by fishnet grid cell. How does the distribution of poverty relate to maltreatment events? 
      
      ```{r include = TRUE, fig.align="center",}
    povertyRateMap
    ```
    
    Figure 2.3 illustrates the relationship between poverty rate and predicted maltreatment count. The scatter plot shows that the correlation between poverty and predictive risk is marginal. This visual relationship is confirmed by a correlation coefficient of 0.29. The weak relationship persists even when the zero count grid cells are removed.
    
    ```{r include = TRUE, fig.width = 8, fig.align="center"}
    povRatePredPlot
    ```
    
    ###Maltreatment risk and health outcomes
    
    Studies suggest that maltreatment is correlated with a host of other health outcomes like asthma and obesity. While we don't currently have data in hand on rates of these other health outcomes, it would be interesting to test whether maltreatment risk is correlated with these other health outcomes across space. If they are, we might be able to use maltreatment risk as a way to target interventions associated with these other outcomes.

###Maltreatment risk and removals of a child from the household

```{r include = TRUE, fig.align="center"}
removalsMap
```

Figure 2.4 maps maltreatment risk categories overlaid with locations that a child was removed from the home because of abuse. Are these removals in places the model predicts high risk? 

To answer this question, Figure 2.5 counts the number of removal events by risk category. It is clear that an overwhelming proportion of removals occur in the highest risk category. 

```{r include = TRUE, fig.width = 8, fig.align="center"}
removalsPlot
```

###Maltreatment risk and child fatalities

Figure 2.6 maps locations of child fatalities over the predicted maltreatment risk categories. The associated bar plot shows the majority of child fatalities are occurring in the two highest risk categories.

```{r include = TRUE, fig.width=14, fig.height=7}
cowplot::plot_grid(fatalitiesMap, fatalitiesPlot, align = "hv", axis = "lrbt")
```

###Assign risk scores to protective land uses

The maltreatment predictions suggest where education, outreach, and prevention efforts should occur. What resources are available at these locations? We answer this question using some of the original protective factors data gathered for the predictive model. Stakeholders can replicate this approach on a more finite list of sites that could host these interventions. Figure 2.7 shows the distribution of protective land uses by type.

```{r include = TRUE, fig.width = 10, fig.align="center"}
protectiveUsesByType
```

We then calculate a relative measure of risk exposure for each protective land use by drawing quarter mile buffers around each site and taking the mean count of predicted events. Figure 2.8 plots these buffers and the relative measure of risk exposure. The table that follows lists the top 20 individual protective locations sorted by type and mean predicted count.

```{r include = TRUE, fig.width = 10, fig.align="center"}
quarterMileBuffer_protective
```

```{r include = TRUE}
protectiveTable
```

As mentioned, this process can be repeated for a specific list of sites. In Figure 2.9 we look at the relative measure of risk exposure for churches and other faith organizations. The following table lists the ten most optimally located churches based on mean predicted count of maltreatment events within a quarter mile.

```{r include = TRUE, fig.width=10.5}
churchMap
```

```{r include = TRUE}
top_church
```

Figure 2.10 evaluates the relative risk exposure for licensed child care providers. The table that follows lists the top provider locations sorted by type and mean predicted count.

```{r include = TRUE, fig.width = 10, fig.align="center"}
childcareMap
```

```{r include = TRUE}
top_childcare
```

Finally, Figure 2.11 shows the relative measure of risk exposure for resource homes. Resource homes are locations certified to accept foster care children. The top resource home locations are listed in the table below.

```{r include = TRUE, fig.width = 10, fig.align="center"}
resourcehomeMap
```

```{r include = TRUE}
top_resourcehomes
```

###Do home visits occur in high risk places?

Figure 2.12 maps the predicted risk categories overlaid with a limited set of home visit locations. As above, the number of home visits by risk category is counted to see if they are occurring in high risk places. The bar plot below shows that they are.

```{r include = TRUE, fig.width=14, fig.height=7}
cowplot::plot_grid(homeVisits, vistsCategory, align = "hv", axis = "lrbt")
```

###Maltreatment risk and SCAN Centers

Stop Child Abuse Now (SCAN) Centers are an important family resource in Richmond. Are they located in optimal locations? To answer this question, we overlay SCAN Centers atop risk categories and calculate a relative exposure score for each (Figure 2.13).

```{r include = TRUE, fig.align="center"}
scanCenters
```

Figure 2.14 maps the mean predicted maltreatment count within a quarter mile of each SCAN Center. The low count of maltreatment events within this radius suggests that some of these centers are not optimally located relative to maltreatment risk.

```{r include = TRUE,fig.align="center", fig.width = 10}
scanMap 
```

Finally, below is a table showing the top three optimally located SCAN Centers.

```{r include = TRUE}
scan.buffers %>%
  bind_cols(scan) %>%
  top_n(n=3,wt=pred) %>%
  as.data.frame() %>%
  mutate(Mean_Predicted_Count = round(pred)) %>%
  dplyr::select(SCAN.s.Trauma.Informed.Community.Network..TICN.,Street.Address, Mean_Predicted_Count) %>%
  arrange(-Mean_Predicted_Count) %>%
  rename("Scan Center" = SCAN.s.Trauma.Informed.Community.Network..TICN.,
         "Street Address" = Street.Address,
         "Mean Predicted Count" = Mean_Predicted_Count) %>% 
  kable() %>% 
  kable_styling()
```


###Gap analysis

To reiterate, the purpose of this analysis is to ensure that the supply of child welfare services is properly aligned with the demand for these services. We approach this in a piecemeal fashion above but attempt bring it all together in one spatial analytic that can compare relative maltreatment risk to the relative supply of protective resources by neighborhood.

To define relative risk, we create a density metric defined as the sum of the highest risk category grid cells in a neighborhood divided by the total number grid cells in that neighborhood. To define the relative supply of protective resources, we take a density of protective resources from above and divide by the total area of the neighborhood. Both metrics are scaled into percentiles to run from 1 to 100, where 100 equates to a relatively high density.

We then calculate the gap with using the following formula: gap = RelativeProtectiveSupply - RelativeRiskgap = RelativeProtectiveSupply - RelativeRisk. For example, a neighborhood with a protective score of 100 (lots of protective resources) and a risk score of 10 (relatively little relative risk), would have a gap score of 90, suggesting more resources are present than needed.

Conversely, a neighborhood with a protective score of 10 (few protective resources) and a risk score of 90 (relatively high maltreatment risk), would have a gap score of -80, suggesting a tremendous misalignment of resources given the predicted need.

We calculate this and map it below (Figure 2.15). Light red and light green neighborhoods are those where there is a strong alignment between protective resource and risk. Dark green places are those where there are more protective resources than risk, whereas dark red areas are places where there is far more risk than protective resources.

This metric can be tuned further by gathering other data that better describe the protective resources available to children in Richmond. 

```{r include = TRUE, fig.width=7, fig.height=6.5, fig.align="center"}
ggmap(cps_base_map) +
  geom_sf(data=ll(nbr_statAreas.gap), aes(fill=gap), inherit.aes = FALSE,alpha = 0.8) +
  scale_fill_gradientn(colours=c(re,"green2", bl),
                       limits = c(-100,100),
                       breaks = c(-100,100),
                       labels = c("More risk\nthan protection","More protection\nthan risk")) +
  labs(title = "Gap analysis:\nComparing relative risk to protective resources",
       subtitle = "By Neighborhood Statistical Area",
       caption = "Figure 2.15") +
  mapTheme() +
  theme(legend.position = 'bottom',
        legend.title=element_blank(),
        legend.text=element_text(size=10, face = "bold"),
        legend.justification = "center") +
  guides(fill= guide_colorbar(barwidth=15,barheight=2))
```

##3. Motivation

###Program evaluation vs. predictive modeling

Much of the related child welfare research is focused on the causal relationship between maltreatment and associated exogenous factors. A well designed experiment, or quasi-experiment, can have important implications on the policy responses to child maltreatment. Conclusions from these sorts of program evaluations are often used to drive major programmatic or budgetary decisions.

In contrast, predictive modeling is best thought of as a tool for operational decision-making, helping stakeholders more effectively allocate their limited resources. A well calibrated causal model is one that avoids confounding bias when identifying how a variable of interest affects the outcome, whereas a well calibrated predictive model leads to more effective decision-making relative to the current resource allocation process. 

This is in the spirit of Figure 1.6 above which compares model predictions to kernel density.

###People vs. placed-based predictive modeling

To date, researchers and jurisdictions have built both people and placed-based predictive models of child maltreatment.[^6] The benefit of people-based models is their ability to guide interventions to specific individuals or households, potentially preempting a maltreatment event. This level of resolution comes with costs, however. People-level predictions require people-level data, often requiring a jurisdiction to overcome the significant legal, bureaucratic, and financial costs needed to integrate highly private, across-agency administrative data. 

On the other hand, although placed-based models make predictions at greater geographic scales, the only required private data is geocoded locations of maltreatment events. Placed-based modeling does not entail high resolution integrated data. Most of the predictor variables describe environmental factors such as crime, blight, nuisance land uses, etc. - public data often available for download in bulk on city or state Open Data websites. Not only does this lessen the concern over the mistreatment of private data, it also means that building, testing, and deploying placed-based predictive models is more cost effective.

While people and placed-based models vary in their inputs, outputs, and applications, the modeling process is very similar. In both instances, a well fit model is one that is both accurate and generalizable across different urban contexts.


###The value of open source analytics

The software and algorithms created for this analysis are licensed under WHAT IS APPROPRIATE OPEN SOURCE LICENSE? The suite of tools we have developed and documented below have been written in the R Statistical Language using custom functions of our own creation, as well as a number of open source packages shared freely by their authors. 

The codebase written for this project is designed with the goals of standards and transparency in mind. The public sector is still developing the internal capacity for developing machine learning algorithms. Typically, governments procure sophisticated, closed-source software at a significant expense for both initial development and ongoing maintenance. We believe that by creating the foundations for an open source suite of spatial machine learning tools as part of this project, we can lay the groundwork for standards that other jurisdictions can adopt with minimal startup costs in the future. 

The proliferation of standards will make it easier for the policy community to coalesce around a set of best practices for developing and deploying these models. Perhaps most critical is the ability to interpret the accuracy of these models and identify potential sources of bias. The reader will find all the source code used to develop this analysis in the appendices below.

###Aligning the supply of child welfare services to the predicted demand for these services

The predictive model developed below was created specifically to foster more efficient and effective decision-making in the child maltreatment realm. The goal is to ensure that the limited child welfare resources available to children and families in Richmond are allocated where they are needed most.

Toward this goal, we use the model predictions along with a host of ancillary data provided by the State of Virginia to develop a strategic planning framework that can identify places where the supply of services and the demand for these services are misaligned. This framework can be adopted and updated either in R or with standard Desktop GIS. 

###How this report is organized

This document is written in the R Markdown format. The purpose of R Markdown is to embed descriptive text, data visualizations, and code in to one cohesive narrative. Most readers will focus only on the case study. Others, particularly those interested in replicating the analysis, should refer heavily to the appendices toward the end.

##4. Methods

The child maltreatment spatial risk prediction framework presented here was developed in the spirit of criminological platforms like [RTMDx](http://www.riskterrainmodeling.com/) and [Hunchlab](https://www.hunchlab.com/), with some critical differences. First, it is free and open source and released with the hope that other jurisdictions will replicate. Second, it is more than just a predictive algorithm. The exploratory data analysis functionality, bias detection tools, and suite of comprehensive planning tools (Align) should make it easier for analysts to communicate data-driven insight to non-technical policy makers. 

Spatial prediction has been a tool in the spatial analysis toolbox for decades. Predicting unknown quantities across space from observed sample data is typically known as 'interpolation'. In their exhaustive review, Li and Heap situate this brand of spatial prediction in the realm of 'spatial interpolation' suggesting, 'nearly all spatial interpolation methods can be represented as weighted averages of sampled data'.[^7]

Methodological literature at the intersection of interpolative predictive modeling and geography include simple interpolation, geostatistical methods such as Kriging, Gaussian Process Regression, Geographic Weighted Regression, Generalized Linear Models, and non-linear models like Random Forests.[^8]

These models have been applied across a variety of disciplines including forestry, soil science, biology, archaeology, criminology, and public health.[^9] There is also a compelling thread of literature on the validation of spatial prediction methods including Congalton, Vicente-Serrano et al., Li and Heap, and Brenning.[^10] There is decades of literature on machine learning techniques, which vary from geostastics but are mechanically similar, including Kuhn and Johnson and Hastie, Tibshirani, and Friedman.[^11]  

The first application of these techniques to predict child maltreatment employed The Risk Terrain Model (RTM).[^12] The original RTM model used a weighted raster overlay methodology rooted in 'Map Algebra', methods first presented by Tomlin.[^13] While this is a useful descriptive approach for generating spatial hotspots, it does not provide measures of statistical confidence or goodness of fit.

The RTM approach matured from geographical overlay into a more prescriptive machine learning workflow as part of a partnership with Jeremy Heffner and software development firm Azavea. The Risk Terrain Modeling Diagnostics Utility tool (RTMDx) used regularization to reduce potential collinearity when predicting crime counts.[^14] Heffner develops a novel feature selection approach combining Penalized regression and Stepwise regression to estimate a final Poisson regression model that predicts crime counts. 

The RTMDx statistical workflow was developed using open source statistical packages in R. While the analytics that underlie RTMDx analytical engine are open source, the utility itself is not. RTMDx [ranges from](http://www.rutgerscps.org/rtmtce-program.html) $100/year for a student license to $4,995/year for 'Agency Users'. Hunchlab, the predictive policing application developed by Azavea, [can cost](https://www.dailydot.com/layer8/predictive-policing-costs-official-police-business/) $15,000/yr for every 50,000 people in a jurisdiction. According to the same source, Predpol, another predictive policing application can also range in the six figures.


Below, we review the many tools developed as part of the framework. A host of Extract, Transform & Load tools have been developed for the purposes of data ingestion, cleaning, and standardization. Several Exploratory Data Analysis routines have been created as well, that describe key relationships in the data, many of which can be visualized and explained to non-technical policy makers. Finally, a host of comprehensive, machine-learning specific tools have been generated for the purposes of both prediction and prediction assessment. We look at each in turn below.

###ETL & Feature Engineering

Feature engineering is the creation of standardized observations from which predictive relationships can be mined. The process of feature engineering includes the steps of data ingestion, aggregation, and transformation.  As Table 4.1 shows, we employ several datasets for this analysis, converting each into a series of individual features.

```{r eval=TRUE, echo=FALSE, include = TRUE, cache=FALSE}
datasetsTable <- rbind(
  data.frame(Dataset = "Crime",
             Description = "Locations of reported violent and nonviolent incidents that represent risk in the city"),
  data.frame(Dataset = "Points of Interest",
             Description = "Places in Richmond that characterize environmental factors and are categorized as either risk (i.e. Pawnbrokers, Payday loan locations, ABC stores) or protective (i.e. Libraries, Community Centers, Grocery stores) features"),
  data.frame(Dataset = "Businesses",
             Description = "Businesses that either characterize nuisance land uses or protective land uses"),
  data.frame(Dataset = "Code Violations",
             Description = "Indicates the safety and overall quality of structures"),
  data.frame(Dataset = "CPS Accepted Events",
             Description = "Locations of child matreatment incidents")
)

datasetsTable  %>% 
  kable(., format = "html") %>% 
  kable_styling()
```

Routines have been developed that load data from various files and formats into the R programing environment for standardization and reshaping. This step begins with moving all data files to a common folder and then using R to list the files, check for the presence of ID and spatial coordinate fields, the number of rows, and the number of columns. A custom R function is written to handle these steps automatically regardless of file type or file names. Once loaded, summary statistics on each dataset are generated.

Additional data cleaning steps include the removal of events that are spatial and temporal duplicates. Additionally, maltreatment events that are labeled as 'unverified' are removed from the analysis.

In creating the dependent variable, a lattice grid, the 'fishnet', is overlain across Richmond and maltreatment events are summed for each grid cell. The fishnet consists of 1,910 individual cells with an area of 1000 ft^2, which allows for greater level of predictive resolution relative to say, census tracts. We also calculate for each grid cell, the population normalized rate of maltreatment events per 100 residents. This is achieved by overlaying the fishnet grid onto 2010 census tracts and attributing to each cell a weighted population proportional to the area of the tract that falls into the grid cell. 

```{r cache = TRUE,echo=FALSE, warning=FALSE, include = TRUE, fig.height=10}
fishnet1 <- ggmap(cps_base_map) +
  geom_sf(data=ll(net_hood), aes(), inherit.aes = FALSE, alpha = 0.8) +
  labs(title="Fishnet - Richmond, VA") +
  mapTheme() +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0, face = "plain", size = 14, family = "sans"))

CPS_RATE_BY_FISHNET_PLOT2 <- ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_rate_cut), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  labs(title = "CPS rate per 100 people",
       caption = "Figure 4.2") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "CPS Rate\nper 100") +
  mapTheme() +
  theme(plot.title = element_text(size = 14, family = "sans", face = "plain", hjust = 0),
    plot.subtitle=element_text(size = 11, family = "sans", hjust = 0),
    plot.caption=element_text(size = 10, family = "sans", face = "italic", hjust = 0),
    axis.line = element_blank(),
    legend.title = element_text(size = 10, family = "sans"),
    legend.text = element_text(size = 9, family = "sans"))

cowplot::plot_grid(fishnet1, CPS_COUNT_BY_FISHNET_PLOT, CPS_RATE_BY_FISHNET_PLOT2, ncol = 1, align = "hv", axis = "lrbt")
```

We also relate measures of exposure to the fishnet, aggregating risk and protective factors using three different strategies:[^15]

  1. Net or sum of exposure events per grid cell.
  2. The Euclidean distance from the center of each grid cell to the nearest exposure event. 
  3. The average Euclidean distance from the center of each grid cell to the five nearest event neighbors. 

More than 200 features are created in this fashion, scaled and combined into a dataset which is then used in the modeling process.[^16] We also generate a series of spatial lag features, using the three feature engineering approaches above to account for the spatial externalities associated with maltreatment. Figure 4.3 visualizes examples of each feature engineering approach.

```{r message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, include=TRUE, fig.width = 8}
#pull out rec centers
rec_centers <- var_list$CommunityCenters
rec_centers_count_map <-
ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 2, alphae = 0.9) +
  geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 1) +
  labs(title = "Community center locations") +
  #scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "Count") +
  mapTheme()


#grab and map count
rec_centers_agg <- ALL_FEATURES %>% 
  dplyr::select(agg_CommunityCenters, net_id) %>% 
  left_join(., net_Richmond, by = "net_id") %>% 
  mutate(value = ifelse(is.na(agg_CommunityCenters), 0, agg_CommunityCenters)) %>% 
  st_sf()
rec_centers_agg <- make_cuts(rec_centers_agg, "value", cuts = "breaks", n_breaks = 5)
rec_centers_agg_map <-
ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers_agg), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  # geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 4) +  
  #geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 2) +
  labs(title = "Community center count\nby fishnet") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "Count") +
  mapTheme()

#grab and counteuclidean distance
rec_centers_ed <- ALL_FEATURES %>% 
  dplyr::select(ed_CommunityCenters, net_id) %>% 
  left_join(., net_Richmond, by = "net_id") %>% 
  mutate(value = ifelse(is.na(ed_CommunityCenters), 0, ed_CommunityCenters)) %>% 
  st_sf()
rec_centers_ed <- make_cuts(rec_centers_ed, "value",  "value", cuts = "breaks", n_breaks = 5)
rec_centers_ed_map <-
ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers_ed), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 1, alpha = 0.9) +
  #geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 2) +
  labs(title = "Community center\neuclidean distance",
       caption = "Figure 4.3") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "NN Distance") +
  mapTheme()

#grab and map avg nn 
rec_centers_NN <- ALL_FEATURES %>% 
  dplyr::select(NN_CommunityCenters, net_id) %>% 
  left_join(., net_Richmond, by = "net_id") %>% 
  mutate(value = ifelse(is.na(NN_CommunityCenters), 0, NN_CommunityCenters)) %>% 
  st_sf()
rec_centers_NN <- make_cuts(rec_centers_NN, "value",  "value", cuts = "breaks", n_breaks = 5)
rec_centers_NN_map <-
ggmap(cps_base_map) +
  geom_sf(data = ll(rec_centers_NN), aes(fill = cut_val), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  geom_sf(data = ll(rec_centers), inherit.aes = FALSE, color = "red", size = 1, alpha = 0.9) +
  #geom_sf(data = ll(nbr_diss), inherit.aes = FALSE, color = "black", fill = NA, size = 2) +
  labs(title = "Community center average\nnearest neighbor distance") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "NN Distance") +
  mapTheme()

cowplot::plot_grid(rec_centers_count_map,rec_centers_agg_map,rec_centers_ed_map, rec_centers_NN_map, align="hv", axis = "rlbt", ncol=2)
```


###Exploratory Data Analysis

Exploratory Data Analysis (EDA) is a principled exploration of the data that allows natural patterns, structures, and relationships in the data to come to the surface.[^17] The tables and visuals created for this stage highlight outliers and anomalies, test assumptions, and uncover underlying structures. A desired outcome of EDA is to present data in such a way that stakeholders ask new and interesting questions that were not previously realized. This approach benefits in clearer goal setting and an atmosphere of collaboration between policy makers, technical specialists, and analysts.

EDA is employed here to gain a deeper understanding at the intersection of the contributing features, maltreatment outcomes, and subject matter expertise. This process is even more prescient due to the complicating dimensions of space and time. The EDA methods developed here consist of:

  1. Calculating summary statistics for each of the features
  2. Plotting histograms and counts of categorical variables
  3. Mapping the distribution and density of each feature
  4. Visualizing the correlation between each variable
  5. Computing Global and Local Moran's I statistics
  6. Simulating random Nearest Neighbor distance
  7. Estimating the distribution of the outcome variable
  
  Summary statistics (e.g. minimum, maximum, deciles, counts, etc.) provide quantitative descriptions of each feature. Correlations inform the pairwise relationship between features and the outcome of interest. 
  
  Moran's I is a measure of spatial autocorrelation and used here to estimate the pattern of spatial association for maltreatment counts. The values of Moran's I generally range between -1 and +1, but more extreme values are possible. A value of zero typically indicates spatial randomness, a value of -1 indicates negative spatial autocorrelation (i.e. a regular pattern), and a value of +1 indicates positive spatial autocorrelation (i.e. clustering). For this study, the Moran's I is calculated on both the global scale and the local scale. Global Moran's I results in a single value describing the universal autocorrelation. This study uses the `moran.mc` function of the `spdep` R package to derive the global I value through Monte Carlo simulation.[^18]
  
  The local Moran's I describes the spatial autocorrelation within a local neighborhood of eight fishnet grid cells surrounding a given fishnet grid cell. This neighborhood configuration is called the 'Queen case' because it is the same eight directions as the Queen moves in chess. The local measure of Moran's I also computes the p-value indicating the significance of the local autocorrelation. Both the Moran's I value and the p-value are plotted to visualize significant positive and negative local clusters of maltreatment event counts.

A second simulation method is used to better understand whether risk and protective factors are more closely or distantly associated with maltreatment event locations.[^19] This is achieved by simulating a set of random points equal in quantity to the number of events for a specific feature and averaging the nearest neighbor distance to n maltreatment events. This is repeated 1,000 times resulting in a distribution of randomly permuted nearest neighbor distances. Finally, this distribution is compared to the observed global average nearest neighbor distance of each contributing feature. If the observed distance of a given feature is closer than 95% of the randomly permuted distances (a p-value of 0.05), we can conclude that the feature is 'close' to maltreatment citywide.  

The final step in the EDA is to gain a better understanding of the statistical distribution of maltreatment event counts. Inherently, the number of maltreatment events per fishnet cell is a count data type, which is typically modeled by either the Poisson or Negative Binomial distributions.

The intuition for the Poisson distribution is that maltreatment is a relatively rare event and that the probability of this occurrence is independent after accounting for contributing factors. Further, it is assumed that the variance in maltreatment event counts is approximately equal to the mean of counts. This assumption limits the potential for drastic outliers in maltreatment event counts relative to the mean of all counts. By contrast, the Negative Binomial distribution can be conceptualized in a similar manner with the exception that the variance is not the same as the mean. 

The `fitdist` function in the `fitdistrplus` package is employed to simulate samples from the empirical maltreatment event count distribution and compare the goodness of fit to both the Poisson and Negative Binomial distributions.[^20] The results of this test are visualized and used to choose between the two distributions.

###Model fitting & stacking

Model 'fitting' describes the process by which a statistical algorithm learns about maltreatment risk by relating the interaction of risk/protective factors to maltreatment events across space. Once a model is fit and validated, the learned pattern is applied back to the contributing features in each fishnet cell to predict the count of maltreatment events across space. This prediction highlights areas where maltreatment is present but unreported.

The first step in the model building process is to select the 15 most statistically important risk and protective feature sets. We select across the different feature types (Euclidean distance, average nearest neighbor distance, and aggregate counts) based upon statistical correlation. These features make up the final feature sets, which are then subjected to our models.

Three different algorithms are fit modelling different aspects of the spatial process and then combined into a fourth 'meta-model'. The three individual models are a Poisson Generalized Linear Model (Poisson GLM), a Random Forest model, and a Spatial Durbin Model (SDM). The final prediction of maltreatment events is produced from the meta-model which is created by applying the Random Forest algorithm to the predictions made by the sub-models. The use of three different model algorithms is an effort to understand different aspects of the highly complex system that contributes to the observation of a maltreatment event. 

At each stage in this process, models are fit using a 'leave one group out cross validation' routine (LOGOCV). LOGOCV splits the data into spatially explicit groups, in this case neighborhoods, fits the models to all but one of the groups, and predicts maltreatment event counts for the left out group. This process, explained in greater detail below, tests how well the models generalize across neighborhoods. Below we explain the three sub-models and their inclusion in the final meta-model as well.

```{r cache = TRUE,echo=FALSE,warning=FALSE, message = FALSE, include = TRUE}
ggmap(cps_base_map) +
  geom_sf(data=ll(net_hood), aes(fill=name), inherit.aes = FALSE, color = NA, alpha = 0.8) +
  scale_fill_viridis_d() +
  guides(fill=FALSE) +
  labs(title="LOGOCV Neighborhoods",
       caption = "Figure 4.4") +
  mapTheme()
```

_Poisson GLM_

The Poisson GLM model, fit with the base R `glm` function, is an adaptation of linear regression that accounts for the characteristics of count data. The adaptations include modeling the residuals as Poisson distributed and transforming the linear model with a natural log function. As a result, the predictions from a Poisson model are positive and represent mean expected counts conditional on the contributing risk or protective features for each fishnet grid cell. In the meta-model, Poisson GLM predictions represent a linear model of a Poisson distributed count process. 

_Random Forest_

In this study, the Random Forest algorithm is fit using the `ranger` library.[^21] The Random Forest algorithm builds a series of decision tree models to learn the relationship between maltreatment and exposure variables. The stochastic approach to sampling from observed data ensures that each individual tree is different from the next. The Random Forest provides a 'wisdom of many' approach, contributing non-linear interactions between maltreatment and the corresponding features to the final meta-model.

_Spatial Durbin Model_

To model spatial interrelationships - also referred to as 'spatial autocorrelation' - a Spatial Durbin Model (SDM) is fit using the `errorsarlm` function of the `spdep` package in R.[^22] In the setting of this study, the interpretation of this model is that the rate of maltreatment events is affected by both the exogenous exposure factors  as well as neighboring rates of maltreatment. Further, this model assumes that there may be latent features that impact the model errors but are not accounted by the exposure features. The key model input of spatial autocorrelation is a spatial weights matrix relating maltreatment in a given grid cell to its neighbors. Modeling the underlying spatial maltreatment process provides a powerful predictive story when input into the final meta-model. It is important to note that the SDM is not fit with the LOGOCV method due to the complications of subsetting a spatial weights matrix in a cross-validation setting.

_Meta-Model_

The final maltreatment count predictions are generated from a meta-model which combines predictions from the three sub-models. The process to combine the three models is straightforward; as the predicted counts from each sub-model are used as input features of a new model fit with the Random Forest algorithm. Often referred to as model 'stacking', this technique seeks to average out the variance in the three separate models. To reduce the risk of over-fitting, the stacked meta-model is fit and predicted using the same LOGOCV routine as the sub-models.

###Model validation

Assessing the accuracy and spatial generalizability of model predictions is crucial when considering how to embed this model in the provision of child welfare services. A variety of approaches are used for model validation including leave one group out cross validation (LOGOCV) and assorted goodness of fit metrics. Some of these metrics are statistical in nature, while others measure goodness of fit across space.  

_Leave One Group Out Cross Validation_

LOGOCV is a technique for assuring that model predictions are generalizable across neighborhoods. The first step in LOGOCV is to assign each fishnet cell to the neighborhood that encompasses it. From a policy perspective, LOGOCV evaluates whether the maltreatment experience as we've modelled it is relevant to varying neighborhood contexts in Richmond. From a modeling perspective, this approach helps ensure our models are not overfit. Each of the 148 neighborhoods takes a turn as the hold out, totaling in 297 individual sub-models and 297 separate estimates of goodness of fit.[^23]
  
  _Goodness of fit metrics_
  
  Model error is defined simply as the difference between the observed count of maltreatment events and the predicted count for each grid cell. Complicating matters is that 297 models yields more than 567,000 grid cell level predictions. We derive several statistics to summarize and aggregate these errors in order to judge models and compare across them. We describe each below:
    
    The Mean Absolute Error or MAE, measures the average absolute difference between the observed and predicted values.[^24] An example interpretation of MAE is that, 'on average, the model is off by plus or minus 1.67 events'. MAE is simple to interpret in a policy context, however, it comes with some drawbacks, namely that the direction of the error is unknown and that every error is assumed to have the same severity. The MAE assumes that an error between a predicted count of 5 and an observed count of 7 events should be considered the same as an prediction of 23 and an observed value of 25 events. This metric is used here due to its obvious interpretation and common usage in the assessment of predictive models.
  
  The second goodness of fit metric used in this study is called the Logarithmic Score. This metric is not as straightforward as the MAE, but it has qualities that make is well-suited to count-based predictions. The intuition of the Logarithmic Score is as follows: 'What is the likelihood of the observed count given the predicted count. More descriptively stated: if the model predicts 10 events and the observed count is 7 events, then what is the probability of observing those 7 events if the prediction of 10 is indeed the correct number. In this way, the Logarithmic Score measures the deviance between the predicted and observed counts. Specifically, this is measured by calculating the probability density of the observed value from a Poisson distribution centered on the predicted value. The goodness of fit measures below report the negative log of the probability density so that the value should always be minimized. In the results portion of this report, the Logarithmic Score is converted back to a probability and aggregated. The result is a score that is interpreted as the 'average likelihood that the observed counts are true given the predicted maltreatment counts. Closer to one means a higher relative likelihood, 0.5 equates to maximum uncertainty, and a value near zero signifies very little likelihood.[^25]
  
  ###Accuracy and generalization tradeoff
  
  The purpose of the LOGOCV and the goodness of fit metrics is to assess model errors on average and across space. A model that perfectly predicts the observed event counts for each fishnet grid cell would be very accurate, but would not generalize well to other cells because exposure changes across the city. Conversely, a model that predicts the same count of maltreatment events for every cell would generalize well, but not be relevant to the conditions of any one cell. LOGOCV and associated metrics help establish a balance between model accuracy and model generalization. Given the purpose of this study, it is important to create a model that is accurate enough to give confidence, but general enough to be applicable in areas where few cases are documented.
  
  ##5. Exploratory Analysis
  
  In this section, we derive a number of descriptive insights from our data. To begin, maltreatment events across space and time are visualized and we discuss some of the possible selection bias in the data. Next, hypotheses related to the clustering of maltreatment events across space are presented. Finally, we calculate a series of pairwise correlations between maltreatment and our features.
  
  ###Analysis of maltreatment events over time and space
  
  Figure 5.1 plots the counts of CPS events throughout the study period which began midway from 2013 and ended midway through 2017. From discussions with our partners in Virginia, the differences in counts across years may be due to changes in how maltreatment reports were entered into the system. As we do not observe these reporting changes, time variation cannot be used for model validation. 
  
  ```{r countEventsFishnet2, warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width=8}
  lubridate::year(var_list[["CPS_Accepted"]]$RDate) %>%
    data.frame(year = .) %>%
    ggplot(., aes(x = year)) +
    geom_histogram() +
    labs(title="Count of maltreatment events by year",
         caption = "Figure 5.1") +
    plotTheme()
  ```
  
  Although the counts may vary over time, they appear to be relatively consistent across space. Figure 5.2 shows the density of maltreatment events across space between 2013 and 2017. This is a strong indicator that the aforementioned reporting bias has less of an effect across space.
  
  ```{r warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width = 10}
  CPS_KDE_BY_YEAR_plot
  ```
  
  ###Visualizing risk and protective features
  
  Figures 5.3 and 5.4 plot the spatial density of selected protective and risk factors, respectively.
  
  ```{r warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width=12, fig.height=12}
  PROTECTIVE_KDE_FACET_PLOT
  ```
  
  
  ```{r warning=FALSE, message = FALSE, cache = TRUE, echo=FALSE, include = TRUE, fig.align = "center", fig.width=12, fig.height=12}
  RISK_KDE_FACET_PLOT
  ```
  
  
  ###Testing maltreatment events for clusters
  
  One overarching assumption behind our model is that maltreatment events are clustered in space. To test this hypothesis, the Local Moran's I statistic is employed.[^26]
 
The Local Moran's I statistic asks if the local distribution in the rate of maltreatment events, defined by a spatial weights matrix, is more clustered than we would expect due to random chance alone. Figure 5.5 plots the Local Moran's I results. The first panel shows the count of maltreatment events; Panel 2 shows the Local Moran's I value; and Panel 3 shows areas that exhibit statistically significant clustering. Panel 3 shows areas that resemble discrete clusters of maltreatment in space.
  
  ```{r moranIExp, cache = TRUE, warning=FALSE,echo=FALSE, include = TRUE,include = TRUE, fig.height=10}
  MORANS_I_P_plot
  ```
  
  ###Which risk/protective features are statistically 'close' to maltreatment events?
  
  Our predictive models below produce measures of 'variable importance', but because these estimates are produced outside of an experimental setting, they should not be interpreted as causal in nature. In this section, we generate some descriptive statistics that test the extent to which risk/protective factors are 'close' to maltreatment events.
  
  The x-axes of these plots represent the average nearest neighbor distance from the factor to maltreatment events. The bar plots visualize the distribution of randomly generated distances, while the black lines represent the observed nearest neighbor distance. Figure 5.6 suggests that domestic instances of aggravated assault are not only far closer to maltreatment events than what would be expected due to random chance alone, but are closer than all other crime types.
  
  ```{r cache = TRUE, warning=FALSE,echo=FALSE, include = TRUE, fig.height=18}
  CRIME_CPS_VS_NN_plot
  ```
  
  In fact, all crimes are closer to maltreatment events than otherwise expected, suggesting that nearby crime is a significant risk factor for maltreatment. 
  
  Figure 5.7, which visualizes the results for violation-related risk factors suggests that blight-related factors, like unfit structures and refuse, are strongly associated with maltreatment in space.
  
  ```{r cache = TRUE, warning=FALSE,echo=FALSE, include = TRUE, fig.height=14}
  VIOLATION_CPS_VS_NN_plot
  ```
  
  Finally, Figure 5.8 illustrates how this test can also play a role in understanding select business features. The plot tells us that child care providers, taken as a whole, are uniquely situated in close proximity for maltreatment. Thus, when looking to align resources to fight maltreatment, stakeholders should consider deploying these resources from child care providers.
  
  ```{r cache = TRUE, warning=FALSE,echo=FALSE, include = TRUE, fig.height = 17}
  BUSINESS_CPS_VS_NN_plot
  ```
  
  ###Pairwise correlations
  
  In the Feature Engineering phase, we create more than 200 features. Figures 5.9 and 5.10 visualize pairwise correlations for the top 15 most correlative risk and protective factors respectively. Note the correlation coefficients associated with maltreatment count ('cps_net') and maltreatment rate ('cps_rate'). The colors of the plot vary with the strength of the correlations, either positive or negative.
  
  There are 3 different prefixes associated which each type of feature. `NN` refers to features calculated by taking the average distance between a fishnet grid cell and its n nearest risk/protective factor neighbor. `ed` refers to the Euclidean distance between a fishnet grid cell and its 1 nearest risk/protective factor neighbor. `agg` refers to the count of risk/protective factor events in a given fishnet grid cell.
  
  ```{r corrplotStrongRisk,  cache = TRUE, warning=FALSE,echo=FALSE,fig.height=10,fig.width=10.5, include = TRUE}
  #features_risk_strong_plot <- features_risk_strong %>%
  # dplyr::select(-net_id)
  risk_cp <- feature_corrplot(features_risk_strong_plot, "Correlation of risk features")
  #CORR_RISK_FEATURES_plot
  ```
  
  
  ```{r corrplotStrongProtective, cache = TRUE, warning=FALSE, echo=FALSE, include = TRUE, fig.height=10,fig.width=10.5}
  #features_protective_strong_plot <- features_protective_strong %>%
  #dplyr::select(-net_id)
  protective_cp <- feature_corrplot(features_protective_strong_plot, "Correlation of protective features")
  #CORR_PROTECTIVE_FEATURES_plot
  ```
  
  ##6. Modeling and Validation
  
  The results of the modeling and validation stage of this report indicate that the three sub-models (Poisson GLM, Random Forest, and SDM) each obtain similar levels of accuracy and generalizability and the meta-model captures the nuances of each. The results indicate that the models are accurate, but there is a significant amount of variation in accuracy between neighborhoods. As we describe below, the meta-model generalizes well across neighborhoods of varying poverty rates, but does not generalize well across neighborhoods of varying race.
  
  Below we provide both spatial and aspatial goodness of fit metrics.
  
  ###Average goodness of fit results
  
  The table below displays the goodness of fit metrics for each of the sub-models and the meta-model. Mean and standard deviation of different metrics are calculated. Means are taken to describe relative goodness of fit across each held out neighborhood. Standard deviations are taken to describe the variation in goodness of fit across each held out neighborhood. If the model generalizes well across neighborhoods, then the standard deviation should be relatively low. 
  
  
  ```{r include = TRUE}
  Model_Error_Results_table
  ```
  
  R2 or R Squared is a traditional measure of goodness of fit. Although typically not used to evaluate count outcomes, we include it here because it will be familiar to many readers. 
  
  MAE or Mean Absolute Error is the absolute difference between the observed maltreatment counts and predicted counts. The meta-model MAE equates to roughly one half of one maltreatment event on average. This suggests the model is accurate. The relatively high standard deviation of MAE suggests that greater errors can be found certain places, namely those with very high maltreatment counts.
  
  RMSE or Root Mean Squared Error is the standard deviation of the prediction error. Like MAE, RMSE is reported on the scale of the dependent variable, but it varies in that the metric is weighted heavily by errors of high magnitude. 
  
  For the Logarithmic Score (logdev) the mean is `r round(meta_log_mean,3)` with a standard deviation of `r round(meta_log_sd, 3)`. This equates to a 95% confidence interval between `r meta_log_error_lower` and `r meta_log_error_upper` for the population average. The intuition of this result is that on average, the probability that the model estimates are correct given the documented maltreatment counts is between `r meta_log_error_lower` and `r meta_log_error_upper`. While the population average of errors from independent LOGOCV estimates is helpful for assessing how the model generalized, it is equally important to know how these errors are distributed both statistically and across space.
  
  Of note in the above table is the reduction in not only MAE and logdev but perhaps more importantly is a reduction in the standard deviation in those metrics across all of the 149 neighborhoods. The meta-model results in an average MAE of `r round(meta_MAE_mean, 3)` with a standard deviation of `r round(meta_MAE_sd, 3)`. The 95% confidence interval for the meta-model MAE across the entire population of neighborhoods is between `r meta_MAE_error_lower` and `r meta_MAE_error_upper`. Since MAE is on the scale of absolute count of maltreatment events, this means that the population average MAE is less than one incident.
  
  Figure 6.1 visualizes predicted vs. observed maltreatment event counts for the meta-model. The black line represents a perfect fit while the blue line represents the predicted fit. This plot provides visual evidence of an accurate model. Nevertheless, the plot also shows that the model errors are much higher for the highest observed counts. In other words, the model fits most of the data well but breaks down in grid cells with far greater counts. As we discuss below, this has some ramifications with respect to generalizability.
  
  ```{r include = TRUE, fig.align = "center"}
  plot_fold_pred(ens_cv_tbl$pred, ens_cv_tbl$test_y, type = "fit") +
    labs(x = "Observed Maltreatment Counts",
         y = "Predicted Maltreatment Counts",
         title = "Predicted vs. observed maltreatment counts",
         caption = "Figure 6.1") +
    plotTheme() +
    theme(panel.border = element_blank())
  ```
  
  ###Mapping goodness of fit
  
  From the spatial perspective, Figure 6.2 illustrates the MAE and predicted maltreatment count for each of the three sub-models and the meta-model. The plots show that each model's approach to prediction is unlike its peers. The Poisson linear model is focused on the main areas of recorded maltreatment with lower variance outside of the City of Richmond population centers. The Random Forest model includes a higher degree of variance across areas where few incidents are documented, but where underlying risk and protective features are present. The SDM model incorporates knowledge of the underlying spatial organization of both maltreatment events and risk/protective factors. Given that the SDM model is fit and estimated on the full Richmond dataset, that information is translated into the 'patchiness' of the estimates. Finally, the meta-model exhibits a pattern of prediction that moderates the three sub-models and identifies the known areas of higher maltreatment rates. Note that the meta-model predicts areas as having high risk where the risk/protective factors are present, but recorded events are few. 

```{r include = TRUE, fig.height=12}
cowplot::plot_grid(POISSON_MODEL_PREDICTION_MAP_plot, RF_MODEL_PREDICTION_MAP_plot, SARLM_MODEL_PREDICTION_MAP_plot, META_MODEL_PREDICTION_MAP_plot, ncol = 1, align = "hv", axis = "lrbt")
```

Further complementing these findings, Figure 6.3 shows the goodness of fit metrics broadened to the neighborhood level for the meta-model estimates. These goodness of fit indicators were created by way of LOGOCV. Generally speaking, the MAE and Logarithmic Score metrics follow a similar pattern with higher errors in neighborhoods with higher rates of maltreatment events. 

If the model was perfectly generalizable, model errors by neighborhood would be randomly distributed. The map in Figure 6.3 shows that MAE clusters slightly, particularly in neighborhoods in the northeast of the city. A Global Moran's I test confirms the clustering of errors, with a p-value of 0.001.
  
  ```{r include = TRUE, fig.width=12, fig.height=5}
  cowplot::plot_grid(LOGDEV_BY_NEIGHBORHOOD_plot,MAE_BY_NEIGHBORHOOD_plot,align = "h")
  ```
  
  ###Feature importance 
  
  Next, we try to get under the hood of the model. We do this first, by visualizing feature importance. The below plot visualizes 'feature importance' for the Random Forest sub-model, showing which features make the greatest contribution in predicting maltreatment. We caution the reader to consider these relationships the result of correlation, not causation. The most important predictor, `NN_CPS_Accepted`, is the spatial lag variable used to account for the spatial externalities associated with maltreatment. Four of the top ten features relate to domestic occurrence of crime including assault and juvenile runaway. Three of the top ten are control variables describing demographic and housing unit characteristics. We also see other significant exposure factors including vacant housing, community centers and motels. 
  
  ```{r include = TRUE, fig.height=7.5, fig.width=10}
  RF_VARIMP_PLOT
  ```
  
  ###Neighborhood typology comparison
  
  Income and race are inextricably linked to many of the census and exposure features used in the model, but no variables directly measuring race or income are included in the models. While feature importance provides some glimpses into how the model predicts, the best way to understand the inner-workings of a model is to look for patterns in how it predicts. Our approach for doing so, tests how well the model generalizes across both rich and poor neighborhoods as well as white and minority neighborhoods. 
  
  Two census attributes are selected for these purposes including percent living below poverty and percent non-white. These census data are joined to [Neighborhood Statistical Areas](https://data.richmondgov.com/Well-Managed-Government/Neighborhood-Statistical-Areas/tddt-q3bd/data) (NSA) and high and low neighborhood typologies are created.
  
  Next, median meta-model predictions are calculated for each NSA and goodness of fit is compared between high and low areas. Table 6.2 lists the median Logarithmic Score for both the high and low classes for each of the census variables. If the model generalizes well to both neighborhood typologies, the Logarithmic Score should be comparable across high and low categories. We find this to be true for poverty-related differences across the city but less so for race-related differences. 
  
  ```{r include = TRUE}
  data.frame(rbind(cbind(Poverty="Low",Log_score=.658,Count_events=668),
                   cbind(Poverty="High",Log_score=.635,Count_events=1145))) %>%
    kable() %>%
    kable_styling()
  
  data.frame(rbind(cbind(Non_White="Low",Log_score=.757,Count_events=524),
                   cbind(Non_White="High",Log_score=.471,Count_events=1289))) %>%
    kable() %>%
    kable_styling()
  ```
  
  This suggests the model generalizes well to places with varying incomes but generalizes less well to neighborhoods of different racial composition. A portion of this finding has to do with the very high maltreatment counts that the model cannot account for. These are the areas where more than six maltreatment events have been recorded for a single apartment building. This may suggest that some spatial externalities exist at scales smaller than that of our current model. Perhaps future iterations of this model can account for this building scale variation, which may help correct for some of the bias described in Table 6.2.
  
  ###Comparing meta-model predictions to Kernel Density
  
  Perhaps the strongest method for assessing the usefulness of a predictive model is to compare its predictive power to that of the current resource allocation strategy. Although no equivalent decision making tool exists in Richmond, we can compare our model to another common spatial targeting algorithm - Kernel Density Estimation (KDE). 
  
  KDE is a simple spatial interpolation technique that calculates 'predicted risk' by taking a weighted local density of maltreatment events. No risk/protective factors are used and no measures of statistical significance can be calculated. To compare between the meta-model predictions and KDE, predictions from both are divided into five risk categories for the purposes of comparison. We then overlay held out maltreatment events that were not used to fit the original model, and calculate the percent of observed maltreatment events that fall into each predicted risk category. 
  
  Figure 6.4 maps the comparison. The KDE clearly picks up the main areas of recorded events, but also interpolates high predictions for maltreatment in the areas between and beyond. The meta-model is far more targeted. 
  
  ```{r include = TRUE, fig.width=10}
  REALTIVE_SENSITIVITY_PREDICTIONS2 <- ggmap(cps_base_map) +
    geom_sf(data = ll(p.summ), aes(fill = factor(sens_group)), 
            color = NA, alpha = 0.8, inherit.aes = FALSE) +
    geom_sf(data = ll(cps_dissolve), inherit.aes = FALSE, size = 1) +
    scale_fill_viridis_d(na.value = NA, option = "D", direction = 1,
                         name = "Risk\nCategory") +
    labs(title = "Risk categories from Meta-Model") +
    mapTheme()
  
  cowplot::plot_grid(REALTIVE_SENSITIVITY_KDE, REALTIVE_SENSITIVITY_PREDICTIONS2, align = "h")
  ```
  
  Figure 6.5 formalizes the comparison in chart form. The highest risk category risk category for the meta-model captures approximately 70% of the recorded maltreatment events, whereas the KDE captures only about 35%. This suggests that the spatial risk model vastly outperforms KDE.
  
  ```{r include = TRUE, fig.width=8}
  ggplot(data=countComparisonsLong, aes(Category,Value)) +
    geom_bar(aes(fill = Variable), position = "dodge", stat="identity", color = NA) +
    scale_fill_viridis_d(name = " ",
                         labels=c("Risk & Protective\nFeatures", "Kernel Density")) +
    labs(x= "Predicted Risk Levels",
         y="Percent of Test Set Cases",
         title= "Goodness of fit: Spatial risk model vs. Kernel Density",
         caption = "Figure 6.5") +
    plotTheme()
  ```
  
  
  ##7. Conclusion
  
  We set out to create a tool for embedding predictive modeling into the decision-making process of child welfare stakeholders. We provide several descriptive spatial and statistical analytics for understanding maltreatment across Richmond. Our model predicts child maltreatment accurately relative to a more traditional Kernel Density approach and exhibits little bias with respect to income.
  
  The model correctly predicts high maltreatment risk in several African American communities in the northeast of Richmond. In these places, observed maltreatment events occur at much higher rates than others areas of the city. Although the model correctly highlights these areas as high risk, these outlying counts lead to higher errors which suggest, at least mechanically, that the model may exhibit some bias toward African American communities. As discussed in Section 6, some of these errors may be due to unaccounted variation in the built environment - namely that many of these events happen in the same apartment complex. Future models that control for these parcel level features may help adjust for these anomalies.
  
  Our predictions show where maltreatment risk is at its greatest. We hope that stakeholders will use this metric to help guide education and prevention resources. In Section 2, model predictions are then used as inputs into spatial analysis that ask to what extent the supply of child welfare services align to the demand for these services. We show areas where more protective factors are needed. The only required input for this analysis from the model are the predictive risk categories. The hope is that stakeholders will repeat this analysis with other datasets towards the completion of a strategic plan for combating child maltreatment in Richmond.
  
  Finally, the code presented in the appendices below include all the tools required for replicating our analysis. While we will continue to develop this codebase into a more easy to use package for replicating the analysis, we hope curious civic technologists will adopt the code for their own purposes.
  
  ## Appendix 1: Data wrangling
  This appendix documents some key elements of loading, cleaning, and the initial manipulation of this project's data. As with each of the code appendices, the code blocks here do not show the entire source code, but do show most of the key functions and routines used to achieve these tasks. The code illustrated here follows the basic steps of:

1.  detect all `xls` and `csv` files in a directory and read them into a list
2.  Import spatial neighborhood data with `read_sf()` and `get_decennial()`
3.  create spatial fishnet grid with `st_make_grid()` and calculate spatial weights with `poly2nb()` and `nb2listw()`
4.intersect fishnet and census blocks to create populations estimates and weights per fishnet cell


This Code example of data import function. The inputs are `.xls`, `.xlsx`, and `.csv` files in a folder. The output is a `list` data type where each element of the list if one of the input data sets in the `sf` spatial data format.
```{r APPENDIX_1a, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Read data filenames
files <-list.files(file.path(base_dir,"/data"), pattern = "*\\.xls$|*\\.csv$")
var_list <- vector(mode = "list")
var_names <- NULL
# Loop over files and load
for(i in seq_along(files)){
  filename <- str_sub(files[i], start = 1, end = -5)
  sf_i <- tryCatch({
    if(tools::file_ext(files[i]) == "xls"){
      dat <- readxl::read_xls(file.path(base_dir,"data",files[i])) 
    } else if(tools::file_ext(files[i]) == "csv"){
      dat <- read.csv(file.path(base_dir,"data",files[i])) 
    }
    dat %>%
      filter(!is.na(X) | !is.na(Y)) %>%
      # Make files spatial `sf` object and assign geographic projection
      st_as_sf(., coords = c("X", "Y"), crs = 102747)
  }, error = function(e){
    cat(filename, "error = ",e$message,"\n")
    return(e)
  }
  )
  # add dataframes to list
  if(!inherits(sf_i, "error")){
    var_list[[length(var_list)+1]] <- sf_i
    var_names[length(var_list)] <- filename
  }
}
names(var_list) <- var_names
```


Code chunk demonstrating the reading of neighborhood and census block data from the web. The `read_sf()` function reads a `geojson` format file from the web and makes it into an `sf` files. This file is converted into a `raster` file type. the census block attribute for total population `P0010001` is read from the U.S. Census API using the `get_decennial` function. It is made into an `sf` object and calculations are made.
```{r APPENDIX_1b, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Get Richmond neighborhoods
nbr <- read_sf("https://data.richmondgov.com/resource/7juf-nwis.geojson")  %>%
  st_sf() %>%
  st_transform(102747)
# Create neighborhood outline
nbr_diss <- nbr %>%
  mutate(dissolve = 1) %>%
  # get rid of slivers
  st_buffer(., dist = 0.1) %>%
  group_by(dissolve) %>%
  summarise()

# Create neighborhood raster
nbr_rast_SP <- raster(as(nbr_diss, "Spatial"), nrows = 2000, ncol = 2000)

# Query Population data
vars10 <- c("P0010001") # total population
# Get total 2010 census population for blocks & calculate area
richmond_block <- get_decennial(geography = "block", variables = vars10, year = 2010,
                                summary_var = "P0010001", state = 51, county = 760, geometry = TRUE) %>%
  st_transform(crs = 102747)

# Calculate area
richmond_block <- richmond_block %>%
  mutate(acre = as.numeric(st_area(richmond_block)*2.29568e-5),
         # acre = units::set_units(acre, acre), 
         pop_acre_rate = value / acre) 
```


This block demonstrates the creation of the the spatial fishnet grid used as the unit of analysis for this project. The `sf_make_grid` function from the `sf` package makes this quite easy. A geographical intersect returns filters the fishnet to the cells that are with or touching the boundaries of Richmond City. Finally, the spatial neighborhood list is constructed. This is used by the spatial regression model to calculate spatial weights
```{r APPENDIX_1c, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# set global parameter for fishnet grid dimensions
fishnet_grid_dim = 1200
# Fishnet creation
net <- st_make_grid(nbr, cellsize = fishnet_grid_dim) 

# Count CPS incidents per net cell
net_agg <- aggregate(cps_dissolve, net, sum) %>%
  tibble::rowid_to_column(.,"net_id")

# List of net cells IDs that intersect with Richmond Neighborhoods
net_intersect <- st_intersects(nbr, net_agg) 

# Extract Richmonds net cells based on intersect ID
net_Richmond <- net_agg[unique(unlist(net_intersect)),]

# Join neighborhood attributes to fishnet grid cells
net_hood <- st_join(net_Richmond, nbr, largest = TRUE)

# Calculate spatial neighborhood matrix
listw <- nb2listw(poly2nb(as(net_Richmond, "Spatial"), queen = TRUE))
```


In this final code example, the area weights population of each fishnet cell is calculated. The first step is to intersect the census blocks with the fishnet to create polygons of every intersecting region. After calculating the proportion of each Census block within each fishnet cell intersection and the matching proportion of that intersection, the `intersect_pop` populations are summed for each fishnet cell. The result is an estimate of the population of each fishnet cell based on the area and population of each census block that overlaps with it. Cells with zero population are dropped. Finally, the aggregated counts of maltreatment incidents are joined to the fishnet and a rate of incidents per 100 population is calculated.
```{r APPENDIX_1d, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Compute intersection of census blocks and fishnet
net_blocks_intersect <- st_intersection(richmond_block, net_Richmond)

# ... Calculate percent of each blocks area within each fishnet cell and divide block pop by that percent

# Summerise population by fishnet cell
fishnet_pop <- net_blocks_intersect %>% # xcc
  group_by(net_id) %>%
  summarise(net_pop = sum(intersect_pop)) %>%
  filter(net_pop > 0)   # <-  zeros or no zeros!!!!

# ... make cps_agg which is aggregate of each variable by cell

# Spatial join of fishnet_pop and fishnet_cps to then calculate rate for all CPS features
fishnet_pop_cps <- st_join(fishnet_pop, CPS_agg, join = st_equals) %>%
  mutate_at(vars(paste0("net_",CPS_vars)), funs(rate = ./(net_pop/100)))  %>% # cps per 100 person
  rename_at(vars( contains( "_rate")), funs(paste("rate", gsub("net_|_rate", "", .), sep = "_"))) %>% 
  replace(is.na(.), 0) # replace NA with zero

```


## Appendix 2: Feature engineering
This appendix documents some key elements of creating the variables, features, and data frames used in the train and test the machine learning models. As with each of the code appendices, the code blocks here do not show the entire source code, but do show most of the key functions and routines used to achieve these tasks. The code illustrated here follows the basic steps of:

1.  Compile relevant spatial point features from `var_list` into Protective and Risk specific spatial objects
2.  Create Nearest Neighbor, Aggregate Count, and Euclidean Distance features for Risk and Protective variables. Compose into single data frame of all features per fishnet cell
3.  Computer correlation between all features and dependent variable
4.  Select feature type with highest absolute correlation for each variable
5.  Combine selected features types for both Risk and Protective features and standardize independent variables


This code block illustrates the processes of selecting the pre-determined Risk and Protective variable from the `var_list` list that contained all for he candidate variables evaluated in this project. These steps are much more of a data processing step than an analytical step.
```{r APPENDIX_2a, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Create list of Protective variables
protective_class <- c("CommunityCenters","FireStations",
                      "HomelessShelters","Libraries","Parks","PointsOfInterest",
                      "PoliceStations","PublicSchools","ResourceOASIS","SNAP_WIC",
                      "VotingStations")
# Add column for variable set name and assign to new list
protective_vars <- list()
for(i in seq_along(protective_class)){
  dat <- var_list[[protective_class[i]]] %>%
    mutate(feature_name = protective_class[i],
           class = "protective") %>%
    dplyr::select(feature_name, class)
  protective_vars[[i]] <- dat
}

# Pull protective features from business features
Businesses_protective <- var_list[["BusinessProject"]] %>%
  filter(Classification == "PROTECTIVE") %>%
  mutate(feature_name = "BusinessProject",
         class = "protective") %>%
  dplyr::select(feature_name, class)
# Add to protective feature list
protective_vars[[length(protective_vars)+1]] <- Businesses_protective
# Turn into a spatial sf object with columsn for feature name, protective vs. risk class, and point coordinates
protective_vars <- do.call(rbind, protective_vars)
# Add dataframe to varaibles list
var_list[["Protective"]] <- protective_vars

## Simialr to above, but for Risk variables
risk_class <- c("BusStops")
risk_vars <- list()
for(i in seq_along(risk_class)){
  dat <- var_list[[risk_class[i]]] %>%
    mutate(feature_name = risk_class[i],
           class = "risk") %>%
    dplyr::select(feature_name, class)
  risk_vars[[i]] <- dat
}
# Business risks
Business_risk <- var_list[["BusinessProject"]] %>%
  filter(Classification == "RISK") %>%
  mutate(feature_name = "BusinessProject",
         class = "risk") %>%
  dplyr::select(feature_name, class)
risk_vars[[length(risk_vars)+1]] <- Business_risk
# Crime realted risks
CrimeData_risk <- var_list[["CrimeData"]] %>%
  filter(OFFENSE %in% c('DRUG/NARCOTIC VIOLATION','SIMPLE ASSAULT, DOMESTIC',
                        'Runaway','AGGRAVATED ASSAULT DOMESTIC')) %>%
  mutate(feature_name = "CrimeData",
         class = "risk") %>%
  dplyr::select(feature_name, class)
risk_vars[[length(risk_vars)+1]] <- CrimeData_risk
# Code violation risks
Violations_III_ks_risk <- var_list[["Violations_III_ks"]] %>%
  filter(CodeDsrp %in% c('General Violations','Unsafe Structure',
                         'Unfit Structure')) %>%
  mutate(feature_name = "Violations_III_ks_risk",
         class = "risk") %>%
  dplyr::select(feature_name, class)
risk_vars[[length(risk_vars)+1]] <- Violations_III_ks_risk
# Bind into dataframe
risk_vars <- do.call(rbind, risk_vars)
# Add to var_list
var_list[["Risk"]] <- risk_vars
```

This code block contains the three functions for turning the geographic point representation of each variable into a feature representation usable in regression or classification. This featureization is done in three different ways with the intent to capture different aspects of the spatial relationship between feature points (e.g. crime, code violations, certain businesses, etc...) and maltreatment events. The three ways of measuring this are 1) the mean Nearest Neighbor with `NN_point_features`, 2) the mean Euclidean distance to all points with `Euclidean_point_features`, 3) and the simple count of all points within each fishnet grid cell with `Aggregate_points_Features`. These function are written to use the `foreach()` and `%dopar` functions of the `foreach` package in order to execute the code using multiple processor cores. This helps to improve the efficiency of the computations. At the end of this code block, all of the features are joined together into a single data frame.
```{r APPENDIX_2b, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Functions to make thee feature types:
# Mean Nearest Neighbor distance
NN_point_features <- function(var_list, fishnet, k){
  NN_results <- foreach(i = seq_along(var_list),
                        .export=c('nn_function'),
                        .packages=c('raster', 'sf', 'dplyr', "FNN", "tibble", "tidyr")) %dopar% { 
                          feature <- names(var_list)[i]
                          # Create centroid of fishnet cell
                          fishnet_centroid_XY <- st_coordinates(st_centroid(fishnet))
                          dat <- var_list[[i]] 
                          # If more features the `k` nearest neighbors...
                          if(nrow(dat) >= k){
                            # get mean distance and id for `k` nearest neighbors ...
                            # from center of each fishnet cell
                            net_NN <- nn_function(fishnet_centroid_XY,
                                                  st_coordinates(dat)[,1:2], k) %>%
                              mutate(feature_name = paste0("NN_",feature),
                                     net_id = fishnet$net_id) %>%
                              left_join(., fishnet, by = "net_id") %>%
                              rename("value" = value.x) %>%
                              dplyr::select(-value.y) %>%
                              st_as_sf()
                          } else {
                            # If there are not enough features to make NN, then it is NA
                            net_NN <- data.frame(value = rep(NA, nrow(fishnet))) %>%
                              mutate(feature_name =  paste0("NN_",feature),
                                     net_id = fishnet$net_id) %>%
                              left_join(., fishnet, by = "net_id") %>%
                              rename("value" = value.x) %>%
                              dplyr::select(-value.y) %>%
                              st_as_sf()                       
                          }
                        }
  names(NN_results) <- paste0("NN_",names(var_list))
  return(NN_results)
}

# Nearest Euclidean Distance
Euclidean_point_features <- function(var_list, dist_raster, raster_mask, fishnet){
  ED_results <- foreach::foreach(i = seq_along(var_list), 
                                 .combine='comb', .multicombine=TRUE,
                                 .init=list(list(), list()),
                                 .export=c('distanceFromPoints', 'raster_to_fishnet'),
                                 .packages=c('raster', 'sf', 'dplyr')) %dopar% { 
                                   feature <- names(var_list)[i]
                                   # Calculate distance raster from all point features
                                   bs_dist <- distanceFromPoints(dist_raster, 
                                                                 sf::st_coordinates(var_list[[feature]]))
                                   # Clip raster to Richmond City
                                   bs_clip <- raster::mask(bs_dist, mask = as(raster_mask, "Spatial"))
                                   # Extract raster distance values within each fishnet cell and take mean
                                   fea_mean_dist <- raster_to_fishnet(bs_clip,fishnet,paste0("ed_",feature))
                                   list(fea_mean_dist, bs_clip)
                                 }
  # Add results to list
  dist_results <- ED_results[[1]]
  dist_rasters <- ED_results[[2]]
  names(dist_results) <- paste0("ED_",names(var_list))
  names(dist_rasters) <- paste0("ED_",names(var_list))
  return(list(dist_results, dist_raster))
}

# Aggregare Point Count
Aggregate_points_Features <- function(var_list, fishnet){
  agg_results <- foreach(i = seq_along(var_list),
                         .packages=c('raster', 'sf', 'dplyr')) %dopar% { 
                           feature <- names(var_list)[i]
                           dat <- var_list[[i]] %>%
                             mutate(value = 1) %>%
                             dplyr::select(value)
                           # Count feature points within each fishnet grid cell
                           net_agg <- aggregate(dat, fishnet, sum) %>%
                             mutate(feature_name = paste0("agg_",feature),
                                    net_id = fishnet$net_id)
                         }
  names(agg_results) <- paste0("agg_",names(var_list))
  return(agg_results)
}

#Make `ALL_FEATUES` dataframe by joining all Mean Nearest Neighbor, Mean Euclidean Distance, and Aggregare Count features
ALL_FEATURES <- full_join(NN_features, agg_features, by = "net_id") %>%
  full_join(.,ED_features, by = "net_id") %>%
  # Join in census data features
  full_join(.,sf1_features, by = "net_id")

# Clean up joined fields and replace `NA` with zeros
ALL_FEATURES <- ALL_FEATURES %>%
  dplyr::select(-cps_rate.y, -cps_rate.x.x, -cps_rate.y.y, 
                -cps_net.y, -cps_net.x.x, -cps_net.y.y,
                -net_pop.y, -net_pop.x.x, -net_pop.y.y) %>%
  dplyr::select(-contains("_CPS_")) %>%
  dplyr::rename(cps_net  = cps_net.x,
                cps_rate = cps_rate.x,
                net_pop  = net_pop.x) %>%
   mutate_all(funs(replace(., is.na(.), 0)))  %>%
  dplyr::rename_all(funs(make.names(.)))

```


Following the featurization demonstrated above, the pairwise Pearson's correlation of each feature and the dependent variable is computed using the `cor()` function. In order to perform feature selection on the three different ways of measuring the spatial relationships (e.g. mean Nearest Neighbor, mean Euclidean distance, and Aggregate count), the feature type with the highest absolute correlation is selected. This is achieved using the combination of `slice()` with `which.max()` functions.
```{r APPENDIX_2c, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Compute correlation between all pariwise features
cps_cor_ALL <- cor(ALL_FEATURES)
All_cors <- cps_cor_ALL[,"cps_net"]
# Compute p-values
p.mat_ALL <- cor.mtest(ALL_FEATURES)$p
p.mat_ALL <- p.mat_ALL[,which(colnames(cps_cor_ALL)=="cps_net")]
# Prepare data for plotting
cor_ALL_plot <- data.frame(feature = names(All_cors), 
                           cor = as.numeric(All_cors),
                           p_value   = p.mat_ALL) %>%
  filter(!(feature %in% c("cps_rate","cps_net","net_pop","net_cps","net_id"))) %>%
  filter(!(feature %in% grep("CPS", names(All_cors),value=T))) %>%
  arrange(desc(cor)) %>% 
  mutate(p_value = ifelse(p_value >= 0.1, "Not Significant", "Significant"))
cor_ALL_plot$feature <- factor(cor_ALL_plot$feature,
                               levels=cor_ALL_plot[order(cor_ALL_plot$cor,
                                                         decreasing=F),]$feature)

# For wach Protective variable, extract the feature type (mean NN, mean distance, aggregate) that as the highest absolute correlation
features_strong_protective_names <- cor_ALL_plot %>% 
  filter(feature %in% names(features_protective_all)) %>%
  mutate(prefix = str_extract(feature, "^[^_]+(?=_)"),
         suffix = str_extract(feature, "(?<=_)[^_].*"),
         feature = as.character(feature)) %>%
  group_by(suffix) %>%
  # Highest absolute correlation
  slice(which.max(abs(cor)))
features_protective_strong <- features_protective_all %>%
  dplyr::select(features_strong_protective_names$feature,
                NN_CPS_Accepted,
                cps_net, cps_rate, net_pop, net_id)

# Do the same for Protective
```

Finally, once the feature representation for each Risk and Protective variable is selected based on correlation, the features are joined into a single data frame. With some additional minor manipulation, this data frame will be the basis of the regression modeling that follows.
```{r APPENDIX_2d, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Join Risk and Protective features to selected census feaures to form data for regression models
og_dat <- full_join(features_risk_strong, features_census_select, by = "net_id") %>%
  full_join(., features_protective_strong, by = "net_id") %>% 
  dplyr::select(-net_pop.y, -cps_net.y, -cps_rate.y,
                -net_pop.x, -cps_net.x, -cps_rate.x,
                -NN_CPS_Accepted.y) %>% 
  rename("NN_CPS_Accepted" = NN_CPS_Accepted.x)

# Remove unneeded columns and center & scale all variables except the dependent variable
dat    <- og_dat %>% dplyr::select(-cps_rate, -net_pop, -net_id) %>%
  mutate_at(vars(-cps_net), scale_this)
# Add neighborhood name
net_hood <- st_join(net_Richmond, nbr, largest = TRUE)
og_dat$.block_id <- net_hood$name
```


## Appendix 3: Exploratory Analysis
This appendix documents some key elements of exploring and visualizing the features of this data set. The process of viewing, aggregating, and testing the data set in various undirected ways is referred to as Exploratory Data Analysis (EDA). As with each of the code appendices, the code blocks here do not show the entire source code, but do show most of the key functions and routines used to achieve these tasks. The code illustrated here follows the basic steps of:
  
  1.  Mapping maltreatment event counts and rates by fishnet cell
2.  Plotting the redecoration of maltreatment events across a range of time scales
3.  Visualizing the spatial trends of all Risk and Protective features
4.  Calculating Global and Local Moran's I statistics


The first exploration of code is to map the count and rate of maltreatment incidents by fishnet cells. This done at a range of fishnet cells dimensions and for a variety of types of maltreatment events to better understand the spatial trends. The `make_cuts()` function uses the `Hmisc::cut2()` function to partition the data. In the `ggplot2` plot, the `ggmap::ggmap()` function allows for data to be overlain on base maps of various styles.
```{r APPENDIX_3a, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# bin the countof maltreatment events
fishnet_pop_cps_cut <- fishnet_pop_cps %>%
  mutate(net_CPS_Accepted = ifelse(is.na(net_CPS_Accepted), 0, net_CPS_Accepted)) %>% 
  make_cuts(., "net_CPS_Accepted", cuts = "breaks", n_breaks = 10)
# plot maltreatment event counts on top of Richmond City basemap
CPS_COUNT_BY_FISHNET_PLOT <- ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_cut), aes(fill = cut_val), inherit.aes = FALSE, color = NA) +
  labs(title = "CPS Count per Fishnet Cell") +
  scale_fill_viridis_d(na.value = NA, option = "D", direction = 1, name = "CPS Count") +
  theme_bw()
```


This code example demonstrates a visualization of maltreatment events by normalized by month for each year in the data set. This shows each month of each years deviation from the average number of maltreatment events for that month across all years. This visualization also shows that for the years 2013 and 2017 only one-half of the years data is available. A number of examples of similar plots were viewed to understand the temporal patterns in maltreatment event redecoration. As with the vast majority of plots, the `ggplot2` library is used here.
```{r APPENDIX_3b, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Normalizes values by month
CPS_normalized_by_month <- st_drop_geometry(var_list[["CPS_Accepted"]]) %>%
    mutate(month = lubridate::month(RDate),
           year  = lubridate::year(RDate)) %>%
    group_by(year, month) %>%
    summarise(m_total = n()) %>%
    arrange(month, year) %>%
    dplyr::select(month, year, m_total) %>%
    ungroup() %>%
    group_by(month) %>%
    # Normalize
    mutate(m_mean = mean(m_total),
           m_sd   = sd(m_total),
           m_z    = (m_total - m_mean) / m_sd)
# Plot
CPS_LINE_NORMALIZED_plot <- ggplot(CPS_normalized_by_month, aes(x = as.factor(month), 
                                          y = m_z, group = year, 
                                          color = as.factor(year))) +
    geom_line() +
    geom_hline(yintercept = 0, color = "gray20", linetype = "dashed") +
    scale_y_continuous(limits = c(-2,2)) +
    theme_bw()
```


Additional spatial trends are describable from plotting Kernel Density Estimates (KDE) of each of the Risk and Protective features. A KDE is a spatial interpolation technique that can smooth out the spatial variation on counts to create a more continuous surface.  This surface can indicate larger scale trends that are not as evident with fishnet cell based features. Below is the code example for the Risk plot; the same is done for Protective features. The `geom_tile()` function in the `ggplot2` library allows from plotting raster data. The `dplyr` package `ntile()` function bins the values.
```{r APPENDIX_3c, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Risk KDE facet plot
RISK_KDE_FACET_PLOT <- ggmap(cps_base_map) +
  geom_tile(data = risk_plot_dat, 
            aes(x,y,fill = as.factor(ntile(value,brks)), 
                group = variable), alpha=0.5) +
  scale_fill_viridis_d(name = variable) +
  facet_wrap(~variable) +
  theme(
    axis.title=element_blank(),
    axis.text=element_blank(),
    axis.ticks=element_blank(),
    legend.key = element_rect(fill = "white"),
    strip.text = element_text(face = "bold", size = 12),
    legend.position = "none"
  )
```


This code block shows the general method for simulating possible Global Moran's I values given the spatial structure of the fishnet grid. The `knearneigh()`, `knn2nb`, and `nb2listw` from the `spdep` package are the tools needed to convert from the fishnet to the spatial weights list. The `moran.mc()` function from the same package does the work of simulating permutations of the Global  Moran's statistic and returning `nsim` number of results (see note in code comments). The observed Global  Moran's I value is also returned. This visualization uses `geom_vline()` to plot the observed value in reference to the distribution of simulated values to demonstrate how likely or unlikely the observed value is.
```{r APPENDIX_3d, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# Calculate fishent grid nearest neighbors using the "Queen" case (all directions)
# convert to a neighborhood graph
fishnet_knn <- knn2nb(knearneigh(fishnet_coords, k_direction))
# List of neighborhood weights
fishnet_Weights <- nb2listw(fishnet_knn, style="W")
# Simulate Global Moran's I with `999` simulations
globalMorans <- moran.mc(fishnet_pop_cps$net_CPS_Accepted, fishnet_Weights, nsim=999)

# Plot Global Moran's I simulated distribution and observed value
# note: the `globalMorans` I object will have 1000 rows, but only the first 999 are simulated. 
# The 1000th row is the observed value
GLOBAL_MORANS_PERMUTATION_plot <- ggplot(data.frame(res = globalMorans$res)[1:999,,0], aes(res)) + 
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = globalMorans$statistic), colour = "red",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I", x = "Simulated Moran's I Value") +
  theme_bw()
```


The final code example from the EDA phase of this project is the calculation and visualization of the Local Moran's I values. Using the same spatial neighborhood weights as above, the Local Moran's I is calculated with the `localmoran()` function of the `spdep` package. The data are joined together and plotted as three separate fishnet plots; the count of maltreatment events, binned Local Moran's I values, and the Local Moran's I p-value classified at alpha = `0.9` into significant and not significant clusters.
```{r APPENDIX_3e, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# calculate Local Moran's I for each fishnet cell
localMorans  <- as.data.frame(localmoran(fishnet_pop_cps$net_CPS_Accepted, fishnet_Weights))
# Moran's I join
fishnet_pop_cps_morans        <- fishnet_pop_cps
fishnet_pop_cps_morans$Ii     <- localMorans$Ii
fishnet_pop_cps_morans$pvalue <- localMorans$`Pr(z > 0)`
fishnet_pop_cps_morans        <- cbind(fishnet_coords, fishnet_pop_cps_morans)

# Bin maltreatment event counts
fishnet_pop_cps_morans_cut <- make_cuts(fishnet_pop_cps_morans, "net_CPS_Accepted",
                                        cuts = "breaks", n_breaks = 10)
# Plot maltreatment events (assign to a variable)
plot_cps <- ggmap(cps_base_map) +
  geom_sf(data = ll(fishnet_pop_cps_morans_cut), aes(fill = cut_val),
          color = NA, inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_viridis_d(na.value=NA, name = "Maltreatment Events", option = "D" ) +
  theme_void() +
  theme(
    legend.position = "right"
  )

# Bin Local Moran's I statistic
Ii_cut <- fishnet_pop_cps_morans %>%
  mutate(Ii_cut_val = as.character(Hmisc::cut2(.$Ii, 
                                               cuts = as.numeric(quantile(round(fishnet_pop_cps_morans$Ii,2), 
                                                                          na.rm=T, p = seq(0,1,0.25))))))
# plot binned Local Moran's I statistic (assign to a variable)
plot_Ii <- ggmap(cps_base_map) +
  geom_sf(data = ll(Ii_cut), aes(fill = Ii_cut_val),
          color = NA, inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_viridis_d(na.value=NA, name = "Local Moran's I", option = "D")+
  theme_void()+
  theme(
    legend.position = "right"
  )

# Bin Local Moran's I p-value
p_cut <- fishnet_pop_cps_morans %>%
  mutate(pval_cut = ifelse(pvalue > 0.05, "Not Significant", "Significant"))
# Plot binned p-value (assign to a variable)
plot_p <- ggmap(cps_base_map) +
  geom_sf(data = ll(p_cut), aes(fill = pval_cut),
          color = NA, inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_viridis_d(na.value=NA, name = "p-value", option = "D")    +
  theme_void()+
  theme(
    legend.position = "right"
  )
# use `cowplot` to put plots together
MORANS_I_P_plot <- cowplot::plot_grid(plot_cps, plot_Ii, plot_p, 
                                      rel_widths = c(0.9,0.9,0.9),
                                      ncol = 1, align = "v")
```


## Appendix 4: Modeling and Evaluation

This appendix documents some key elements of fitting machine learning models and evaluating their results. In these steps, the data manipulated and explored above is modeled to find the patterns and project those patterns back to the project area. From these projections, the goddness of fit is calculated and biases are uncovered. The purpose of this is to better understand the areas where factors contributing to maltreatment are present, but unreported, as well as understand conditions where the model may work better or worse. As with each of the code appendices, the code blocks here do not show the entire source code, but do show most of the key functions and routines used to achieve these tasks. The code illustrated here follows the basic steps of:
  
  1.  Refine data sets and establish the cross-validation folds (one fold for each neighborhood)
2.  Fit three machine learning models (Poisson GLM, Random Forest, and Spatial Durbin) to each neighborhood
3.  Extract model predictions and join to the fishnet and neighborhood spatial data
4.  Use the prediction from three models to create a meta-model via model stacking with Random Forest
5.  Calculate goodness of fit for both each Quintilian of the data distribution and overall
5.  Download neighborhood statistical area shapes, divide into high/low classes, and compute error
6.  Compute Kernel Density Estimate (KDE) of data distribution and compare to meta-model predictions

The approach used in this report to facilitate cross-validation is to use a combination of `tibble` data frames and `purrr::map()` functions within `dplyr::mutate()`. This approach allows for a single table to include all CV folds, models, and derivative errors or metrics. By using this method, the data are compiled into a single object where they can be easily subset, viewed, and analyzed. The cons of this approach are that there is a bit more computational overhead (but not significant in this case) and the syntax may not be familiar to sum R users. In the code below, the first four lines create the neighborhood fixed effects and adds them to the regression data. Following this, the `groupdata2::fold()` function is used to create the CV fold index stratified by the neighborhood `.block_id`. Finally, the `tibble`, `purrr`, `dplyr` routine creates the CV fold table used in the model fitting section.
```{r APPENDIX_4a, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
# neighborhood fixed effect model
hood_matrix <- model.matrix(cps_net~.block_id,og_dat)
hood_model <- lm(sqrt(og_dat$cps_net) ~ hood_matrix)
dat$hood_fixed <- predict(hood_model, type = "response")^2
og_dat$hood_fixed <- predict(hood_model, type = "response")^2
# Create CV neighborhood fold index
all_hoods <- length(unique(net_hood$name))
n_folds = ifelse(n_folds == "LOOCV", all_hoods, n_folds)
folds_index <- groupdata2::fold(og_dat, k = n_folds, id_col = '.block_id')$.folds
# create tibble with all CV folds and assocaited data
cv_tbl <- tibble(folds = seq_len(n_folds),
                 train = NA, train_y = NA, train_index = NA, train_net_id = NA,
                 test  = NA, test_y  = NA, test_index  = NA, test_net_id  = NA)
for(k in seq_len(n_folds)){
  fold_i  <- which(folds_index == k)
  cv_tbl[k,]$train         <- list(dat[-fold_i,])
  cv_tbl[k,]$test          <- list(dat[ fold_i,])
  cv_tbl[k,]$train_y       <- list(og_dat[-fold_i,target_var])
  cv_tbl[k,]$test_y        <- list(og_dat[ fold_i,target_var])
  cv_tbl[k,]$train_index   <- list(setdiff(seq(1:nrow(dat)),fold_i))
  cv_tbl[k,]$test_index    <- list(fold_i)
  cv_tbl[k,]$train_net_id  <- list(og_dat[-fold_i,"net_id"])
  cv_tbl[k,]$test_net_id   <- list(og_dat[ fold_i,"net_id"])
  ```  
  
  The model fitting used helper functions to make the use of `purrr::map()` more streamlines. The `glm_fit`, `rf_fit`, and `score_model()` functions make a consistent interface for the `map()` to interact with the `glm()`, `ranger()`, and goodness of fit functions functions. The spatial model is fit directly with `errorsarlm()` because it doe not use the CV folds due to the neighborhood weight matrix. For each model, after it is fit, predictions are made, and the model is scored.
  ```{r APPENDIX_4b, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
  # Helper function for GLM fit
  glm_fit <- function(dat, formula, family){
    glm_model <- glm(formula, data = dat, family = family)
    return(glm_model)
  }
  # HElper funtion for Random Forest fit
  rf_fit <- function(dat, formula, mtry_add = 0, importance = "none"){
    mtry <- floor(sqrt(ncol(dat)-1))+mtry_add
    rf_model <- ranger(formula, data = dat, 
                       mtry = mtry,
                       splitrule = "variance",
                       importance = importance,
                       num.trees = 500,
                       min.node.size = 10)
    return(rf_model)
  }
  # Helper function for model scoring
  score_model <- function(dat){
    dat <- dat %>%
      mutate(R2     = map2_dbl(pred, test_y, r_squared),
             MAE    = map2_dbl(pred, test_y, mae),
             MAAPE  = map2_dbl(pred, test_y, maape),
             RMSE   = map2_dbl(pred, test_y, rmse),
             logdev = map2_dbl(pred, test_y, logdev_p))
    return(dat)
  }
  # Fit the Poisson GLM model
  po_cv_tbl <- cv_tbl %>%
    mutate(fit   = map(train, glm_fit, 
                       formula =  paste("cps_net ~ ."), 
                       family = "poisson"),
           pred  = map2(fit, test, lm_predict, sqrt = FALSE),
           mdl_nam = "GLm - Poisson") %>% 
    score_model()
  # Fit the Random Forest model
  rf_cv_tbl <- cv_tbl %>%
    mutate(fit   = map(train, rf_fit, formula = "cps_net ~ .", mtry_add = 2, importance = "impurity"),
           pred  = map2(fit, test, lm_predict),
           mdl_nam = "Random Forest") %>% 
    score_model()
  # Fit the Spatial Durbin model
  spat_durbin <- errorsarlm(sqrt(cps_net) ~ ., data = dat, listw, etype ="emixed")
  spat_durbin_tbl <- tibble(
    fit   = list(spat_durbin),
    pred  = map(fit, sar_pred),
    test_y= list(dat$cps_net),
    test_net_id = list(og_dat$net_id),
    mdl_nam = "Spatial Durbin - sqrt") %>% 
    score_model()
  ```
  
  This code section demonstrates the extraction of the out-of-fold predictions from the model tibbles and joining of these to each other. Only the example for the Poisson regression is show, but the code for the other two models is nearly identical. The `unnest()` function allows for the data bound in the tibble to be extracted. The sequence of `left_join()` creates a data set of each models predictions and the associated  neighborhood characteristics. These are the data that are used to fit the stacked meta-model.
  ```{r APPENDIX_4c, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
  # Extract predictions from Possion model (same is done for other two models)
  po_pred_dat <- po_cv_tbl %>%
    unnest(pred) %>%
    mutate(test_y = po_cv_tbl %>% unnest(test_y) %>% pull(test_y),
           test_net_id = po_cv_tbl %>% unnest(test_net_id) %>% pull(test_net_id))
  # Plot prediction map
  po_pred_geoplot <- model_pred_geoplot(po_pred_dat$pred,
                                        po_pred_dat$test_y,
                                        po_pred_dat$test_net_id,
                                        net_Richmond, cps_base_map, "po")
  # Join all predictions from three models into single data frame
  cps_preds <- og_dat %>% 
    dplyr::select(net_id, cps_net) %>% 
    left_join(., dplyr::select(po_pred_dat,
                               net_id = test_net_id,
                               pred_lm = pred), by = "net_id") %>%
    left_join(., dplyr::select(rf_pred_dat, 
                               net_id = test_net_id,
                               pred_rf = pred), by = "net_id") %>% 
    left_join(., dplyr::select(sarlm_pred_dat, 
                               net_id = test_net_id,
                               pred_sarlm = pred), by = "net_id") %>% 
    mutate_if(is.double, round, 2)
  ```
  
  As was done above, a `tibble` is created to contain the CV folds; one for each neighborhood. The fold index `fold_index` is recycled here to make sure that the out-of-fold predictions are used here. This assures that the meta-model is fit to data that are independently predicted from the model. The final block of code reuses the `rf_fit()` helper function to fit the candidate model predictions with the `Random Forest` algorithm using `ranger()`.
  ```{r APPENDIX_4d, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
  # Create CV neighborhood folds for meta-model
  cps_preds_cv_dat <- dplyr::select(cps_preds, -net_id)
  ens_cv_tbl <- tibble(folds = seq_len(n_folds),
                       train = NA, train_y = NA, train_index = NA, train_net_id = NA,
                       test  = NA, test_y  = NA, test_index  = NA, test_net_id  = NA)
  for(k in seq_len(n_folds)){
    fold_i  <- which(folds_index == k)
    ens_cv_tbl[k,]$train         <- list(cps_preds_cv_dat[-fold_i,])
    ens_cv_tbl[k,]$test          <- list(cps_preds_cv_dat[ fold_i,])
    ens_cv_tbl[k,]$train_y       <- list(cps_preds_cv_dat[-fold_i,target_var])
    ens_cv_tbl[k,]$test_y        <- list(cps_preds_cv_dat[ fold_i,target_var])
    ens_cv_tbl[k,]$train_index   <- list(setdiff(seq(1:nrow(cps_preds_cv_dat)),fold_i))
    ens_cv_tbl[k,]$test_index    <- list(fold_i)
    ens_cv_tbl[k,]$train_net_id  <- list(cps_preds[-fold_i,"net_id"])
    ens_cv_tbl[k,]$test_net_id   <- list(cps_preds[ fold_i,"net_id"])
  }
  # Fit meta-model with Random Forest
  ens_cv_tbl <- ens_cv_tbl %>%
    mutate(fit   = map(train, rf_fit, formula = "cps_net ~ pred_rf + pred_sarlm"),
           pred  = map2(fit, test, lm_predict),
           # pred  = map(pred, round),
           mdl_nam = "Meta-Model") %>% 
    score_model()
  ```
  
  These code examples show the compilation of the goodness of fit measures for each model. The errors are aggregated in two different ways; first over the quantiles of maltreatment event counts and secondly by mean and standard deviation across all neighborhoods. The quantile errors are calculated by grouping the predictions with the `quantile_error()` function. The last block of code uses the base `mean` and `sd` functions to calculate metrics grouped by each model. The `knitr::kable()` and `kableExtra` packages are used to present the findings.
  ```{r APPENDIX_4e, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
  # Helper function for quantile error
  quantile_error <- function(pred,obs,quant){
    preds <- data.frame(pred = pred, obs = obs) %>%
      filter(quantile(seq(0,max(obs)), quant)>obs)
    return(preds)
  }
  # Join/bind model prediction tables
  models <- bind_rows(rf_cv_tbl, spat_durbin_tbl, ens_cv_tbl, po_cv_tbl)
  # Unnest predictions by model
  CV_preds_long <- models %>%
    group_by(mdl_nam) %>%
    unnest(pred, test_y) 
  ## Map over all quantiles to get error metrics
  quantile_errors <- CV_preds_long %>%
    nest(-mdl_nam) %>%
    mutate(q      = list(seq(0,1,0.01)),
           pred   = map(data, "pred"),
           test_y = map(data, "test_y")) %>%
    dplyr::select(-data) %>%
    unnest(q, .preserve = c(pred, test_y)) %>%
    filter(q != 0) %>% 
    mutate(q_dat  = pmap(list(pred, test_y, q), quantile_error),
           q_pred = map(q_dat, "pred"),
           q_obs  = map(q_dat, "obs"),
           q_RMSE = map2_dbl(q_pred, q_obs, rmse),
           q_MAE  = map2_dbl(q_pred, q_obs, mae),
           q_logdev  = map2_dbl(q_pred, q_obs, logdev_p),
           y_max  = quantile(seq(0,max(dat$cps_net)), q),
           q_cnt  = nrow(og_dat) - map_int(q_dat, nrow))
  
  # Map over all predictions grouped by model to calculate mean and sd for error metrics
  model_results <- models %>%
    dplyr::select("Model Name" = mdl_nam, R2, RMSE, MAE, logdev) %>%
    group_by(`Model Name`) %>%
    arrange(`Model Name`) %>%
    summarise(R2_mean      = mean(R2, na.rm=TRUE),
              R2_sd        = sd(R2, na.rm=TRUE),
              MAE_mean     = mean(MAE, na.rm=TRUE),
              MAE_sd       = sd(MAE, na.rm=TRUE),
              RMSE_mean    = mean(RMSE, na.rm=TRUE),
              RMSE_sd      = sd(RMSE, na.rm=TRUE),
              logdev_mean  = mean(logdev, na.rm=TRUE),
              logdev_sd    = sd(logdev, na.rm=TRUE)) 
  Model_Error_Results_table <- model_results %>%
    kable(., format = "html", digits = 3) %>%
    kable_styling()
  ```
  
  An important part of the evaluation of the meta-model is to compare it against important demographic factors that are not explicitly used in the model formulas. The `read_sf()` function retrieves spatial data for the neighborhood statistical groups (NSG) and `get_acs()` retrieves census data. The code that follows manipulates the census and NSG data by calculating percentages of population. After classifying the population percentage for both percent non-white and percent poverty, they are classified into high and low by diving at the 60the percentile. The errors are then aggregated to high and low classes using `aggregate()` and `make_cuts()`. Likewise the count of maltreatment events are aggregated in a similar manner. The last code chunk shows how the metrics are aggregated for poverty, but that same is done for percent non-white. 
  ```{r APPENDIX_4f, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
  # Download statarea
  nbr_statAreas <- read_sf("https://data.richmondgov.com/resource/8kyq-v9j2.geojson") %>%
    st_transform(crs = 102747) %>% 
    mutate(stat_area_id = id)
  
  # Download poverty and population data
  tract10 <- get_acs(geography = "tract", variables = c("B02001_001","B02001_002E","B17001_002"), 
                     year = 2010, state=51, county=760, geometry=T)
  # Aggregate data and make percentages
  tract10 <- tract10 %>%
    dplyr::select(variable,estimate) %>%
    as.data.frame() %>%
    spread(variable,estimate) %>%
    rename(TotalPop=B02001_001,
           NumberWhites=B02001_002,
           TotalPoverty=B17001_002) %>%
    mutate(percentNonWhite = ifelse(TotalPop > 0, ((TotalPop - NumberWhites) / TotalPop),0),
           percentPoverty  = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
           tract_id        = row_number()) %>%
    st_sf() %>%
    st_transform(102747) 
  tract10$tract_area <- st_area(tract10)
  
  # Aggreate mean errors to statareas
  stat_area_metric_logdev <- error_points %>%
    aggregate(., nbr_statAreas.spJoin, mean) %>%
    dplyr::select(logdev) %>% 
    mutate(logdev = round(logdev, 3)) %>% 
    make_cuts(., "logdev")
  stat_area_metric_MAE<- error_points %>%
    aggregate(., nbr_statAreas.spJoin, mean) %>%
    dplyr::select(MAE) %>% 
    mutate(MAE = round(MAE, 3)) %>% 
    make_cuts(., "MAE")
  
  # Aggregate sum of CPS incidents to statarea
  stat_area_cps <- error_points %>%
    aggregate(., nbr_statAreas.spJoin, sum) %>%
    dplyr::select(test_y)
  stat_area_errors <- stat_area_metric_logdev %>% 
    st_join(., stat_area_metric_MAE, join = st_equals) %>% 
    st_join(., stat_area_cps, join = st_equals) %>% 
    st_join(., nbr_statAreas.spJoin, join = st_equals)
  
  # Group by poverty and get median of statarea aggregate errors
  poverty_aggregate <- stat_area_errors %>% 
    group_by(poverty.percentile) %>% 
    summarise(med_dev = round(median(logdev),3),
              med_MAE = round(median(MAE),3),
              med_CPS = sum(test_y)) %>% 
    st_drop_geometry() %>% 
    dplyr::select(poverty.percentile, med_dev, med_MAE, med_CPS)
  ```
  
  The final code example from the meta-model evaluation phase is the comparison of prediction density between a KDE of maltreatment events and the meta-model predictions. The main parts of this section are the creation of the KDE using `spatstat::density.ppp`, the normalization of the predictions and KDE with the `bin_class()` function, and finally the plotting of spatial data and a bar plot for comparison. The `bin_class()` function takes in a vector of maltreatment event predictions or densities, bins them into quantiles with `.bincode()`, and then breaks the quantiles into five sensitivity classes with `cut()`. The code below shows the maltreatment event predictions aggregated by sensitivity class into the `p.summ` object. The approach is shown for aggregating the events by KDE sensitivity `kde.summ`. Finally, the percent of maltreatment events per sensitivity zone are counted for each of the meta-model predictions and KDE density sensitivity classes and plotted as a bar chart.
  ```{r APPENDIX_4g, eval=FALSE, echo=TRUE, include = TRUE, cache=FALSE}
  # Function to create sensitivity classes by binning and cutting quantities
  bin_class <- function(dat, bin_col = "pred", 
                        quantile_labels = 100, break_vec = c(-1, 30, 50, 70, 90, 100)){
    if(is(dat, "sf")){
      dat <- st_drop_geometry(dat)
    }
    pred_bin <- as.numeric(.bincode(dat[,bin_col]+1e-8, # wiggle factor to get above zero
                                    breaks = quantile(dat[,bin_col],
                                                      seq(0,1, by=(1/quantile_labels)), 
                                                      na.rm = TRUE,
                                                      labels = seq(1,quantile_labels,1))))
    pred_bin_class <- as.numeric(cut(pred_bin, 
                                     breaks = break_vec, 
                                     na.rm  = TRUE,
                                     labels = seq(1,length(break_vec)-1,1)))
    pred_bin_class <- ifelse(is.na(pred_bin_class), length(break_vec)-1, pred_bin_class)
  }
  
  error_geoplot$pred_bin_class <- bin_class(error_geoplot, "pred")
  # Count recorded incidents by meta-model prediction sensitivity classes
  p.summ <- error_geoplot %>%
    group_by(pred_bin_class) %>%
    dplyr::summarize(obs.total = sum(test_y),
                     obs.cnt = n()) %>% 
    rename(sens_group = pred_bin_class) %>%
    filter(!is.na(sens_group)) %>%
    identity()
  
  # Compute KDE
  cps_ppp <- as.ppp(st_coordinates(cps_dissolve), W = st_bbox(net_Richmond))
  cps_KDE <- spatstat::density.ppp(cps_ppp)
  # COnvert KDE to fishnet grid
  cps_KDE_tbl <- as.data.frame(cps_KDE) %>%
    st_as_sf(coords = c("x", "y"), crs = 102747) %>%
    aggregate(., net_Richmond, mean) %>%
    mutate(net_id = net_Richmond$net_id)
  
  error_geoplot$kde_bin_class  <- bin_class(cps_KDE_tbl, "value")
  # Count incident counts by KDE sensitvity classes
  kde.summ <- error_geoplot %>%
    group_by(kde_bin_class) %>%
    dplyr::summarize(kde.total = sum(test_y),
                     kde.cnt = n()) %>% 
    rename(sens_group = kde_bin_class) %>%
    filter(!is.na(sens_group)) %>%
    identity()
  
  # Compile counts of incidents from KDE and predictions then create percentages
  countComparisons <- merge(st_drop_geometry(p.summ), st_drop_geometry(kde.summ)) %>%
    mutate_if(is.double, round, 3) %>% 
    mutate(Category = rev(c("90% - 100%", "70% - 89%", "50% - 69%", 
                            "30% - 49%", "1% - 29%"))) %>%
    dplyr::mutate(kernelPct = round(kde.total / sum(kde.total),4),
                  fittedPct = round(obs.total / sum(obs.total), 4))
  
  countComparisonsLong <- countComparisons %>% 
    gather(Variable, Value, kernelPct:fittedPct)
  # Bat plot of results
  REALTIVE_RISK_BARPLOT_COMPARE_plot <- ggplot(data=countComparisonsLong, aes(Category,Value)) +
    geom_bar(aes(fill = Variable), position = "dodge", stat="identity", color = NA) +
    scale_fill_viridis_d(name = " ",
                         labels=c("Risk & Protective\nFeatures", "Kernel Density")) +
    labs(x= "Predicted Risk Levels",
         y="Percent of Test Set Cases",
         title= "Goodness of Fit: Spatial Risk Model vs. Kernel Density hotspot",
         caption = "Figure 1.6 - Kernel density comparison") +
    plotTheme() +
    theme(axis.line = element_blank())
  ```
  
  
  
  
  
  ## Appendix 5: List/description of functions objects
  
  ### Objects
  ```{r APPENDIX_3_OBJECTS, eval=TRUE, echo=FALSE, include = TRUE, cache=FALSE}
  # Objects
  objects <- data.frame("Name" = setdiff(ls(), lsf.str()), stringsAsFactors = FALSE) %>% 
    mutate(Class    = purrr::map_chr(Name, ~ class(get(.x))[1]),
           Size_kB  = purrr::map_dbl(Name, ~ round(object.size(get(.x))*0.001,2)),
           Rows     = ifelse(Class %in% c("data.frame","tibble"), 
                             purrr::map(Name, ~ nrow(get(.x))), NA),
           Columns  = ifelse(Class %in% c("data.frame","tibble"), 
                             purrr::map(Name, ~ ncol(get(.x))), NA),
           Length   = ifelse(Class %in% c("numeric","integer","character"), 
                             purrr::map(Name, ~ length(get(.x))), NA)) %>% 
    arrange(Name)
  
  objects %>%
    kable(., format = "html", digits = 3) %>%
    kable_styling()
  ```
  
  
  ### Functions
  ```{r APPENDIX_3_FUNCTIONS, eval=TRUE, echo=FALSE, include = TRUE, cache=FALSE}
  # Objects
  funs <-  data.frame("Name" = ls(), stringsAsFactors = FALSE) %>% 
    mutate(Class    = purrr::map_chr(Name, ~ class(get(.x))[1])) %>% 
    filter(Class == "function")  %>% 
    arrange(Name)
  
  funs %>%
    kable(., format = "html", digits = 3) %>%
    kable_styling()
  
  ```
  
  ## Footnotes
  
  [^1]: Virginia Department of Social Services. ["Abuse and Neglect by Locality Reports"](https://www.dss.virginia.gov/geninfo/reports/children/cps/all_other.cgi), 2013-2017.
  
  [^2]: Daley, Dyann, Michael Bachmann, Brittany A. Bachmann, Christian Pedigo, Minh-Thuy Bui, and Jamye Coffman. "Risk terrain modeling predicts child maltreatment." Child abuse & neglect 62 (2016): 29-38.
  
  [^3]: Durlauf, Steven N. "Neighborhood effects." In Handbook of regional and urban economics, vol. 4, pp. 2173-2242. Elsevier, 2004.
  
  [^4]: We do not map the raw point location data for privacy reasons.
  
  [^5]: Daley, Dyann, Michael Bachmann, Brittany A. Bachmann, Christian Pedigo, Minh-Thuy Bui, and Jamye Coffman. "Risk terrain modeling predicts child maltreatment." Child abuse & neglect 62 (2016): 29-38.
  
  [^6]: Hurley, Dan. "Can an Algorithm Tell When Kids Are in Danger?", The New York Times Magazine, Jan. 2, 2018.
  
  [^7]: Li, Jin and Andrew D. Heap. "A Review of Spatial Interpolation Methods for Environmental Scientists." Geoscience Australia, 2008.
  
  [^8]: Silverman, B.W. "Density Estimation for Statistics and Data Analysis." In Monographs on Statistics and Applied Probability, London: Chapman and Hall, 1986; Cressie, Noel A.C. "Statistics for spatial data." 1993; Dearmon, Jacob and Tony E. Smith. "Gaussian Process Regression and Bayesian Model Averaging: An Alternative Approach to Modeling Spatial Phenomena." Geographical Analysis (2016): vol. 48, p.82-111; Brunsdon, Chris, Stewart Fotheringham, and Martin Charlton. "Geographically Weighted Regression - Modelling Spatial Non-Stationarity." Journal of the Royal Statistical Society. Series D (The Staistician) (1998): vol. 47, no. 3, pp.431-443; Haining, Robert, Jane Law, and Daniel Griffith. "Modelling small area count in the presence of overdispersion and spatial autocorrelation." Computational Statistics & Data Analysis (2009): vol. 53, no. 8, p.2923-2937; Oliveira, Sandra, Friderike Oehler, Jesus San-Miguel_Ayanz, Andrea Camia, and Jose M.C. Pereira. "Modeling spatial patterns of fire occurrence in Mediterranean Europe using Multiple Regression and Random Forest." Forest Ecology and Management (2012): vol. 275, p.117-129.
  
  [^9]: Oliveira, Sandra, Friderike Oehler, Jesus San-Miguel_Ayanz, Andrea Camia, and Jose M.C. Pereira. "Modeling spatial patterns of fire occurrence in Mediterranean Europe using Multiple Regression and Random Forest." Forest Ecology and Management (2012): vol. 275, p.117-129; Leib, Mareike, Bruno Glaser, and Bernd Huwe. "Uncertainty in the spatial prediction of soil texture: Comparison of regression tree and Random Forest models." Geoderma (2012): vol. 170, p. 70-79; Knudby, Anders, Alexander Brenning, and Ellsworth LeDrew. "New approaches to modelling fish - habitat relationships." (2010): vol. 221, no. 3, p.503-511; Harris, Matthew D., Robert G. Kingsley, and Andrew R. Sewell. "Archeological Predictive Model Set." Pennsylvania Department of Transportation, March 2015; Caplan, Joel M., Leslie W. Kennedy, and Joel Miller. "Risk Terrain Modeling: Brokering Criminological Theory and GIS Methods for Crime Forecasting". Justice Quarterly (2011): vol. 28, no. 2; Steif, Kenneth, Jordan Butz, and Annie Streetment. "Predicting Spatial Risk of Opioid Overdoses in Providence, RI." May 2018.
  
  [^10]: Congalton, Russell G. "A Review of Assessing the Accuracy of Classifications of Remotely Sensed Data." Remote Sensing of Environment (1991): vol. 37, p.35-46; Vicente-Serrano, Sergio M. M. Angel Saz-Sanchez, and Jose M. Cuadrat. "Comparative analysis of interpolation methods in the middle Ebro Valley (Spain): application to annual precipitation and temperature." Climate Research (2003): vol. 24, p.161-180.; Li, Jin and Andrew D. Heap. "A Review of Spatial Interpolation Methods for Environmental Scientists." Geoscience Australia, 2008; Brenning, Alexander. "Spatial cross-validation and bootstrap for the assessment of prediction rules in remote sensing: The R package sperrorest." In 2012 IEEE International Geoscience and Remote Sensing Symposium, July 2012.
  
  [^11]: Kuhn, Max and Kjell Johnson. "Applied Predictive Modeling." 2013; Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. "The Elements of Statistical Learning: Data Mining, Inference, and Prediction." 2008.
  
  [^12]: Daley, Dyann, Michael Bachmann, Brittany A. Bachmann, Christian Pedigo, Minh-Thuy Bui, and Jamye Coffman. "Risk terrain modeling predicts child maltreatment." Child abuse & neglect 62 (2016): 29-38; Caplan, Joel M., Leslie W. Kennedy, and Joel Miller. "Risk Terrain Modeling: Brokering Criminological Theory and GIS Methods for Crime Forecasting". Justice Quarterly (2011): vol. 28, no. 2.
  
  [^13]: Tomlin, Dana C. "Geographic Information Systems and Cartographic Modeling." 1990.
  
  [^14]: Caplan, Joel M., Leslie W. Kennedy, and Eric L. Piza. "Risk Terrain Modeling Diagnostics Utility User Manual." Rutgers Center on Public Security, 2013.
  
  [^15]: The first approach illustrated the right image in this figure, measures the distance from each grid cell to its one nearest neighbor risk/protective factor. This relative measure of exposure is more useful than a simple aggregate count of risk/protective factors, however, it may be biased if the one nearest neighbor is an outlier. Thus, as illustrated by the left image in this figure, our third approach is to measure the average distance from each grid cell to its n nearest neighbor risk/protective factor, in this case n = 3. How many nearest neighbors is the 'correct' number to use? Consider the following three notions: First, for a given risk/protective factor, the 'correct' number of nearest neighbors leads to the best prediction. An optimal (but computationally intensive) predictive algorithm is one that would iteratively test each combination of risk/protective factors by each combination of n, selecting those the combination which leads to the most optimal model. Second, assumptions about n can be made according to how rare a given risk/protective event occurs in space. For instance, a feature describing exposure to crime would likely have a higher n than a feature describing distance to the nearest school. This is because crime occurs more frequently. Finally, if the scale of phenomena varies across the study area, there is likely no one correct nearest neighbor parameter. For example, imagine a city composed of a dense downtown and a less dense neighborhood along the periphery. Despite being in the same jurisdiction, the scale of the social relationships occurring in each place are fundamentally different because the scale of the built environment is fundamentally different. The figure provides an example of all three feature engineering. approaches.![](C:/projects/PAP_Virginia/final_report/nearestNeighborDiagram.png)
  
  [^16]: The final step in the feature engineering phase is to normalize the contributing risk and protective features by putting all of the measurements onto a relative scale. Data are normalized in two steps: 1) centering the range of measurements for each feature on zero by subtracting the mean, and 2) by scaling the measurements of each feature by dividing by the measurements standard deviation. The end result is that each feature has a mean of zero and each value is a z-score. A primary benefit of putting each of the measurements on the same scale is to help the machine learning algorithms compute more efficiently. Additionally, it leads to scaled model coefficients that are relative to the average measurement of the feature.

[^17]: Tukey, John W. "Exploratory Data Analysis." 1977.

[^18]: Bivand, Roger and Gianfranco Piras. "Comparing Implementations of Estimation Methods for Spatial Econometrics. Journal of Statistical Software"(2015): vol. 63, no. 18, p.1-36.

[^19]: Smith, Tony E. "Notebook on Spatial Data Analysis." 2016, https://www.seas.upenn.edu/~ese502/#notebook.
  
  [^20]: Delignette-Muller, Marie Laure  and Christophe Dutang. "fitdistrplus: An R Package for Fitting Distributions. Journal of Statistical Software"  (2015):vol. 64 no. 4, p.1-34

[^21]: Wright, Marvin N. and Andreas Ziegler. "ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R." Journal of Statistical Software (2017): vol. 77 no. 1, p.1-17.

[^22]: Bivand, Roger and Gianfranco Piras. "Comparing Implementations of Estimation Methods for Spatial Econometrics. Journal of Statistical Software"(2015): vol. 63, no. 18, p.1-36.

[^23]: There 148 neighborhoods in Richmond. With each taking a turn as a hold out, there are 296 models calculated for the GLM and Random Forest models. As explained above, the Spatial Durbin model is estimated once, as the spatial weights matrix prevents LOGOCV approach. This yields a total of 297 models.

[^24]: For example, if the predicted number of events is 5 and the observed number of recorded events is 7, then the MAE is 2. The absolute part describes that the error is the same whether it is positive or negative. The same prediction of 5 events and an observed value of 3 also has an MAE of 2. The MAE returns a single value no matter how many estimates are made. If the predictions for three different fishnet cells is 5, 8, and 10 with corresponding observed values of 3, 9, and 12, then the absolute errors are 2, 1, and 2 leading to an MAE of 1.67. 

[^25]: The graph below gives an example of how the log density and probability density measurements of the Logarithmic Score relate. In this plot, the two measurements are calculated for the same scenario in which the predicted value of maltreatment events is 50 (at the red vertical line) and the observed number of events is represented by each of the black dots from zero to 100. At the left hand side of each is the case where the recorded number of events is zero or close to zero. At this location the log density is very high relative to the baseline of zero and the probability density is near zero. In the middle of each chart where the estimated and expected values are close to the same, the log density is near zero and the probability is at its maximum. As the observed values move to the right away from the estimate, the log density again goes up and the probability goes down. The important takeaway from this plot is that when measured as a log density, the best estimate is always the one closest to zero which makes it very easy to compare models. However, the scale of the log density is not very intuitive. On the other hand, measuring on the probability side can lead to difficulties in comparing models if they are fit to different sets of data. However, it is on an intuitive scale of probability between zero and one. Given that all of the models here are fit to the same dataset, the probability density measurement is selected to represent the Logarithmic Score. ![](C:/projects/PAP_Virginia/final_report/log_score_image.png)

[^26]: Anselin, Luc. "Local Indicators of Spatial Association - LISA." Geographical Analysis (1995): p.93-115
